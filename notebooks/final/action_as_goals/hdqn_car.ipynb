{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"HDQN_car.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BOa4bDnuU8w7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609322155524,"user_tz":-60,"elapsed":21881,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"31b7a2b2-fb04-4cec-d89b-a67a03cbd73b"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#!cp \"/content/drive/My Drive/Dissertation/preprocessing.py\" .\n","#!cp -r \"/content/drive/My Drive/Dissertation/gym_maze\" .\n","#!cp -r \"/content/drive/My Drive/Dissertation/envs\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UjRnm66x6Sga","executionInfo":{"status":"ok","timestamp":1609322155528,"user_tz":-60,"elapsed":2407,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["# for inference, not continued training\r\n","def save_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","\r\n","    torch.save({\r\n","      'meta_controller': model.meta_controller.state_dict(),\r\n","      'controller': model.controller.state_dict()\r\n","    }, path)\r\n","\r\n","import copy\r\n","def load_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.meta_controller.load_state_dict(checkpoint['meta_controller'])\r\n","    model.meta_controller_target = copy.deepcopy(model.meta_controller)\r\n","    model.controller.load_state_dict(checkpoint['controller'])\r\n","    model.controller_target = copy.deepcopy(model.controller)\r\n","\r\n","    model.eval()\r\n","    model.meta_controller.eval()\r\n","    model.controller.eval()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_nd1HgGU8w7","executionInfo":{"status":"ok","timestamp":1609322159806,"user_tz":-60,"elapsed":5468,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","import cv2\n","from PIL import Image\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nwe9sNmHU8w7","executionInfo":{"status":"ok","timestamp":1609322159813,"user_tz":-60,"elapsed":4889,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["env = gym.make(\"MountainCar-v0\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vG98TmEU8w8"},"source":["---\n","### Helper functions"]},{"cell_type":"code","metadata":{"id":"KdafwykgU8w8","executionInfo":{"status":"ok","timestamp":1609322940604,"user_tz":-60,"elapsed":710,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["loss_plot = []\n","loss_plot_meta = []\n","def plot_durations(episode_durations):\n","    global loss_plot\n","    fig, axs = plt.subplots(3, figsize=(10,15))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    axs[1].set_xlabel('Steps')\n","    axs[1].set_ylabel('Loss')\n","    axs[2].set_xlabel('Steps')\n","    axs[2].set_ylabel('Loss (meta)')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","\n","    if len(loss_plot) > 0:\n","        durations_t, durations = list(map(list, zip(*loss_plot)))\n","        durations = torch.tensor(durations, dtype=torch.float)\n","\n","        axs[1].plot(durations_t, durations.numpy())\n","    if len(loss_plot_meta) > 0:\n","        durations_t, durations = list(map(list, zip(*loss_plot_meta)))\n","        durations = torch.tensor(durations, dtype=torch.float)\n","\n","        axs[2].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qx6CukwVU8w8"},"source":["---\n","### Code"]},{"cell_type":"code","metadata":{"id":"fisoWfOnU8w8","executionInfo":{"status":"ok","timestamp":1609322159821,"user_tz":-60,"elapsed":2851,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZ9BRCoIU8w8","executionInfo":{"status":"ok","timestamp":1609322160984,"user_tz":-60,"elapsed":1121,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","class DQN(nn.Module):\n","    def __init__(self, inputs, outputs, mem_len = 100000):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(inputs, 128)\n","        self.fc2 = nn.Linear(128, 128)\n","        self.head = nn.Linear(128, outputs)\n","        \n","        self.memory = ReplayMemory(mem_len)\n","\n","        self.n_actions = outputs\n","        self.steps_done = 0\n","        \n","        self.EPS_START = 1.0\n","        self.EPS_END = 0.01\n","        self.EPS_DECAY = 50000 # in number of steps\n","        self.TAU = 0.001\n","\n","        self.policy_update = 2\n","        self.tot_updates = 0\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.head(x)\n","    \n","    def act(self, state, is_training):\n","        if is_training:\n","            eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * (1. - min(1., self.steps_done / self.EPS_DECAY))\n","            self.steps_done += 1\n","\n","            # With probability eps select a random action\n","            if random.random() < eps_threshold:\n","                return torch.tensor([[random.randrange(self.n_actions)]], device=device, dtype=torch.long)\n","\n","        # otherwise select action = maxa Q∗(φ(st), a; θ)\n","        with torch.no_grad():\n","            return self(state).max(1)[1].view(1, 1)\n","    \n","    def experience_replay(self, optimizer, target):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.tot_updates += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","        \n","        current_Q_values = self(state_batch).gather(1, action_batch)\n","        # Compute next Q value based on which goal gives max Q values\n","        # Detach variable from the current graph since we don't want gradients for next Q to propagated\n","        next_max_q = target(next_state_batch).detach().max(1)[0]\n","        next_Q_values = not_done_mask * next_max_q\n","        # Compute the target of the current Q values\n","        target_Q_values = reward_batch + (GAMMA * next_Q_values)\n","        # Compute Bellman error (using Huber loss)\n","        loss = F.smooth_l1_loss(current_Q_values, target_Q_values.unsqueeze(1))\n","        loss_val = loss.item()\n","\n","        # Optimize the model\n","        optimizer.zero_grad()\n","        loss.backward()\n","        for param in self.parameters():\n","            param.grad.data.clamp_(-1, 1)\n","        optimizer.step()\n","\n","        if self.tot_updates % self.policy_update == 0:\n","            soft_update(target, self, self.TAU)\n","\n","        return loss_val\n","        \n","class HDQN(nn.Module):\n","    def __init__(self, inputs, outputs):\n","        super(HDQN, self).__init__()\n","        # Optimizer\n","        #learning_rate = 2.5e-4\n","        \n","        # goal is left/right\n","        self.meta_controller = DQN(inputs, outputs).to(device)\n","        #self.meta_controller_optimizer = optim.RMSprop(self.meta_controller.parameters(), lr=learning_rate)\n","        self.meta_controller_optimizer = optim.Adam(self.meta_controller.parameters())\n","        self.meta_controller_target = DQN(inputs, outputs, mem_len = 0).to(device)\n","        self.meta_controller_target.eval()\n","        \n","        # takes goal+state jointly\n","        self.controller = DQN(inputs + 1, outputs).to(device)\n","        #self.controller_optimizer = optim.RMSprop(self.controller.parameters(), lr=learning_rate)\n","        self.controller_optimizer = optim.Adam(self.controller.parameters())\n","        self.controller_target = DQN(inputs + 1, outputs, mem_len = 0).to(device)\n","        self.controller_target.eval()\n","\n","        self.controller.EPS_END = 0.0\n","        self.controller.EPS_DECAY = 1000\n","    \n","    def store_controller(self, *args):\n","        self.controller.memory.store(*args)\n","    \n","    def store_meta_controller(self, *args):\n","        self.meta_controller.memory.store(*args)\n","    \n","    def select_goal(self, external_observation, is_training):\n","        return self.meta_controller.act(external_observation, is_training)\n","        \n","    def select_action(self, joint_goal_obs, is_training):\n","        return self.controller.act(joint_goal_obs, is_training)\n","    \n","    def teach_meta_controller(self):\n","        return self.meta_controller.experience_replay(self.meta_controller_optimizer, self.meta_controller_target)\n","\n","    def teach_controller(self):\n","        return self.controller.experience_replay(self.controller_optimizer, self.controller_target)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgHmamR6U8w8"},"source":["def plot_norms(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\n","    \n","    plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","    plt.xlabel('L2 Norm')\n","    plt.ylabel('Average Reward')\n","    \n","    mu = np.mean(ys, axis=1)\n","    plt.plot(x, mu)\n","    stds = np.std(ys, axis = 1)\n","    plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nr9-j_IbU8w8","executionInfo":{"status":"ok","timestamp":1609322910079,"user_tz":-60,"elapsed":662,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["import time\n","SAVE_OFFSET = 11\n","\n","def train_model():\n","    global SAVE_OFFSET\n","    # Get number of actions and observations from gym action space\n","    n_actions = env.action_space.n\n","    n_observations = env.observation_space.shape[0]\n","\n","    # Initialize action-value function Q with random weights\n","    hdqnAgent = HDQN(n_observations, n_actions).to(device)\n","\n","    max_episode_length = 200\n","\n","    num_episodes = 4000 # M\n","    episode_durations = []\n","\n","    steps = 0\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        overall_reward = 0\n","        done = False\n","        episode_steps = 0\n","        while not done:\n","            # select a goal\n","            goal = hdqnAgent.select_goal(state, True)\n","            goal_i = goal.item()\n","\n","            goal_done = False\n","            total_extrinsic = 0\n","            s_0 = state\n","            steps_until_goal = 0\n","            while not done and not goal_done:\n","                joint_goal_state = torch.cat([goal, state], axis=1)\n","\n","                # Execute action a_t in emulator and observe reward r_t and image x_{t+1}\n","                action = hdqnAgent.select_action(joint_goal_state, True)\n","                action_i = action.item()\n","\n","                observation, reward, done, _ = env.step(action_i)\n","                steps += 1\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","                \n","                extrinsic_reward = torch.tensor([reward], device=device)\n","\n","                overall_reward += reward\n","                total_extrinsic += reward\n","\n","                # preprocess φ_{t+1} = φ(s_{t+1})\n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                joint_next_state = torch.cat([goal, next_state], axis=1)\n","\n","                goal_done = (goal_i == action_i)\n","                if not goal_done:\n","                    steps_until_goal += 1\n","                else:\n","                    pass\n","                    #loss_plot.append((steps, steps_until_goal))\n","\n","                intrinsic_reward = torch.tensor([1.0 if goal_done else 0], device=device)\n","\n","                # Store transition (φt, at, rt, φt+1) in D\n","                hdqnAgent.store_controller(joint_goal_state, action, joint_next_state, intrinsic_reward, done)\n","\n","                state = next_state\n","\n","                loss = hdqnAgent.teach_controller()\n","                if loss is not None and i_episode % 50 == 0:\n","                    loss_plot.append((steps, loss))\n","\n","            # Store transition for meta controller\n","            hdqnAgent.store_meta_controller(s_0, goal, next_state, torch.tensor([total_extrinsic], device=device), done)\n","            loss = hdqnAgent.teach_meta_controller()\n","            if loss is not None and i_episode % 50 == 0:\n","                loss_plot_meta.append((steps, loss))\n","        \n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations)\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0 and i_episode >= 1000 and np.mean(dur[-100:]) < -199.0:\n","                print(f\"Failed to get lucky after 1000 eps, terminating... Avg: {np.mean(dur[-100:])}\")\n","                return None # unlucky\n","            if i_episode % 250 == 0:\n","                print(f\"Episode {i_episode}: {np.mean(dur[-100:])}\")\n","            if np.mean(dur[-100:]) >= -110:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(hdqnAgent, f\"hdqn_car_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return hdqnAgent\n","\n","    return None # did not train"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYpz9B3RmlRj","executionInfo":{"status":"ok","timestamp":1609327639978,"user_tz":-60,"elapsed":4696246,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"e05a9edc-917e-4b44-f30b-66ddd85098d7"},"source":["i = 10\r\n","while i < 11:\r\n","    agent = train_model()\r\n","    if agent is not None:\r\n","        print(f\"Num. {i} done!\")\r\n","        i += 1"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Episode 250: -200.0\n","Episode 500: -168.11\n","Episode 750: -196.14\n","Failed to get lucky after 1000 eps, terminating... Avg: -200.0\n","Episode 250: -199.36\n","Episode 500: -166.83\n","Episode 750: -198.01\n","Failed to get lucky after 1000 eps, terminating... Avg: -200.0\n","Episode 250: -200.0\n","Episode 500: -183.6\n","Episode 750: -195.9\n","Episode 1000: -177.85\n","Episode 1250: -143.99\n","Episode 1500: -125.85\n","Episode 1750: -114.25\n","Solved after 1866 episodes!\n","Num. 10 done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o6BqeP-7w7MN","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1609246255146,"user_tz":-60,"elapsed":2576378,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"0d74866a-be0e-426f-9f92-4052ea82666c"},"source":["loss_plot = []\r\n","loss_plot_meta = []\r\n","#agent = train_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Solved after 1580 episodes!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55noGZWJ7rFU","executionInfo":{"status":"ok","timestamp":1609322176786,"user_tz":-60,"elapsed":11034,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device)\r\n","state_min = torch.from_numpy(env.observation_space.low).to(device)\r\n","def fgsm_attack(data, eps, data_grad):\r\n","    sign_data_grad = data_grad.sign()\r\n","\r\n","    perturbed_data = data + eps * sign_data_grad * state_max\r\n","\r\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\r\n","\r\n","    return clipped_perturbed_data\r\n","\r\n","def fgsm_goal(g_state, agent, eps, target, targetted):\r\n","    #g_state = torch.tensor(g_state, requires_grad=True)\r\n","\r\n","    g_state_var = g_state.clone().detach().requires_grad_(True)\r\n","\r\n","    # initial forward pass\r\n","    goal = agent.meta_controller(g_state_var)\r\n","    #goal = temp.max(1)[1].view(1, 1)\r\n","\r\n","    if targetted:\r\n","        loss = F.smooth_l1_loss(goal, target)\r\n","    else:\r\n","        pass\r\n","        #loss = F.smooth_l1_loss(goal, temp.min(1)[1].view(1, 1).float())\r\n","\r\n","    agent.meta_controller.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = g_state_var.grad.data\r\n","\r\n","    # perturb state\r\n","    g_state_p = fgsm_attack(g_state, eps, data_grad)\r\n","    return agent.select_goal(g_state_p, False)\r\n","\r\n","def fgsm_action(state, goal, agent, eps, target, targetted):\r\n","    #state = torch.tensor(state, requires_grad=True)\r\n","    state_var = state.clone().detach().requires_grad_(True)\r\n","\r\n","    joint_goal_state = torch.cat([goal, state_var], 1).float()\r\n","    \r\n","    # initial forward pass\r\n","    action = agent.controller(joint_goal_state)\r\n","    #action = temp.max(1)[1].view(1, 1).float()\r\n","\r\n","    if targetted:\r\n","        loss = F.smooth_l1_loss(action, target)\r\n","    else:\r\n","        pass\r\n","        #loss = F.smooth_l1_loss(action, temp.min(1)[1].view(1, 1).float())\r\n","\r\n","    agent.controller.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = state_var.grad.data\r\n","    # perturb state\r\n","    state_p = fgsm_attack(state, eps, data_grad)\r\n","\r\n","    joint_goal_state = torch.cat([goal, state_p], 1).float()\r\n","    return agent.select_action(joint_goal_state, False)\r\n","\r\n","def apply_fgsm(agent, episode_durations, goal_attack, action_attack, targetted):\r\n","    TARGET_GOAL = torch.tensor([[0.0, 0.0, 0.0]], device=device, dtype=torch.float)\r\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0, 0.0]], device=device, dtype=torch.float)\r\n","\r\n","    agent.eval()\r\n","    agent.meta_controller.eval()\r\n","    agent.controller.eval()\r\n","\r\n","    max_episode_length = 200\r\n","\r\n","    num_episodes = 100\r\n","\r\n","    for eps in np.arange(0.0, 0.31, 0.025):\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","                \r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                # select a goal\r\n","                if goal_attack:\r\n","                    goal = fgsm_goal(state, agent, eps, TARGET_GOAL, targetted)\r\n","                else:\r\n","                    goal = agent.select_goal(state, False)\r\n","                goal_i = goal.item()\r\n","\r\n","                goal_done = False\r\n","                while not done and not goal_done:\r\n","                    joint_goal_state = torch.cat([goal, state], axis=1)\r\n","\r\n","                    if action_attack:\r\n","                        action = fgsm_action(state, goal, agent, eps, TARGET_ACTION, targetted)\r\n","                    else:\r\n","                        action = agent.select_action(joint_goal_state, False)\r\n","\r\n","                    action_i = action.item()\r\n","                    observation, reward, done, _ = env.step(action_i)\r\n","\r\n","                    overall_reward += reward\r\n","\r\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                        done = True\r\n","                    episode_steps += 1\r\n","\r\n","                    goal_done = (goal_i == action_i)\r\n","\r\n","                    state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktebJKBtU8w8","executionInfo":{"status":"ok","timestamp":1609328826275,"user_tz":-60,"elapsed":753,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device)\n","def eval_model(hdqnAgent, episode_durations, goal_noise, action_noise, same_noise):\n","    hdqnAgent.eval()\n","    hdqnAgent.meta_controller.eval()\n","    hdqnAgent.controller.eval()\n","\n","    max_episode_length = 200\n","    num_episodes = 100\n","\n","    for l2norm in np.arange(0,1.001,0.1):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            noise = torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","            if goal_noise:\n","                g_state = state + state_max * noise\n","                g_state = g_state.float()\n","            if action_noise:\n","                if same_noise:\n","                    state = state + state_max * noise\n","                else:\n","                    state = state + state_max * torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                state = state.float()\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = hdqnAgent.select_goal(g_state, False)\n","                goal_i = goal.item()\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    joint_goal_state = torch.cat([goal, state], axis=1)\n","\n","                    action = hdqnAgent.select_action(joint_goal_state, False)\n","                    action_i = action.item()\n","                    observation, reward, done, _ = env.step(action_i)\n","\n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    goal_done = (goal_i == action_i)\n","\n","                    state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    noise = torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                    if goal_noise:\n","                        g_state = state + state_max * noise\n","                        g_state = g_state.float()\n","                    if action_noise:\n","                        if same_noise:\n","                            state = state + state_max * noise\n","                        else:\n","                            state = state + state_max * torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                        state = state.float()\n","\n","        episode_durations[l2norm].append(overall_reward / num_episodes)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJKWKLPjAipR"},"source":["def plot_fgsm(episode_durations):\r\n","    plt.figure(2, figsize=(10,10))\r\n","    \r\n","    for kk in ['both', 'goal_only', 'action_only']:\r\n","        x, ys = np.array(list(episode_durations[kk].keys())), np.array(list(episode_durations[kk].values()))\r\n","        #plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\r\n","        plt.xlabel('$\\epsilon$')\r\n","        plt.ylabel('Average Reward')\r\n","        \r\n","        mu = np.mean(ys, axis=1)\r\n","        plt.plot(x, mu, label=kk)\r\n","        stds = np.std(ys, axis = 1)\r\n","        plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\r\n","    \r\n","    plt.legend()\r\n","    plt.pause(0.001)  # pause a bit so that plots are updated\r\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBfZ2tc_U8w8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609329387752,"user_tz":-60,"elapsed":559573,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"254c5554-3d7d-4cb6-b241-3fec6aa139e1"},"source":["same_noise = {}\n","diff_noise = {}\n","goal_only = {}\n","action_only = {}\n","for l2norm in np.arange(0,1.001,0.1):\n","    for i in [same_noise, diff_noise, goal_only, action_only]:\n","        i[l2norm] = []\n","\n","n_actions = env.action_space.n\n","n_observations = env.observation_space.shape[0]\n","\n","# train 20 models, then eval them\n","i = 11\n","while i < 12:\n","    #agent = train_model()\n","    agent = HDQN(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hdqn_car_{i}\")\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_model(agent, same_noise, True, True, True)\n","        eval_model(agent, diff_noise, True, True, False)\n","        eval_model(agent, goal_only, True, False, False)\n","        eval_model(agent, action_only, False, True, False)\n","        print(i)\n","        print(f\"same noise: {same_noise}\")\n","        print(f\"diff noise: {diff_noise}\")\n","        print(f\"goal only: {goal_only}\")\n","        print(f\"action only: {action_only}\")\n","        i += 1\n","\n","print(f\"same noise: {same_noise}\")\n","print(f\"diff noise: {diff_noise}\")\n","print(f\"goal only: {goal_only}\")\n","print(f\"action only: {action_only}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["11\n","same noise: {0.0: [-112.73], 0.1: [-121.77], 0.2: [-133.37], 0.30000000000000004: [-153.03], 0.4: [-165.22], 0.5: [-173.38], 0.6000000000000001: [-182.65], 0.7000000000000001: [-188.65], 0.8: [-190.74], 0.9: [-193.01], 1.0: [-195.94]}\n","diff noise: {0.0: [-115.21], 0.1: [-119.8], 0.2: [-135.39], 0.30000000000000004: [-157.01], 0.4: [-175.45], 0.5: [-183.75], 0.6000000000000001: [-185.93], 0.7000000000000001: [-195.2], 0.8: [-191.41], 0.9: [-196.62], 1.0: [-196.37]}\n","goal only: {0.0: [-115.46], 0.1: [-118.46], 0.2: [-123.7], 0.30000000000000004: [-144.9], 0.4: [-156.73], 0.5: [-170.03], 0.6000000000000001: [-176.67], 0.7000000000000001: [-189.03], 0.8: [-192.07], 0.9: [-194.54], 1.0: [-196.12]}\n","action only: {0.0: [-117.52], 0.1: [-116.2], 0.2: [-119.05], 0.30000000000000004: [-122.62], 0.4: [-131.33], 0.5: [-136.34], 0.6000000000000001: [-138.11], 0.7000000000000001: [-147.88], 0.8: [-147.66], 0.9: [-146.48], 1.0: [-145.73]}\n","same noise: {0.0: [-112.73], 0.1: [-121.77], 0.2: [-133.37], 0.30000000000000004: [-153.03], 0.4: [-165.22], 0.5: [-173.38], 0.6000000000000001: [-182.65], 0.7000000000000001: [-188.65], 0.8: [-190.74], 0.9: [-193.01], 1.0: [-195.94]}\n","diff noise: {0.0: [-115.21], 0.1: [-119.8], 0.2: [-135.39], 0.30000000000000004: [-157.01], 0.4: [-175.45], 0.5: [-183.75], 0.6000000000000001: [-185.93], 0.7000000000000001: [-195.2], 0.8: [-191.41], 0.9: [-196.62], 1.0: [-196.37]}\n","goal only: {0.0: [-115.46], 0.1: [-118.46], 0.2: [-123.7], 0.30000000000000004: [-144.9], 0.4: [-156.73], 0.5: [-170.03], 0.6000000000000001: [-176.67], 0.7000000000000001: [-189.03], 0.8: [-192.07], 0.9: [-194.54], 1.0: [-196.12]}\n","action only: {0.0: [-117.52], 0.1: [-116.2], 0.2: [-119.05], 0.30000000000000004: [-122.62], 0.4: [-131.33], 0.5: [-136.34], 0.6000000000000001: [-138.11], 0.7000000000000001: [-147.88], 0.8: [-147.66], 0.9: [-146.48], 1.0: [-145.73]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpWwUiRkAjnM","executionInfo":{"status":"ok","timestamp":1609346203247,"user_tz":-60,"elapsed":681858,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"6941cc01-cb6f-477c-9682-59444e9098b0"},"source":["targeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\r\n","untargeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\r\n","for eps in np.arange(0.0, 0.31, 0.025):\r\n","    for x in ['both', 'goal_only', 'action_only']:\r\n","        targeted[x][eps] = []\r\n","        untargeted[x][eps] = []\r\n","\r\n","n_actions = env.action_space.n\r\n","n_observations = env.observation_space.shape[0]\r\n","\r\n","i = 1\r\n","while i < 12:\r\n","    #agent = train_model()\r\n","    agent = HDQN(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"hdqn_car_{i}\")\r\n","    if agent is not None:\r\n","        apply_fgsm(agent, targeted['both'], True, True, True)\r\n","        apply_fgsm(agent, targeted['goal_only'], True, False, True)\r\n","        apply_fgsm(agent, targeted['action_only'], False, True, True)\r\n","        #apply_fgsm(agent, untargeted['both'], True, True, False)\r\n","        #apply_fgsm(agent, untargeted['goal_only'], True, False, False)\r\n","        #apply_fgsm(agent, untargeted['action_only'], False, True, False)\r\n","        print(i)\r\n","        print(f\"Targeted: {targeted}\")\r\n","        print(f\"Untargeted: {untargeted}\")\r\n","        #plot_fgsm(episode_durations)\r\n","        i += 1\r\n","\r\n","#plot_fgsm(episode_durations)\r\n","print(f\"Targeted: {targeted}\")\r\n","print(f\"Untargeted: {untargeted}\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["1\n","Targeted: {'both': {0.0: [-108.77], 0.025: [-110.74], 0.05: [-128.57], 0.07500000000000001: [-130.21], 0.1: [-141.28], 0.125: [-158.29], 0.15000000000000002: [-171.26], 0.17500000000000002: [-181.85], 0.2: [-182.14], 0.225: [-184.92], 0.25: [-185.68], 0.275: [-185.88], 0.30000000000000004: [-195.25]}, 'goal_only': {0.0: [-106.96], 0.025: [-112.23], 0.05: [-127.26], 0.07500000000000001: [-131.16], 0.1: [-144.37], 0.125: [-154.28], 0.15000000000000002: [-172.03], 0.17500000000000002: [-182.24], 0.2: [-183.97], 0.225: [-188.99], 0.25: [-180.4], 0.275: [-186.71], 0.30000000000000004: [-198.16]}, 'action_only': {0.0: [-106.44], 0.025: [-105.48], 0.05: [-106.69], 0.07500000000000001: [-107.51], 0.1: [-104.87], 0.125: [-104.37], 0.15000000000000002: [-107.23], 0.17500000000000002: [-106.61], 0.2: [-107.3], 0.225: [-108.65], 0.25: [-106.45], 0.275: [-103.61], 0.30000000000000004: [-107.19]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","2\n","Targeted: {'both': {0.0: [-108.77, -101.18], 0.025: [-110.74, -127.09], 0.05: [-128.57, -148.87], 0.07500000000000001: [-130.21, -162.9], 0.1: [-141.28, -176.04], 0.125: [-158.29, -174.88], 0.15000000000000002: [-171.26, -180.39], 0.17500000000000002: [-181.85, -179.46], 0.2: [-182.14, -180.69], 0.225: [-184.92, -180.01], 0.25: [-185.68, -200.0], 0.275: [-185.88, -200.0], 0.30000000000000004: [-195.25, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25], 0.025: [-112.23, -128.23], 0.05: [-127.26, -146.07], 0.07500000000000001: [-131.16, -154.94], 0.1: [-144.37, -175.12], 0.125: [-154.28, -172.02], 0.15000000000000002: [-172.03, -175.02], 0.17500000000000002: [-182.24, -178.38], 0.2: [-183.97, -176.26], 0.225: [-188.99, -173.98], 0.25: [-180.4, -175.75], 0.275: [-186.71, -173.82], 0.30000000000000004: [-198.16, -200.0]}, 'action_only': {0.0: [-106.44, -102.98], 0.025: [-105.48, -99.69], 0.05: [-106.69, -103.24], 0.07500000000000001: [-107.51, -101.15], 0.1: [-104.87, -103.89], 0.125: [-104.37, -101.06], 0.15000000000000002: [-107.23, -105.21], 0.17500000000000002: [-106.61, -100.3], 0.2: [-107.3, -104.22], 0.225: [-108.65, -100.79], 0.25: [-106.45, -101.28], 0.275: [-103.61, -104.45], 0.30000000000000004: [-107.19, -100.6]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","3\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09], 0.025: [-110.74, -127.09, -99.61], 0.05: [-128.57, -148.87, -104.14], 0.07500000000000001: [-130.21, -162.9, -106.5], 0.1: [-141.28, -176.04, -117.41], 0.125: [-158.29, -174.88, -129.98], 0.15000000000000002: [-171.26, -180.39, -164.58], 0.17500000000000002: [-181.85, -179.46, -181.13], 0.2: [-182.14, -180.69, -195.88], 0.225: [-184.92, -180.01, -200.0], 0.25: [-185.68, -200.0, -200.0], 0.275: [-185.88, -200.0, -200.0], 0.30000000000000004: [-195.25, -200.0, -192.09]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92], 0.025: [-112.23, -128.23, -100.28], 0.05: [-127.26, -146.07, -104.39], 0.07500000000000001: [-131.16, -154.94, -110.69], 0.1: [-144.37, -175.12, -125.19], 0.125: [-154.28, -172.02, -153.27], 0.15000000000000002: [-172.03, -175.02, -160.95], 0.17500000000000002: [-182.24, -178.38, -161.9], 0.2: [-183.97, -176.26, -166.07], 0.225: [-188.99, -173.98, -161.97], 0.25: [-180.4, -175.75, -160.2], 0.275: [-186.71, -173.82, -159.11], 0.30000000000000004: [-198.16, -200.0, -160.5]}, 'action_only': {0.0: [-106.44, -102.98, -98.35], 0.025: [-105.48, -99.69, -98.33], 0.05: [-106.69, -103.24, -98.75], 0.07500000000000001: [-107.51, -101.15, -104.43], 0.1: [-104.87, -103.89, -111.87], 0.125: [-104.37, -101.06, -120.39], 0.15000000000000002: [-107.23, -105.21, -118.95], 0.17500000000000002: [-106.61, -100.3, -117.1], 0.2: [-107.3, -104.22, -121.53], 0.225: [-108.65, -100.79, -120.59], 0.25: [-106.45, -101.28, -122.2], 0.275: [-103.61, -104.45, -125.95], 0.30000000000000004: [-107.19, -100.6, -133.89]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","4\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88], 0.025: [-110.74, -127.09, -99.61, -128.5], 0.05: [-128.57, -148.87, -104.14, -144.83], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26], 0.1: [-141.28, -176.04, -117.41, -166.7], 0.125: [-158.29, -174.88, -129.98, -168.93], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5], 0.2: [-182.14, -180.69, -195.88, -183.93], 0.225: [-184.92, -180.01, -200.0, -180.28], 0.25: [-185.68, -200.0, -200.0, -181.86], 0.275: [-185.88, -200.0, -200.0, -175.54], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39], 0.025: [-112.23, -128.23, -100.28, -122.75], 0.05: [-127.26, -146.07, -104.39, -146.57], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35], 0.1: [-144.37, -175.12, -125.19, -163.77], 0.125: [-154.28, -172.02, -153.27, -166.39], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54], 0.2: [-183.97, -176.26, -166.07, -183.39], 0.225: [-188.99, -173.98, -161.97, -181.75], 0.25: [-180.4, -175.75, -160.2, -176.61], 0.275: [-186.71, -173.82, -159.11, -176.5], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77], 0.025: [-105.48, -99.69, -98.33, -120.1], 0.05: [-106.69, -103.24, -98.75, -123.28], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75], 0.1: [-104.87, -103.89, -111.87, -118.82], 0.125: [-104.37, -101.06, -120.39, -121.17], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38], 0.2: [-107.3, -104.22, -121.53, -123.19], 0.225: [-108.65, -100.79, -120.59, -120.89], 0.25: [-106.45, -101.28, -122.2, -120.2], 0.275: [-103.61, -104.45, -125.95, -116.84], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","5\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","6\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","7\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","8\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95, -113.77], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03, -169.16], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27, -156.6], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65, -176.72], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61, -186.37], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79, -185.09], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0, -193.44], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0, -200.0], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0, -200.0], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0, -200.0], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0, -200.0], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43, -113.01], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41, -164.53], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48, -183.08], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06, -190.35], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3, -196.87], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88, -189.28], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0, -186.35], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0, -189.86], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0, -198.23], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71, -112.93], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45, -169.11], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66, -167.3], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04, -162.8], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88, -157.34], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53, -130.98], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17, -105.6], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63, -108.3], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32, -110.38], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98, -112.37], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49, -111.87], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74, -110.0], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72, -110.6]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","9\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95, -113.77, -105.89], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03, -169.16, -104.49], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27, -156.6, -116.35], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65, -176.72, -148.27], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61, -186.37, -159.6], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79, -185.09, -185.23], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0, -193.44, -175.69], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0, -200.0, -184.43], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0, -200.0, -198.43], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0, -200.0, -200.0], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0, -200.0, -200.0], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0, -200.0, -199.37], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0, -200.0, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43, -113.01, -104.66], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41, -164.53, -108.12], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48, -183.08, -117.95], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06, -190.35, -154.89], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3, -196.87, -162.79], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88, -189.28, -180.06], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0, -186.35, -178.83], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0, -189.86, -185.97], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0, -198.23, -199.0], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0, -200.0, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0, -200.0, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0, -200.0, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71, -112.93, -104.15], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45, -169.11, -104.88], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66, -167.3, -107.37], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04, -162.8, -104.91], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88, -157.34, -106.11], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53, -130.98, -105.29], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17, -105.6, -105.17], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63, -108.3, -102.52], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32, -110.38, -106.86], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98, -112.37, -104.92], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49, -111.87, -106.04], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74, -110.0, -103.75], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72, -110.6, -108.13]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","10\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95, -113.77, -105.89, -99.52], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03, -169.16, -104.49, -104.6], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27, -156.6, -116.35, -131.55], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65, -176.72, -148.27, -170.91], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61, -186.37, -159.6, -187.71], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79, -185.09, -185.23, -189.06], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0, -193.44, -175.69, -186.95], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0, -200.0, -184.43, -195.39], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0, -200.0, -198.43, -197.25], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0, -200.0, -200.0, -193.45], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0, -200.0, -200.0, -183.27], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0, -200.0, -199.37, -173.17], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0, -200.0, -200.0, -168.13]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43, -113.01, -104.66, -98.23], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41, -164.53, -108.12, -104.5], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48, -183.08, -117.95, -135.67], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06, -190.35, -154.89, -170.79], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3, -196.87, -162.79, -188.07], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88, -189.28, -180.06, -192.42], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0, -186.35, -178.83, -189.09], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0, -189.86, -185.97, -195.38], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0, -198.23, -199.0, -199.6], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0, -200.0, -200.0, -193.53], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0, -200.0, -200.0, -187.07], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0, -200.0, -200.0, -177.01], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0, -200.0, -200.0, -198.69]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71, -112.93, -104.15, -99.57], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45, -169.11, -104.88, -100.55], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66, -167.3, -107.37, -100.4], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04, -162.8, -104.91, -98.61], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88, -157.34, -106.11, -97.56], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53, -130.98, -105.29, -99.52], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17, -105.6, -105.17, -99.16], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63, -108.3, -102.52, -98.81], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32, -110.38, -106.86, -98.4], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98, -112.37, -104.92, -99.41], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49, -111.87, -106.04, -99.64], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74, -110.0, -103.75, -99.23], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72, -110.6, -108.13, -99.63]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","11\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95, -113.77, -105.89, -99.52, -114.38], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03, -169.16, -104.49, -104.6, -122.19], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27, -156.6, -116.35, -131.55, -120.55], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65, -176.72, -148.27, -170.91, -145.27], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61, -186.37, -159.6, -187.71, -129.74], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79, -185.09, -185.23, -189.06, -152.32], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0, -193.44, -175.69, -186.95, -153.96], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0, -200.0, -184.43, -195.39, -186.42], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0, -200.0, -198.43, -197.25, -190.77], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0, -200.0, -200.0, -193.45, -189.42], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0, -200.0, -200.0, -183.27, -192.89], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0, -200.0, -199.37, -173.17, -199.83], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0, -200.0, -200.0, -168.13, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43, -113.01, -104.66, -98.23, -115.08], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41, -164.53, -108.12, -104.5, -113.13], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48, -183.08, -117.95, -135.67, -117.03], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06, -190.35, -154.89, -170.79, -125.93], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3, -196.87, -162.79, -188.07, -156.04], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88, -189.28, -180.06, -192.42, -169.4], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0, -186.35, -178.83, -189.09, -193.31], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0, -189.86, -185.97, -195.38, -200.0], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0, -198.23, -199.0, -199.6, -200.0], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0, -200.0, -200.0, -193.53, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0, -200.0, -200.0, -187.07, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0, -200.0, -200.0, -177.01, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0, -200.0, -200.0, -198.69, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71, -112.93, -104.15, -99.57, -112.54], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45, -169.11, -104.88, -100.55, -121.12], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66, -167.3, -107.37, -100.4, -123.97], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04, -162.8, -104.91, -98.61, -126.05], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88, -157.34, -106.11, -97.56, -132.84], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53, -130.98, -105.29, -99.52, -163.47], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17, -105.6, -105.17, -99.16, -159.27], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63, -108.3, -102.52, -98.81, -160.47], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32, -110.38, -106.86, -98.4, -166.42], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98, -112.37, -104.92, -99.41, -168.26], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49, -111.87, -106.04, -99.64, -170.83], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74, -110.0, -103.75, -99.23, -141.28], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72, -110.6, -108.13, -99.63, -113.02]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n","Targeted: {'both': {0.0: [-108.77, -101.18, -98.09, -124.88, -107.76, -167.13, -119.95, -113.77, -105.89, -99.52, -114.38], 0.025: [-110.74, -127.09, -99.61, -128.5, -116.05, -183.56, -125.03, -169.16, -104.49, -104.6, -122.19], 0.05: [-128.57, -148.87, -104.14, -144.83, -128.66, -188.33, -149.27, -156.6, -116.35, -131.55, -120.55], 0.07500000000000001: [-130.21, -162.9, -106.5, -160.26, -163.72, -183.41, -160.65, -176.72, -148.27, -170.91, -145.27], 0.1: [-141.28, -176.04, -117.41, -166.7, -172.81, -186.33, -175.61, -186.37, -159.6, -187.71, -129.74], 0.125: [-158.29, -174.88, -129.98, -168.93, -175.3, -193.02, -193.79, -185.09, -185.23, -189.06, -152.32], 0.15000000000000002: [-171.26, -180.39, -164.58, -173.95, -194.15, -192.5, -200.0, -193.44, -175.69, -186.95, -153.96], 0.17500000000000002: [-181.85, -179.46, -181.13, -182.5, -193.41, -193.16, -200.0, -200.0, -184.43, -195.39, -186.42], 0.2: [-182.14, -180.69, -195.88, -183.93, -195.29, -200.0, -200.0, -200.0, -198.43, -197.25, -190.77], 0.225: [-184.92, -180.01, -200.0, -180.28, -189.67, -200.0, -200.0, -200.0, -200.0, -193.45, -189.42], 0.25: [-185.68, -200.0, -200.0, -181.86, -186.02, -200.0, -200.0, -200.0, -200.0, -183.27, -192.89], 0.275: [-185.88, -200.0, -200.0, -175.54, -200.0, -200.0, -200.0, -200.0, -199.37, -173.17, -199.83], 0.30000000000000004: [-195.25, -200.0, -192.09, -186.52, -200.0, -200.0, -200.0, -200.0, -200.0, -168.13, -200.0]}, 'goal_only': {0.0: [-106.96, -101.25, -97.92, -116.39, -107.93, -169.17, -117.43, -113.01, -104.66, -98.23, -115.08], 0.025: [-112.23, -128.23, -100.28, -122.75, -116.21, -183.36, -125.41, -164.53, -108.12, -104.5, -113.13], 0.05: [-127.26, -146.07, -104.39, -146.57, -122.85, -191.89, -152.48, -183.08, -117.95, -135.67, -117.03], 0.07500000000000001: [-131.16, -154.94, -110.69, -159.35, -156.34, -182.54, -161.06, -190.35, -154.89, -170.79, -125.93], 0.1: [-144.37, -175.12, -125.19, -163.77, -162.15, -188.93, -184.3, -196.87, -162.79, -188.07, -156.04], 0.125: [-154.28, -172.02, -153.27, -166.39, -174.18, -191.44, -196.88, -189.28, -180.06, -192.42, -169.4], 0.15000000000000002: [-172.03, -175.02, -160.95, -175.24, -193.67, -187.94, -200.0, -186.35, -178.83, -189.09, -193.31], 0.17500000000000002: [-182.24, -178.38, -161.9, -179.54, -196.15, -182.12, -200.0, -189.86, -185.97, -195.38, -200.0], 0.2: [-183.97, -176.26, -166.07, -183.39, -193.54, -195.63, -200.0, -198.23, -199.0, -199.6, -200.0], 0.225: [-188.99, -173.98, -161.97, -181.75, -188.15, -200.0, -200.0, -200.0, -200.0, -193.53, -200.0], 0.25: [-180.4, -175.75, -160.2, -176.61, -188.32, -200.0, -200.0, -200.0, -200.0, -187.07, -200.0], 0.275: [-186.71, -173.82, -159.11, -176.5, -200.0, -200.0, -200.0, -200.0, -200.0, -177.01, -200.0], 0.30000000000000004: [-198.16, -200.0, -160.5, -189.16, -200.0, -200.0, -200.0, -200.0, -200.0, -198.69, -200.0]}, 'action_only': {0.0: [-106.44, -102.98, -98.35, -115.77, -108.79, -159.49, -118.71, -112.93, -104.15, -99.57, -112.54], 0.025: [-105.48, -99.69, -98.33, -120.1, -107.82, -164.6, -120.45, -169.11, -104.88, -100.55, -121.12], 0.05: [-106.69, -103.24, -98.75, -123.28, -108.16, -163.94, -113.66, -167.3, -107.37, -100.4, -123.97], 0.07500000000000001: [-107.51, -101.15, -104.43, -125.75, -111.55, -165.24, -119.04, -162.8, -104.91, -98.61, -126.05], 0.1: [-104.87, -103.89, -111.87, -118.82, -109.31, -157.62, -121.88, -157.34, -106.11, -97.56, -132.84], 0.125: [-104.37, -101.06, -120.39, -121.17, -109.36, -135.15, -119.53, -130.98, -105.29, -99.52, -163.47], 0.15000000000000002: [-107.23, -105.21, -118.95, -120.54, -109.95, -117.69, -120.17, -105.6, -105.17, -99.16, -159.27], 0.17500000000000002: [-106.61, -100.3, -117.1, -117.38, -108.03, -112.27, -120.63, -108.3, -102.52, -98.81, -160.47], 0.2: [-107.3, -104.22, -121.53, -123.19, -109.89, -122.43, -122.32, -110.38, -106.86, -98.4, -166.42], 0.225: [-108.65, -100.79, -120.59, -120.89, -111.43, -136.16, -118.98, -112.37, -104.92, -99.41, -168.26], 0.25: [-106.45, -101.28, -122.2, -120.2, -113.36, -179.95, -117.49, -111.87, -106.04, -99.64, -170.83], 0.275: [-103.61, -104.45, -125.95, -116.84, -113.73, -177.57, -120.74, -110.0, -103.75, -99.23, -141.28], 0.30000000000000004: [-107.19, -100.6, -133.89, -121.45, -114.82, -182.53, -128.72, -110.6, -108.13, -99.63, -113.02]}}\n","Untargeted: {'both': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'goal_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}, 'action_only': {0.0: [], 0.025: [], 0.05: [], 0.07500000000000001: [], 0.1: [], 0.125: [], 0.15000000000000002: [], 0.17500000000000002: [], 0.2: [], 0.225: [], 0.25: [], 0.275: [], 0.30000000000000004: []}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pUQHmv4-U8w9"},"source":[""],"execution_count":null,"outputs":[]}]}