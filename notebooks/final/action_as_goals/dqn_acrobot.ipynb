{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"dqn_acrobot.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QM04UTO98Nf2","executionInfo":{"status":"ok","timestamp":1609066953672,"user_tz":-60,"elapsed":41247,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"1678cf20-b939-4041-b0a8-683136556fb8"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive/')\r\n","\r\n","#!cp \"/content/drive/My Drive/Dissertation/preprocessing.py\" .\r\n","#!cp -r \"/content/drive/My Drive/Dissertation/gym_maze\" .\r\n","#!cp -r \"/content/drive/My Drive/Dissertation/envs\" ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ByGS3LUsPTHV"},"source":["# for inference, not continued training\r\n","def save_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","\r\n","    torch.save({\r\n","      'controller': model.state_dict(),\r\n","    }, path)\r\n","\r\n","import copy\r\n","def load_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.load_state_dict(checkpoint['controller'], strict = False)\r\n","    #model.target.load_state_dict(model.state_dict(), strict = False)\r\n","\r\n","    model.eval()\r\n","    #model.target.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSK59293xw7G"},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVZc8qYdxw7j"},"source":["env = gym.make('Acrobot-v1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Da5BnH6Nxw7m"},"source":["---\n","### Helper functions"]},{"cell_type":"code","metadata":{"id":"4ZPbVNbIxw7o"},"source":["def plot_durations(episode_durations):\n","    fig, axs = plt.subplots(2, figsize=(10,10))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    axs[1].set_xlabel('Episode')\n","    axs[1].set_ylabel('State Visits')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cn-NnuV8xw7q"},"source":["---\n","### Code"]},{"cell_type":"code","metadata":{"id":"ciaEwZa9xw7s"},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFx-wY0xxw7w"},"source":["def plot_norms(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\n","    \n","    plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","    plt.xlabel('L2 Norm')\n","    plt.ylabel('Average Reward')\n","    \n","    mu = np.mean(ys, axis=1)\n","    plt.plot(x / 10, mu)\n","    stds = np.std(ys, axis = 1)\n","    plt.fill_between(x / 10, mu + stds , mu - stds, alpha=0.2)\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9uURg2Wxw7z"},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","def one_hot(n, v):\n","    a = np.zeros(n)\n","    a[v] = 1.0\n","    return np.expand_dims(a, axis=0)\n","\n","def rev_one_hot(a):\n","    return np.where(a[0] > 0)[0][0]\n","\n","class DQN(nn.Module):\n","    def __init__(self, inputs, outputs, mem_len = 2000000):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(inputs, 256)\n","        self.fc2 = nn.Linear(256, 256)\n","        self.head = nn.Linear(256, outputs)\n","        \n","        self.memory = ReplayMemory(mem_len)\n","        self.optimizer = None\n","        self.target = None # to keep parameters frozen while propogating losses\n","        \n","        self.n_actions = outputs\n","        self.steps_done = 0\n","        \n","        self.EPS_START = 1.0\n","        self.EPS_END = 0.1\n","        self.EPS_DECAY = 10000 # in number of steps\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.head(x)\n","    \n","    def act(self, state, is_training):\n","        if is_training:\n","            eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * (1. - min(1., self.steps_done / self.EPS_DECAY))\n","            self.steps_done += 1\n","\n","            # With probability eps select a random action\n","            if random.random() < eps_threshold:\n","                return torch.tensor([[random.randrange(self.n_actions)]], device=device, dtype=torch.long)\n","\n","        # otherwise select action = maxa Q∗(φ(st), a; θ)\n","        with torch.no_grad():\n","            return self(state).max(1)[1].view(1, 1)\n","    \n","    def experience_replay(self):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","        \n","        current_Q_values = self(state_batch).gather(1, action_batch)\n","        # Compute next Q value based on which goal gives max Q values\n","        # Detach variable from the current graph since we don't want gradients for next Q to propagated\n","        next_max_q = self.target(next_state_batch).detach().max(1)[0]\n","        next_Q_values = not_done_mask * next_max_q\n","        # Compute the target of the current Q values\n","        target_Q_values = reward_batch + (GAMMA * next_Q_values)\n","        # Compute Bellman error (using Huber loss)\n","        loss = F.smooth_l1_loss(current_Q_values, target_Q_values.unsqueeze(1))\n","        \n","        # Optimize the model\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        for param in self.parameters():\n","            if param.grad is not None:\n","                param.grad.data.clamp_(-1, 1)\n","        self.optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBXS1kPFxw72"},"source":["SAVE_OFFSET = 0\n","\n","def train_model():\n","    global SAVE_OFFSET\n","    # Get number of actions and observations from gym action space\n","    n_actions = env.action_space.n\n","    n_observations = env.observation_space.shape[0]\n","\n","    # Initialize action-value function Q with random weights\n","    dqnAgent = DQN(n_observations, n_actions).to(device)\n","    dqnAgent.target = DQN(n_observations, n_actions).to(device)\n","\n","    # Optimizer\n","    learning_rate = 2.5e-4\n","    dqnAgent.optimizer = optim.RMSprop(dqnAgent.parameters(), lr=learning_rate)\n","\n","    num_episodes = 2000 # M\n","    episode_durations = []\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        # unsqueeze adds batch dimension\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        overall_reward = 0\n","        done = False\n","        while not done:\n","            # Execute action a_t in emulator and observe reward r_t and image x_{t+1}\n","            action = dqnAgent.act(state, True)\n","            observation, reward, done, _ = env.step(action.item())\n","            extrinsic_reward = torch.tensor([reward], device=device)\n","\n","            overall_reward += reward\n","\n","            # preprocess φ_{t+1} = φ(s_{t+1})\n","            next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            # Store transition (φt, at, rt, φt+1) in D\n","            dqnAgent.memory.store(state, action, next_state, extrinsic_reward, done)\n","\n","            state = next_state\n","\n","            dqnAgent.experience_replay()\n","\n","        # very needed! see https://stackoverflow.com/a/58730298\n","        if i_episode % 10 == 0:\n","            dqnAgent.target.load_state_dict(dqnAgent.state_dict(), strict = False)\n","\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations)\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 200 == 0:\n","                print(f\"Episode {i_episode}: {np.mean(dur[-100:])}\")\n","            if np.mean(dur[-100:]) >= -90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(dqnAgent, f\"dqn_acrobot_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return dqnAgent\n","\n","    return None # did not solve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBm0cEojxw74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608571833190,"user_tz":-60,"elapsed":629352,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"6b511b73-693f-45fa-ca89-68f7d0148112"},"source":["#dqnAgent = train_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Episode 200: -231.24\n","Episode 400: -273.49\n","Episode 600: -148.46\n","Episode 800: -110.47\n","Episode 1000: -90.59\n","Solved after 1004 episodes!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BqX6tuAqImdv"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device)\r\n","def eval_model(dqnAgent, episode_durations):\r\n","    dqnAgent.eval()\r\n","\r\n","    max_episode_length = 500\r\n","    num_episodes = 100\r\n","\r\n","    for noise in np.arange(0,0.31,0.03):\r\n","        overall_reward = 0\r\n","\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                state = state + state_max * torch.FloatTensor(state.shape).uniform_(-noise/2, noise/2).to(device)\r\n","                state = state.float()\r\n","\r\n","                action = dqnAgent.act(state, False)\r\n","                observation, reward, done, _ = env.step(action.item())\r\n","                overall_reward += reward\r\n","\r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                episode_steps += 1\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[noise].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bf6db-jkRN37"},"source":["state_min = torch.from_numpy(env.observation_space.low).to(device)\r\n","def fgsm_attack(data, eps, data_grad):\r\n","    sign_data_grad = data_grad.sign()\r\n","\r\n","    perturbed_data = data + eps * sign_data_grad * state_max\r\n","\r\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\r\n","\r\n","    return clipped_perturbed_data\r\n","\r\n","def fgsm_action(state, agent, eps, target, targetted):\r\n","    #state = torch.tensor(state, requires_grad=True)\r\n","    state_var = state.clone().detach().requires_grad_(True)\r\n","    \r\n","    # initial forward pass\r\n","    action = agent(state_var)\r\n","    #action = temp.max(1)[1].view(1, 1).float()\r\n","\r\n","    if targetted:\r\n","        loss = F.smooth_l1_loss(action, target)\r\n","    else:\r\n","        pass\r\n","        #loss = F.smooth_l1_loss(action, temp.min(1)[1].view(1, 1).float())\r\n","\r\n","    agent.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = state_var.grad.data\r\n","    # perturb state\r\n","    state_p = fgsm_attack(state, eps, data_grad)\r\n","\r\n","    return agent.act(state_p, False)\r\n","\r\n","def apply_fgsm(agent, episode_durations, targetted):\r\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0, 0.0]], device=device, dtype=torch.float)\r\n","\r\n","    agent.eval()\r\n","\r\n","    max_episode_length = 500\r\n","\r\n","    num_episodes = 100\r\n","\r\n","    for eps in np.arange(0.0, 0.031, 0.0025):\r\n","\r\n","        overall_reward = 0\r\n","\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                action = fgsm_action(state, agent, eps, TARGET_ACTION, targetted)\r\n","                \r\n","                observation, reward, done, _ = env.step(action.item())\r\n","                overall_reward += reward\r\n","\r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                episode_steps += 1\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSbv6a7i1Y8-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609069675724,"user_tz":-60,"elapsed":2632515,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"0de9adbd-b266-4f78-b238-49265b5f5ec4"},"source":["fgsm_t = {}\r\n","for eps in np.arange(0.0, 0.031, 0.0025):\r\n","    fgsm_t[eps] = []\r\n","\r\n","same_noise = {}\r\n","for l2norm in np.arange(0,0.31,0.03):\r\n","    same_noise[l2norm] = []\r\n","\r\n","n_actions = env.action_space.n\r\n","n_observations = env.observation_space.shape[0]\r\n","\r\n","i = 0\r\n","while i < 10:\r\n","    agent = DQN(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"dqn_acrobot_{i}\")\r\n","\r\n","    eval_model(agent, same_noise)\r\n","    apply_fgsm(agent, fgsm_t, True)\r\n","\r\n","    print(i)\r\n","    print(f\"Noise: {same_noise}\")\r\n","    print(f\"Targeted FGSM: {fgsm_t}\")\r\n","    i += 1\r\n","\r\n","print(f\"Noise: {same_noise}\")\r\n","print(f\"Targeted FGSM: {fgsm_t}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","Noise: {0.0: [-80.48], 0.03: [-80.84], 0.06: [-80.58], 0.09: [-84.83], 0.12: [-89.87], 0.15: [-93.46], 0.18: [-97.34], 0.21: [-105.35], 0.24: [-109.4], 0.27: [-123.85], 0.3: [-134.67]}\n","Targeted FGSM: {0.0: [-82.98], 0.0025: [-79.96], 0.005: [-79.57], 0.0075: [-80.12], 0.01: [-77.61], 0.0125: [-81.13], 0.015: [-82.3], 0.0175: [-81.36], 0.02: [-81.34], 0.0225: [-81.79], 0.025: [-84.09], 0.0275: [-88.92], 0.03: [-88.07]}\n","1\n","Noise: {0.0: [-80.48, -84.42], 0.03: [-80.84, -81.59], 0.06: [-80.58, -86.92], 0.09: [-84.83, -91.07], 0.12: [-89.87, -91.3], 0.15: [-93.46, -90.86], 0.18: [-97.34, -100.46], 0.21: [-105.35, -98.82], 0.24: [-109.4, -107.64], 0.27: [-123.85, -114.37], 0.3: [-134.67, -124.78]}\n","Targeted FGSM: {0.0: [-82.98, -83.27], 0.0025: [-79.96, -82.58], 0.005: [-79.57, -87.45], 0.0075: [-80.12, -83.2], 0.01: [-77.61, -90.41], 0.0125: [-81.13, -90.33], 0.015: [-82.3, -103.96], 0.0175: [-81.36, -92.7], 0.02: [-81.34, -88.32], 0.0225: [-81.79, -104.32], 0.025: [-84.09, -103.34], 0.0275: [-88.92, -122.59], 0.03: [-88.07, -141.9]}\n","2\n","Noise: {0.0: [-80.48, -84.42, -81.08], 0.03: [-80.84, -81.59, -80.45], 0.06: [-80.58, -86.92, -84.75], 0.09: [-84.83, -91.07, -83.78], 0.12: [-89.87, -91.3, -88.77], 0.15: [-93.46, -90.86, -91.64], 0.18: [-97.34, -100.46, -97.83], 0.21: [-105.35, -98.82, -104.59], 0.24: [-109.4, -107.64, -105.19], 0.27: [-123.85, -114.37, -120.62], 0.3: [-134.67, -124.78, -128.38]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62], 0.0025: [-79.96, -82.58, -79.54], 0.005: [-79.57, -87.45, -80.97], 0.0075: [-80.12, -83.2, -80.3], 0.01: [-77.61, -90.41, -79.66], 0.0125: [-81.13, -90.33, -81.39], 0.015: [-82.3, -103.96, -80.3], 0.0175: [-81.36, -92.7, -80.72], 0.02: [-81.34, -88.32, -84.7], 0.0225: [-81.79, -104.32, -84.54], 0.025: [-84.09, -103.34, -90.8], 0.0275: [-88.92, -122.59, -96.16], 0.03: [-88.07, -141.9, -97.35]}\n","3\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5], 0.03: [-80.84, -81.59, -80.45, -81.23], 0.06: [-80.58, -86.92, -84.75, -83.79], 0.09: [-84.83, -91.07, -83.78, -88.91], 0.12: [-89.87, -91.3, -88.77, -85.63], 0.15: [-93.46, -90.86, -91.64, -91.82], 0.18: [-97.34, -100.46, -97.83, -116.39], 0.21: [-105.35, -98.82, -104.59, -110.46], 0.24: [-109.4, -107.64, -105.19, -126.49], 0.27: [-123.85, -114.37, -120.62, -123.9], 0.3: [-134.67, -124.78, -128.38, -130.31]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84], 0.0025: [-79.96, -82.58, -79.54, -81.71], 0.005: [-79.57, -87.45, -80.97, -84.8], 0.0075: [-80.12, -83.2, -80.3, -82.77], 0.01: [-77.61, -90.41, -79.66, -87.95], 0.0125: [-81.13, -90.33, -81.39, -83.01], 0.015: [-82.3, -103.96, -80.3, -91.89], 0.0175: [-81.36, -92.7, -80.72, -84.93], 0.02: [-81.34, -88.32, -84.7, -83.98], 0.0225: [-81.79, -104.32, -84.54, -91.8], 0.025: [-84.09, -103.34, -90.8, -95.68], 0.0275: [-88.92, -122.59, -96.16, -106.09], 0.03: [-88.07, -141.9, -97.35, -109.13]}\n","4\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67]}\n","5\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27]}\n","6\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37, -80.68], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58, -80.96], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34, -80.86], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37, -83.41], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46, -87.24], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99, -92.84], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52, -93.49], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92, -104.8], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43, -102.33], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87, -106.2], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06, -116.63]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14, -83.11], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05, -81.2], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58, -78.84], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14, -80.09], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12, -79.92], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18, -77.64], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97, -77.85], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16, -82.91], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58, -85.52], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22, -93.84], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94, -91.86], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87, -103.85], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27, -114.88]}\n","7\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37, -80.68, -82.9], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58, -80.96, -84.04], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34, -80.86, -85.82], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37, -83.41, -88.06], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46, -87.24, -90.15], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99, -92.84, -94.7], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52, -93.49, -96.03], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92, -104.8, -107.51], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43, -102.33, -113.35], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87, -106.2, -116.31], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06, -116.63, -128.96]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14, -83.11, -88.16], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05, -81.2, -84.48], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58, -78.84, -84.13], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14, -80.09, -83.94], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12, -79.92, -84.41], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18, -77.64, -87.09], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97, -77.85, -87.9], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16, -82.91, -90.53], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58, -85.52, -91.31], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22, -93.84, -92.28], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94, -91.86, -96.19], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87, -103.85, -90.51], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27, -114.88, -92.5]}\n","8\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37, -80.68, -82.9, -89.32], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58, -80.96, -84.04, -81.61], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34, -80.86, -85.82, -82.07], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37, -83.41, -88.06, -86.46], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46, -87.24, -90.15, -93.9], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99, -92.84, -94.7, -92.68], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52, -93.49, -96.03, -101.2], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92, -104.8, -107.51, -103.36], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43, -102.33, -113.35, -105.22], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87, -106.2, -116.31, -112.27], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06, -116.63, -128.96, -127.7]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14, -83.11, -88.16, -86.98], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05, -81.2, -84.48, -90.66], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58, -78.84, -84.13, -90.32], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14, -80.09, -83.94, -88.56], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12, -79.92, -84.41, -85.08], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18, -77.64, -87.09, -85.88], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97, -77.85, -87.9, -87.18], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16, -82.91, -90.53, -88.04], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58, -85.52, -91.31, -89.6], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22, -93.84, -92.28, -101.44], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94, -91.86, -96.19, -92.51], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87, -103.85, -90.51, -89.09], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27, -114.88, -92.5, -90.58]}\n","9\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37, -80.68, -82.9, -89.32, -82.12], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58, -80.96, -84.04, -81.61, -77.97], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34, -80.86, -85.82, -82.07, -81.6], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37, -83.41, -88.06, -86.46, -86.24], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46, -87.24, -90.15, -93.9, -85.14], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99, -92.84, -94.7, -92.68, -88.24], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52, -93.49, -96.03, -101.2, -95.3], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92, -104.8, -107.51, -103.36, -97.99], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43, -102.33, -113.35, -105.22, -107.8], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87, -106.2, -116.31, -112.27, -112.39], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06, -116.63, -128.96, -127.7, -117.97]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14, -83.11, -88.16, -86.98, -83.32], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05, -81.2, -84.48, -90.66, -78.43], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58, -78.84, -84.13, -90.32, -84.06], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14, -80.09, -83.94, -88.56, -82.31], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12, -79.92, -84.41, -85.08, -80.15], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18, -77.64, -87.09, -85.88, -83.25], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97, -77.85, -87.9, -87.18, -84.39], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16, -82.91, -90.53, -88.04, -81.76], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58, -85.52, -91.31, -89.6, -85.49], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22, -93.84, -92.28, -101.44, -83.87], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94, -91.86, -96.19, -92.51, -89.39], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87, -103.85, -90.51, -89.09, -84.68], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27, -114.88, -92.5, -90.58, -101.37]}\n","Noise: {0.0: [-80.48, -84.42, -81.08, -83.5, -85.29, -78.37, -80.68, -82.9, -89.32, -82.12], 0.03: [-80.84, -81.59, -80.45, -81.23, -80.42, -79.58, -80.96, -84.04, -81.61, -77.97], 0.06: [-80.58, -86.92, -84.75, -83.79, -82.66, -82.34, -80.86, -85.82, -82.07, -81.6], 0.09: [-84.83, -91.07, -83.78, -88.91, -83.04, -86.37, -83.41, -88.06, -86.46, -86.24], 0.12: [-89.87, -91.3, -88.77, -85.63, -86.43, -90.46, -87.24, -90.15, -93.9, -85.14], 0.15: [-93.46, -90.86, -91.64, -91.82, -90.33, -89.99, -92.84, -94.7, -92.68, -88.24], 0.18: [-97.34, -100.46, -97.83, -116.39, -97.82, -98.52, -93.49, -96.03, -101.2, -95.3], 0.21: [-105.35, -98.82, -104.59, -110.46, -100.84, -105.92, -104.8, -107.51, -103.36, -97.99], 0.24: [-109.4, -107.64, -105.19, -126.49, -101.45, -110.43, -102.33, -113.35, -105.22, -107.8], 0.27: [-123.85, -114.37, -120.62, -123.9, -114.27, -118.87, -106.2, -116.31, -112.27, -112.39], 0.3: [-134.67, -124.78, -128.38, -130.31, -121.91, -129.06, -116.63, -128.96, -127.7, -117.97]}\n","Targeted FGSM: {0.0: [-82.98, -83.27, -78.62, -81.84, -81.33, -78.14, -83.11, -88.16, -86.98, -83.32], 0.0025: [-79.96, -82.58, -79.54, -81.71, -83.6, -77.05, -81.2, -84.48, -90.66, -78.43], 0.005: [-79.57, -87.45, -80.97, -84.8, -89.62, -79.58, -78.84, -84.13, -90.32, -84.06], 0.0075: [-80.12, -83.2, -80.3, -82.77, -82.38, -82.14, -80.09, -83.94, -88.56, -82.31], 0.01: [-77.61, -90.41, -79.66, -87.95, -81.48, -84.12, -79.92, -84.41, -85.08, -80.15], 0.0125: [-81.13, -90.33, -81.39, -83.01, -81.76, -85.18, -77.64, -87.09, -85.88, -83.25], 0.015: [-82.3, -103.96, -80.3, -91.89, -83.91, -82.97, -77.85, -87.9, -87.18, -84.39], 0.0175: [-81.36, -92.7, -80.72, -84.93, -81.36, -88.16, -82.91, -90.53, -88.04, -81.76], 0.02: [-81.34, -88.32, -84.7, -83.98, -81.71, -90.58, -85.52, -91.31, -89.6, -85.49], 0.0225: [-81.79, -104.32, -84.54, -91.8, -82.28, -90.22, -93.84, -92.28, -101.44, -83.87], 0.025: [-84.09, -103.34, -90.8, -95.68, -86.8, -92.94, -91.86, -96.19, -92.51, -89.39], 0.0275: [-88.92, -122.59, -96.16, -106.09, -100.4, -96.87, -103.85, -90.51, -89.09, -84.68], 0.03: [-88.07, -141.9, -97.35, -109.13, -100.67, -112.27, -114.88, -92.5, -90.58, -101.37]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iX8D_vZUInmr","executionInfo":{"status":"ok","timestamp":1609062809068,"user_tz":-60,"elapsed":6842597,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"88665f87-fbc4-4a45-f539-dd084b1ce304"},"source":["same_noise = {}\r\n","for l2norm in np.arange(0,0.31,0.03):\r\n","    same_noise[l2norm] = []\r\n","\r\n","# train 10 models, then eval them\r\n","i = 0\r\n","while i < 10:\r\n","    agent = train_model()\r\n","    if agent is not None:\r\n","        # goal_attack, action_attack, same_noise\r\n","        eval_model(agent, same_noise)\r\n","        print(f\"{i} {same_noise}\")\r\n","        i += 1\r\n","\r\n","print(same_noise)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Episode 200: -275.46\n","Episode 400: -311.74\n","Episode 600: -158.6\n","Episode 800: -94.45\n","Episode 1000: -91.34\n","Solved after 1055 episodes!\n","0 {0.0: [-81.59], 0.03: [-80.63], 0.06: [-81.6], 0.09: [-84.59], 0.12: [-91.8], 0.15: [-91.29], 0.18: [-97.47], 0.21: [-107.19], 0.24: [-115.91], 0.27: [-120.63], 0.3: [-131.92]}\n","Episode 200: -208.29\n","Episode 400: -345.39\n","Episode 600: -137.59\n","Episode 800: -91.0\n","Solved after 918 episodes!\n","1 {0.0: [-81.59, -84.66], 0.03: [-80.63, -82.78], 0.06: [-81.6, -79.71], 0.09: [-84.59, -85.32], 0.12: [-91.8, -93.77], 0.15: [-91.29, -92.61], 0.18: [-97.47, -99.27], 0.21: [-107.19, -106.66], 0.24: [-115.91, -107.8], 0.27: [-120.63, -116.09], 0.3: [-131.92, -123.55]}\n","Episode 200: -201.93\n","Episode 400: -279.17\n","Episode 600: -290.21\n","Episode 800: -113.58\n","Solved after 952 episodes!\n","2 {0.0: [-81.59, -84.66, -80.69], 0.03: [-80.63, -82.78, -81.83], 0.06: [-81.6, -79.71, -85.09], 0.09: [-84.59, -85.32, -84.94], 0.12: [-91.8, -93.77, -87.92], 0.15: [-91.29, -92.61, -94.6], 0.18: [-97.47, -99.27, -93.95], 0.21: [-107.19, -106.66, -100.82], 0.24: [-115.91, -107.8, -111.06], 0.27: [-120.63, -116.09, -116.33], 0.3: [-131.92, -123.55, -129.35]}\n","Episode 200: -310.65\n","Episode 400: -202.38\n","Episode 600: -276.03\n","Episode 800: -104.48\n","Episode 1000: -94.19\n","Solved after 1110 episodes!\n","3 {0.0: [-81.59, -84.66, -80.69, -80.77], 0.03: [-80.63, -82.78, -81.83, -81.77], 0.06: [-81.6, -79.71, -85.09, -85.02], 0.09: [-84.59, -85.32, -84.94, -86.79], 0.12: [-91.8, -93.77, -87.92, -93.06], 0.15: [-91.29, -92.61, -94.6, -94.6], 0.18: [-97.47, -99.27, -93.95, -98.58], 0.21: [-107.19, -106.66, -100.82, -102.38], 0.24: [-115.91, -107.8, -111.06, -112.96], 0.27: [-120.63, -116.09, -116.33, -115.84], 0.3: [-131.92, -123.55, -129.35, -132.11]}\n","Episode 200: -270.1\n","Episode 400: -167.12\n","Episode 600: -144.1\n","Episode 800: -99.74\n","Solved after 945 episodes!\n","4 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65]}\n","Episode 200: -319.82\n","Episode 400: -211.99\n","Episode 600: -231.87\n","Episode 800: -98.56\n","Episode 1000: -90.71\n","Solved after 1004 episodes!\n","5 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12]}\n","Episode 200: -190.6\n","Episode 400: -346.68\n","Episode 600: -156.26\n","Episode 800: -109.05\n","Episode 1000: -91.43\n","Solved after 1030 episodes!\n","6 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02, -84.02], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1, -78.49], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52, -82.82], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36, -83.23], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73, -83.73], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61, -91.18], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99, -95.05], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95, -99.13], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31, -105.43], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61, -111.61], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12, -114.85]}\n","Episode 200: -303.01\n","Episode 400: -341.09\n","Episode 600: -130.01\n","Episode 800: -95.19\n","Solved after 850 episodes!\n","7 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02, -84.02, -89.32], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1, -78.49, -85.61], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52, -82.82, -85.36], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36, -83.23, -85.73], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73, -83.73, -95.75], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61, -91.18, -94.22], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99, -95.05, -97.97], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95, -99.13, -101.53], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31, -105.43, -110.72], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61, -111.61, -122.66], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12, -114.85, -121.81]}\n","Episode 200: -380.65\n","Episode 400: -257.14\n","Episode 600: -136.24\n","Episode 800: -106.09\n","Solved after 947 episodes!\n","8 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02, -84.02, -89.32, -82.87], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1, -78.49, -85.61, -83.62], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52, -82.82, -85.36, -83.85], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36, -83.23, -85.73, -87.85], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73, -83.73, -95.75, -86.49], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61, -91.18, -94.22, -93.78], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99, -95.05, -97.97, -99.44], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95, -99.13, -101.53, -102.05], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31, -105.43, -110.72, -108.91], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61, -111.61, -122.66, -112.6], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12, -114.85, -121.81, -127.86]}\n","Episode 200: -208.36\n","Episode 400: -230.14\n","Episode 600: -197.09\n","Episode 800: -95.48\n","Solved after 882 episodes!\n","9 {0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02, -84.02, -89.32, -82.87, -84.5], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1, -78.49, -85.61, -83.62, -79.55], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52, -82.82, -85.36, -83.85, -79.74], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36, -83.23, -85.73, -87.85, -89.76], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73, -83.73, -95.75, -86.49, -91.03], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61, -91.18, -94.22, -93.78, -86.29], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99, -95.05, -97.97, -99.44, -92.89], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95, -99.13, -101.53, -102.05, -97.46], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31, -105.43, -110.72, -108.91, -104.48], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61, -111.61, -122.66, -112.6, -113.61], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12, -114.85, -121.81, -127.86, -119.73]}\n","{0.0: [-81.59, -84.66, -80.69, -80.77, -84.54, -78.02, -84.02, -89.32, -82.87, -84.5], 0.03: [-80.63, -82.78, -81.83, -81.77, -81.44, -79.1, -78.49, -85.61, -83.62, -79.55], 0.06: [-81.6, -79.71, -85.09, -85.02, -81.01, -81.52, -82.82, -85.36, -83.85, -79.74], 0.09: [-84.59, -85.32, -84.94, -86.79, -82.86, -84.36, -83.23, -85.73, -87.85, -89.76], 0.12: [-91.8, -93.77, -87.92, -93.06, -87.39, -88.73, -83.73, -95.75, -86.49, -91.03], 0.15: [-91.29, -92.61, -94.6, -94.6, -92.15, -92.61, -91.18, -94.22, -93.78, -86.29], 0.18: [-97.47, -99.27, -93.95, -98.58, -97.37, -99.99, -95.05, -97.97, -99.44, -92.89], 0.21: [-107.19, -106.66, -100.82, -102.38, -102.29, -102.95, -99.13, -101.53, -102.05, -97.46], 0.24: [-115.91, -107.8, -111.06, -112.96, -104.74, -112.31, -105.43, -110.72, -108.91, -104.48], 0.27: [-120.63, -116.09, -116.33, -115.84, -112.89, -120.61, -111.61, -122.66, -112.6, -113.61], 0.3: [-131.92, -123.55, -129.35, -132.11, -123.65, -129.12, -114.85, -121.81, -127.86, -119.73]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uJ5Hkg6ZEKS"},"source":[""],"execution_count":null,"outputs":[]}]}