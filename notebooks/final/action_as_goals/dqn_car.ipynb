{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"dqn_car.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOxP3TBlPU--","executionInfo":{"status":"ok","timestamp":1608890430545,"user_tz":-60,"elapsed":33506,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"8eec7ffd-778b-4959-893f-8e155887d815"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive/')\r\n","\r\n","#!cp \"/content/drive/My Drive/Dissertation/preprocessing.py\" .\r\n","#!cp -r \"/content/drive/My Drive/Dissertation/gym_maze\" .\r\n","#!cp -r \"/content/drive/My Drive/Dissertation/envs\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ByGS3LUsPTHV","executionInfo":{"status":"ok","timestamp":1608891720181,"user_tz":-60,"elapsed":569,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["# for inference, not continued training\r\n","def save_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","\r\n","    torch.save({\r\n","      'controller': model.state_dict(),\r\n","    }, path)\r\n","\r\n","import copy\r\n","def load_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.load_state_dict(checkpoint['controller'], strict = False)\r\n","    #model.target.load_state_dict(model.state_dict(), strict = False)\r\n","\r\n","    model.eval()\r\n","    #model.target.eval()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSK59293xw7G","executionInfo":{"status":"ok","timestamp":1608890437693,"user_tz":-60,"elapsed":8065,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVZc8qYdxw7j","executionInfo":{"status":"ok","timestamp":1608890437703,"user_tz":-60,"elapsed":6823,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["env = gym.make('MountainCar-v0')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Da5BnH6Nxw7m"},"source":["---\n","### Helper functions"]},{"cell_type":"code","metadata":{"id":"4ZPbVNbIxw7o","executionInfo":{"status":"ok","timestamp":1608890438773,"user_tz":-60,"elapsed":1053,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["def plot_durations(episode_durations, state_visits):\n","    fig, axs = plt.subplots(2, figsize=(10,10))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    visits_t = [(x[0], torch.tensor(x[1], dtype=torch.float)) for x in state_visits.items()]\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    axs[1].set_xlabel('Episode')\n","    axs[1].set_ylabel('State Visits')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cn-NnuV8xw7q"},"source":["---\n","### Code"]},{"cell_type":"code","metadata":{"id":"ciaEwZa9xw7s","executionInfo":{"status":"ok","timestamp":1608890438780,"user_tz":-60,"elapsed":1038,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFx-wY0xxw7w","executionInfo":{"status":"ok","timestamp":1608890438783,"user_tz":-60,"elapsed":1024,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["def plot_norms(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\n","    \n","    plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","    plt.xlabel('L2 Norm')\n","    plt.ylabel('Average Reward')\n","    \n","    mu = np.mean(ys, axis=1)\n","    plt.plot(x / 10, mu)\n","    stds = np.std(ys, axis = 1)\n","    plt.fill_between(x / 10, mu + stds , mu - stds, alpha=0.2)\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9uURg2Wxw7z","executionInfo":{"status":"ok","timestamp":1608890949971,"user_tz":-60,"elapsed":588,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","def one_hot(n, v):\n","    a = np.zeros(n)\n","    a[v] = 1.0\n","    return np.expand_dims(a, axis=0)\n","\n","def rev_one_hot(a):\n","    return np.where(a[0] > 0)[0][0]\n","\n","class DQN(nn.Module):\n","    def __init__(self, inputs, outputs, mem_len = 2000000):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(inputs, 256)\n","        self.fc2 = nn.Linear(256, 256)\n","        self.head = nn.Linear(256, outputs)\n","        \n","        self.memory = ReplayMemory(mem_len)\n","        self.optimizer = None\n","        self.target = None # to keep parameters frozen while propogating losses\n","        \n","        self.n_actions = outputs\n","        self.steps_done = 0\n","        \n","        self.EPS_START = 1.0\n","        self.EPS_END = 0.0\n","        self.EPS_DECAY = 50000 # in number of steps\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.head(x)\n","    \n","    def act(self, state, is_training):\n","        if is_training:\n","            eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * (1. - min(1., self.steps_done / self.EPS_DECAY))\n","            self.steps_done += 1\n","\n","            # With probability eps select a random action\n","            if random.random() < eps_threshold:\n","                return torch.tensor([[random.randrange(self.n_actions)]], device=device, dtype=torch.long)\n","\n","        # otherwise select action = maxa Q∗(φ(st), a; θ)\n","        with torch.no_grad():\n","            return self(state).max(1)[1].view(1, 1)\n","    \n","    def experience_replay(self):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","        \n","        current_Q_values = self(state_batch).gather(1, action_batch)\n","        # Compute next Q value based on which goal gives max Q values\n","        # Detach variable from the current graph since we don't want gradients for next Q to propagated\n","        next_max_q = self.target(next_state_batch).detach().max(1)[0]\n","        next_Q_values = not_done_mask * next_max_q\n","        # Compute the target of the current Q values\n","        target_Q_values = reward_batch + (GAMMA * next_Q_values)\n","        # Compute Bellman error (using Huber loss)\n","        loss = F.smooth_l1_loss(current_Q_values, target_Q_values.unsqueeze(1))\n","        \n","        # Optimize the model\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        for param in self.parameters():\n","            if param.grad is not None:\n","                param.grad.data.clamp_(-1, 1)\n","        self.optimizer.step()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBXS1kPFxw72"},"source":["import time\n","SAVE_OFFSET = 0\n","\n","def train_model():\n","    global SAVE_OFFSET\n","\n","    # Get number of actions and observations from gym action space\n","    n_actions = env.action_space.n\n","    n_observations = env.observation_space.shape[0]\n","\n","    # Initialize action-value function Q with random weights\n","    dqnAgent = DQN(n_observations, n_actions).to(device)\n","    dqnAgent.target = DQN(n_observations, n_actions).to(device)\n","\n","    # Optimizer\n","    learning_rate = 2.5e-4\n","    dqnAgent.optimizer = optim.RMSprop(dqnAgent.parameters(), lr=learning_rate)\n","\n","    num_episodes = 4000 # M\n","    episode_durations = []\n","    state_visits = {0: [], 1: []}\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        # unsqueeze adds batch dimension\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        overall_reward = 0\n","        ep_state_visits = {0: 0, 1: 0}\n","        done = False\n","        while not done:\n","            # Execute action a_t in emulator and observe reward r_t and image x_{t+1}\n","            action = dqnAgent.act(state, True)\n","            observation, reward, done, _ = env.step(action.item())\n","            extrinsic_reward = torch.tensor([reward], device=device)\n","\n","            overall_reward += reward\n","\n","            # preprocess φ_{t+1} = φ(s_{t+1})\n","            next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            # Store transition (φt, at, rt, φt+1) in D\n","            dqnAgent.memory.store(state, action, next_state, extrinsic_reward, done)\n","\n","            state = next_state\n","\n","            dqnAgent.experience_replay()\n","\n","        # very needed! see https://stackoverflow.com/a/58730298\n","        if i_episode % 20 == 0:\n","            dqnAgent.target.load_state_dict(dqnAgent.state_dict(), strict = False)\n","\n","        episode_durations.append((i_episode, overall_reward))\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if np.mean(dur[-100:]) >= -110:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(dqnAgent, f\"dqn_car_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return dqnAgent\n","\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBm0cEojxw74"},"source":["#dqnAgent = train_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex6nCRTIDyWY","executionInfo":{"status":"ok","timestamp":1608890854494,"user_tz":-60,"elapsed":10986,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device)\n","def eval_model(dqnAgent, episode_durations):\n","    dqnAgent.eval()\n","\n","    max_episode_length = 200\n","    num_episodes = 100\n","\n","    for noise in np.arange(0,1.001,0.1):\n","        overall_reward = 0\n","\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","            # unsqueeze adds batch dimension\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                state = state + state_max * torch.FloatTensor(state.shape).uniform_(-noise/2, noise/2).to(device)\n","                state = state.float()\n","\n","                action = dqnAgent.act(state, False)\n","                observation, reward, done, _ = env.step(action.item())\n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_durations[noise].append(overall_reward / num_episodes)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"bf6db-jkRN37","executionInfo":{"status":"ok","timestamp":1608891912422,"user_tz":-60,"elapsed":1181,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["state_min = torch.from_numpy(env.observation_space.low).to(device)\r\n","def fgsm_attack(data, eps, data_grad):\r\n","    sign_data_grad = data_grad.sign()\r\n","\r\n","    perturbed_data = data + eps * sign_data_grad * state_max\r\n","\r\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\r\n","\r\n","    return clipped_perturbed_data\r\n","\r\n","def fgsm_action(state, agent, eps, target, targetted):\r\n","    #state = torch.tensor(state, requires_grad=True)\r\n","    state_var = state.clone().detach().requires_grad_(True)\r\n","    \r\n","    # initial forward pass\r\n","    action = agent(state_var)\r\n","    #action = temp.max(1)[1].view(1, 1).float()\r\n","\r\n","    if targetted:\r\n","        loss = F.smooth_l1_loss(action, target)\r\n","    else:\r\n","        pass\r\n","        #loss = F.smooth_l1_loss(action, temp.min(1)[1].view(1, 1).float())\r\n","\r\n","    agent.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = state_var.grad.data\r\n","    # perturb state\r\n","    state_p = fgsm_attack(state, eps, data_grad)\r\n","\r\n","    return agent.act(state_p, False)\r\n","\r\n","def apply_fgsm(agent, episode_durations, targetted):\r\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0, 0.0]], device=device, dtype=torch.float)\r\n","\r\n","    agent.eval()\r\n","\r\n","    max_episode_length = 200\r\n","\r\n","    num_episodes = 100\r\n","\r\n","    for eps in np.arange(0.0, 0.31, 0.025):\r\n","\r\n","        overall_reward = 0\r\n","\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                action = fgsm_action(state, agent, eps, TARGET_ACTION, targetted)\r\n","                \r\n","                observation, reward, done, _ = env.step(action.item())\r\n","                overall_reward += reward\r\n","\r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                episode_steps += 1\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Npdvn-CXP2Nx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608896181566,"user_tz":-60,"elapsed":1170523,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"8694ba35-1920-4d49-bb83-d7f25f8933cf"},"source":["noise = {}\r\n","for l2norm in np.arange(0,1.001,0.1):\r\n","    noise[l2norm] = []\r\n","targeted = {}\r\n","for eps in np.arange(0.0, 0.31, 0.025):\r\n","    targeted[eps] = []\r\n","\r\n","# train 10 models and save if fully trained\r\n","i = 0\r\n","while i < 10:\r\n","    #agent = train_model()\r\n","    n_actions = env.action_space.n\r\n","    n_observations = env.observation_space.shape[0]\r\n","\r\n","    # Initialize action-value function Q with random weights\r\n","    agent = DQN(n_observations, n_actions).to(device)\r\n","    #agent.target = DQN(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"dqn_car_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        eval_model(agent, noise)\r\n","        apply_fgsm(agent, targeted, True)\r\n","        print(i)\r\n","        print(f\"Noise: {noise}\")\r\n","        print(f\"Targeted FGSM: {targeted}\")\r\n","        i += 1\r\n","\r\n","print(f\"Noise: {noise}\")\r\n","print(f\"Targeted FGSM: {targeted}\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["0\n","Noise: {0.0: [-102.67], 0.1: [-111.7], 0.2: [-126.64], 0.30000000000000004: [-143.41], 0.4: [-159.11], 0.5: [-178.97], 0.6000000000000001: [-187.24], 0.7000000000000001: [-192.36], 0.8: [-197.76], 0.9: [-197.79], 1.0: [-200.0]}\n","Targeted FGSM: {0.0: [-104.11], 0.025: [-107.94], 0.05: [-131.53], 0.07500000000000001: [-175.02], 0.1: [-185.89], 0.125: [-187.25], 0.15000000000000002: [-195.06], 0.17500000000000002: [-200.0], 0.2: [-200.0], 0.225: [-200.0], 0.25: [-200.0], 0.275: [-200.0], 0.30000000000000004: [-200.0]}\n","1\n","Noise: {0.0: [-102.67, -121.09], 0.1: [-111.7, -122.84], 0.2: [-126.64, -129.0], 0.30000000000000004: [-143.41, -137.55], 0.4: [-159.11, -158.98], 0.5: [-178.97, -166.9], 0.6000000000000001: [-187.24, -179.61], 0.7000000000000001: [-192.36, -188.84], 0.8: [-197.76, -194.03], 0.9: [-197.79, -197.82], 1.0: [-200.0, -199.86]}\n","Targeted FGSM: {0.0: [-104.11, -124.67], 0.025: [-107.94, -125.12], 0.05: [-131.53, -133.64], 0.07500000000000001: [-175.02, -152.03], 0.1: [-185.89, -184.63], 0.125: [-187.25, -191.64], 0.15000000000000002: [-195.06, -200.0], 0.17500000000000002: [-200.0, -200.0], 0.2: [-200.0, -200.0], 0.225: [-200.0, -200.0], 0.25: [-200.0, -200.0], 0.275: [-200.0, -200.0], 0.30000000000000004: [-200.0, -200.0]}\n","2\n","Noise: {0.0: [-102.67, -121.09, -102.75], 0.1: [-111.7, -122.84, -114.14], 0.2: [-126.64, -129.0, -124.89], 0.30000000000000004: [-143.41, -137.55, -145.34], 0.4: [-159.11, -158.98, -154.66], 0.5: [-178.97, -166.9, -172.71], 0.6000000000000001: [-187.24, -179.61, -187.16], 0.7000000000000001: [-192.36, -188.84, -194.74], 0.8: [-197.76, -194.03, -197.53], 0.9: [-197.79, -197.82, -199.72], 1.0: [-200.0, -199.86, -199.73]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64], 0.025: [-107.94, -125.12, -119.55], 0.05: [-131.53, -133.64, -146.68], 0.07500000000000001: [-175.02, -152.03, -174.03], 0.1: [-185.89, -184.63, -176.51], 0.125: [-187.25, -191.64, -174.87], 0.15000000000000002: [-195.06, -200.0, -172.06], 0.17500000000000002: [-200.0, -200.0, -177.99], 0.2: [-200.0, -200.0, -182.42], 0.225: [-200.0, -200.0, -194.57], 0.25: [-200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0]}\n","3\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79], 0.1: [-111.7, -122.84, -114.14, -105.4], 0.2: [-126.64, -129.0, -124.89, -110.53], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07], 0.4: [-159.11, -158.98, -154.66, -133.85], 0.5: [-178.97, -166.9, -172.71, -166.38], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43], 0.8: [-197.76, -194.03, -197.53, -189.22], 0.9: [-197.79, -197.82, -199.72, -193.05], 1.0: [-200.0, -199.86, -199.73, -197.85]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49], 0.025: [-107.94, -125.12, -119.55, -100.24], 0.05: [-131.53, -133.64, -146.68, -114.97], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41], 0.1: [-185.89, -184.63, -176.51, -177.47], 0.125: [-187.25, -191.64, -174.87, -197.86], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76], 0.275: [-200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86]}\n","4\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0]}\n","5\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0]}\n","6\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12, -106.8], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72, -119.65], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6, -130.11], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9, -141.09], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45, -159.64], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25, -173.95], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86, -181.17], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68, -189.03], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62, -196.7], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95, -198.72], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7, -199.95]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87, -108.08], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76, -134.96], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75, -148.74], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93, -150.97], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28, -170.58], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7, -200.0], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0, -200.0]}\n","7\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12, -106.8, -104.5], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72, -119.65, -106.24], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6, -130.11, -122.1], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9, -141.09, -136.5], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45, -159.64, -150.61], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25, -173.95, -160.49], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86, -181.17, -173.62], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68, -189.03, -179.31], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62, -196.7, -189.39], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95, -198.72, -190.96], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7, -199.95, -194.58]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87, -108.08, -107.21], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76, -134.96, -113.34], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75, -148.74, -151.34], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93, -150.97, -175.19], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28, -170.58, -187.0], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7, -200.0, -188.9], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0, -200.0, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0, -200.0, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0, -200.0, -200.0]}\n","8\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12, -106.8, -104.5, -104.03], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72, -119.65, -106.24, -106.36], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6, -130.11, -122.1, -119.25], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9, -141.09, -136.5, -128.85], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45, -159.64, -150.61, -140.28], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25, -173.95, -160.49, -149.39], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86, -181.17, -173.62, -162.52], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68, -189.03, -179.31, -172.53], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62, -196.7, -189.39, -172.66], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95, -198.72, -190.96, -181.35], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7, -199.95, -194.58, -188.96]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87, -108.08, -107.21, -103.08], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76, -134.96, -113.34, -111.95], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75, -148.74, -151.34, -175.45], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93, -150.97, -175.19, -181.02], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28, -170.58, -187.0, -182.34], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7, -200.0, -188.9, -182.7], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0, -200.0, -200.0, -189.54], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0, -200.0, -200.0, -199.66], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0, -200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0, -200.0, -200.0, -200.0]}\n","9\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12, -106.8, -104.5, -104.03, -107.96], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72, -119.65, -106.24, -106.36, -121.45], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6, -130.11, -122.1, -119.25, -143.8], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9, -141.09, -136.5, -128.85, -153.48], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45, -159.64, -150.61, -140.28, -167.59], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25, -173.95, -160.49, -149.39, -175.03], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86, -181.17, -173.62, -162.52, -182.11], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68, -189.03, -179.31, -172.53, -187.66], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62, -196.7, -189.39, -172.66, -191.59], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95, -198.72, -190.96, -181.35, -194.48], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7, -199.95, -194.58, -188.96, -198.18]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87, -108.08, -107.21, -103.08, -108.37], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76, -134.96, -113.34, -111.95, -144.3], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75, -148.74, -151.34, -175.45, -182.84], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93, -150.97, -175.19, -181.02, -200.0], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28, -170.58, -187.0, -182.34, -200.0], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7, -200.0, -188.9, -182.7, -200.0], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0, -200.0, -200.0, -189.54, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0, -200.0, -200.0, -199.66, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}\n","Noise: {0.0: [-102.67, -121.09, -102.75, -100.79, -105.27, -102.12, -106.8, -104.5, -104.03, -107.96], 0.1: [-111.7, -122.84, -114.14, -105.4, -105.54, -108.72, -119.65, -106.24, -106.36, -121.45], 0.2: [-126.64, -129.0, -124.89, -110.53, -129.85, -120.6, -130.11, -122.1, -119.25, -143.8], 0.30000000000000004: [-143.41, -137.55, -145.34, -131.07, -134.89, -127.9, -141.09, -136.5, -128.85, -153.48], 0.4: [-159.11, -158.98, -154.66, -133.85, -148.29, -137.45, -159.64, -150.61, -140.28, -167.59], 0.5: [-178.97, -166.9, -172.71, -166.38, -173.7, -152.25, -173.95, -160.49, -149.39, -175.03], 0.6000000000000001: [-187.24, -179.61, -187.16, -176.71, -184.4, -163.86, -181.17, -173.62, -162.52, -182.11], 0.7000000000000001: [-192.36, -188.84, -194.74, -181.43, -197.14, -170.68, -189.03, -179.31, -172.53, -187.66], 0.8: [-197.76, -194.03, -197.53, -189.22, -199.35, -178.62, -196.7, -189.39, -172.66, -191.59], 0.9: [-197.79, -197.82, -199.72, -193.05, -199.64, -187.95, -198.72, -190.96, -181.35, -194.48], 1.0: [-200.0, -199.86, -199.73, -197.85, -200.0, -188.7, -199.95, -194.58, -188.96, -198.18]}\n","Targeted FGSM: {0.0: [-104.11, -124.67, -102.64, -102.49, -104.6, -101.87, -108.08, -107.21, -103.08, -108.37], 0.025: [-107.94, -125.12, -119.55, -100.24, -116.46, -131.76, -134.96, -113.34, -111.95, -144.3], 0.05: [-131.53, -133.64, -146.68, -114.97, -159.9, -155.75, -148.74, -151.34, -175.45, -182.84], 0.07500000000000001: [-175.02, -152.03, -174.03, -160.41, -176.16, -187.93, -150.97, -175.19, -181.02, -200.0], 0.1: [-185.89, -184.63, -176.51, -177.47, -186.28, -194.28, -170.58, -187.0, -182.34, -200.0], 0.125: [-187.25, -191.64, -174.87, -197.86, -200.0, -199.7, -200.0, -188.9, -182.7, -200.0], 0.15000000000000002: [-195.06, -200.0, -172.06, -199.96, -200.0, -200.0, -200.0, -200.0, -189.54, -200.0], 0.17500000000000002: [-200.0, -200.0, -177.99, -200.0, -200.0, -200.0, -200.0, -200.0, -199.66, -200.0], 0.2: [-200.0, -200.0, -182.42, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.225: [-200.0, -200.0, -194.57, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.25: [-200.0, -200.0, -200.0, -199.76, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.275: [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0], 0.30000000000000004: [-200.0, -200.0, -200.0, -199.86, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T-_kgJzBQYOp"},"source":[""],"execution_count":null,"outputs":[]}]}