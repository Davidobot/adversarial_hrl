{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"td3_pointmaze.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QM04UTO98Nf2","executionInfo":{"status":"ok","timestamp":1612799489676,"user_tz":-60,"elapsed":53548,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"9196a1b9-3695-4271-edad-c973f36127bb"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive/')\r\n","\r\n","!cp \"/content/drive/My Drive/Dissertation/envs/point_maze.py\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4bwBIEXm8gt7","executionInfo":{"status":"ok","timestamp":1612799622965,"user_tz":-60,"elapsed":1521,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["# for inference, not continued training\r\n","def save_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_maze_time/{name}\" \r\n","\r\n","    torch.save({\r\n","      'controller': {\r\n","          'critic': model.critic.state_dict(),\r\n","          'actor': model.actor.state_dict(),\r\n","      }\r\n","    }, path)\r\n","\r\n","import copy\r\n","def load_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_maze_time/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.critic.load_state_dict(checkpoint['controller']['critic'])\r\n","    model.critic_target = copy.deepcopy(model.critic)\r\n","    \r\n","    model.actor.load_state_dict(checkpoint['controller']['actor'])\r\n","    model.actor_target = copy.deepcopy(model.actor)\r\n","\r\n","    model.eval()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1612799626906,"user_tz":-60,"elapsed":5089,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1612799626908,"user_tz":-60,"elapsed":4689,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1612799626910,"user_tz":-60,"elapsed":4306,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["from point_maze import PointMazeEnv \r\n","env = NormalizedEnv(PointMazeEnv(4))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"DQtcj2j8Erv4","executionInfo":{"status":"ok","timestamp":1612799626921,"user_tz":-60,"elapsed":3338,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["def plot_durations(episode_durations, actions):\n","    fig, axs = plt.subplots(2, figsize=(10,10))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","\n","    durations_t, durations = list(map(list, zip(*actions)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    axs[1].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1612799626924,"user_tz":-60,"elapsed":2887,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1612799626934,"user_tz":-60,"elapsed":2589,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1612799626936,"user_tz":-60,"elapsed":2174,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1612799626939,"user_tz":-60,"elapsed":1150,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, 128)\n","        self.fc2 = nn.Linear(128, 128)\n","        self.head = nn.Linear(128, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, 128)\n","        self.l2 = nn.Linear(128, 128)\n","        self.l3 = nn.Linear(128, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, 128)\n","        self.l5 = nn.Linear(128, 128)\n","        self.l6 = nn.Linear(128, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1612799627241,"user_tz":-60,"elapsed":1040,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000)\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 50000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            \n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, self.tau)\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup, decay_epsilon):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,1)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI","executionInfo":{"status":"ok","timestamp":1612799627245,"user_tz":-60,"elapsed":552,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["import time\n","SAVE_OFFSET = 10\n","\n","def train_model():\n","    global SAVE_OFFSET\n","\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = TD3(n_observations, n_actions).to(device)\n","    \n","    max_episode_length = 500\n","    \n","    agent.is_training = True\n","    episode_reward = 0.\n","    observation = None\n","    \n","    warmup = 100\n","    num_episodes = 3000 # M\n","    episode_durations = []\n","    actions = [(0,0)]\n","\n","    steps = 0\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        episode_steps = 0\n","        done = False\n","        while not done:        \n","            # agent pick action ...\n","            action = agent.select_action(state, i_episode <= warmup, True)\n","\n","            # env response with next_observation, reward, terminate_info\n","            action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","            observation, reward, done, info = env.step(action_i)\n","            steps += 1\n","\n","            #actions.append((steps, action_i[0]))\n","                \n","            if max_episode_length and episode_steps >= max_episode_length - 1:\n","                done = True\n","            episode_steps += 1 \n","                \n","            extrinsic_reward = torch.tensor([reward], device=device)\n","            \n","            overall_reward += reward\n","            \n","            next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            # agent observe and update policy\n","            agent.observe(state, action, next_state, extrinsic_reward, done)           \n","            state = next_state\n","            \n","            if i_episode > warmup:\n","                agent.update_policy()\n","\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations, actions)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0:\n","                print(f\"{i_episode}: {np.mean(dur[-100:])}\")\n","            if i_episode >= 300 and i_episode % 100 == 0 and np.mean(dur[-100:]) <= -49.0:\n","                print(f\"Unlucky after {i_episode} eps! Terminating...\")\n","                return None\n","            if np.mean(dur[-100:]) >= 90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"td3_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","    return None"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrKiOTksSvYo"},"source":["i = 17\r\n","while i < 17:\r\n","    agent = train_model()\r\n","    \r\n","    if agent is not None:\r\n","        print(i)\r\n","        i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewRAF108B9Ia"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\r\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\r\n","state_mid = (state_max + state_min) / 2.\r\n","state_range = (state_max - state_min)\r\n","def eval_model(agent, episode_durations):\r\n","    agent.eval()\r\n","    agent.is_training = False\r\n","\r\n","    max_episode_length = 500\r\n","    num_episodes = 100\r\n","\r\n","    for noise in np.arange(0,0.51,0.05):\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                state = state + state_range * torch.FloatTensor(state.shape).uniform_(-noise, noise).to(device)\r\n","                state = torch.max(torch.min(state, state_max), state_min).float()\r\n","\r\n","                action = agent.select_action(state, False, False)\r\n","                action_i = action.detach().cpu().squeeze(0).numpy()\r\n","\r\n","                observation, reward, done, info = env.step(action_i) \r\n","                \r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                \r\n","                episode_steps += 1 \r\n","\r\n","                overall_reward += reward\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[np.round(noise, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgdtuIjSK-Aa"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\r\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\r\n","state_mid = (state_max + state_min) / 2.\r\n","state_range = (state_max - state_min)\r\n","def fgsm_attack(data, eps, data_grad):\r\n","    sign_data_grad = data_grad.sign()\r\n","\r\n","    perturbed_data = data + eps * sign_data_grad * state_range\r\n","\r\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\r\n","\r\n","    return clipped_perturbed_data\r\n","\r\n","def fgsm_action(state, agent, eps, target, targeted):\r\n","    state = state.clone().detach().requires_grad_(True)\r\n","\r\n","    if targeted:\r\n","        # initial forward pass\r\n","        action = agent.actor(state)\r\n","        action = torch.clamp(action, -1., 1.)\r\n","\r\n","        loss = F.mse_loss(action, target)\r\n","    else:\r\n","        loss = agent.critic.Q1(state, agent.actor(state)).mean()\r\n","\r\n","    agent.actor.zero_grad()\r\n","    agent.critic.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = state.grad.data\r\n","    # perturb state\r\n","    state_p = fgsm_attack(state, eps, data_grad).float()\r\n","    return agent.select_action(state_p, False, False)\r\n","\r\n","def apply_fgsm(agent, episode_durations, targeted):\r\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0]], device=device, dtype=torch.float)\r\n","\r\n","    agent.eval()\r\n","\r\n","    max_episode_length = 500\r\n","    agent.is_training = False\r\n","\r\n","    num_episodes = 100\r\n","\r\n","    for eps in np.arange(0.0, 0.201, 0.02):\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                action = fgsm_action(state, agent, eps, TARGET_ACTION, targeted)\r\n","                action_i = action.detach().cpu().squeeze(0).numpy()\r\n","\r\n","                observation, reward, done, info = env.step(action_i)\r\n","                \r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                \r\n","                episode_steps += 1 \r\n","\r\n","                overall_reward += reward\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wfh59tBCA--"},"source":["def plot_norms(episode_durations):\r\n","    plt.figure(2, figsize=(10,10))\r\n","    \r\n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\r\n","    \r\n","    plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\r\n","    plt.xlabel('L2 Norm')\r\n","    plt.ylabel('Average Reward')\r\n","    \r\n","    mu = np.mean(ys, axis=1)\r\n","    plt.plot(x, mu)\r\n","    stds = np.std(ys, axis = 1)\r\n","    plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\r\n","        \r\n","    plt.pause(0.001)  # pause a bit so that plots are updated\r\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jazaVnJNErwK","executionInfo":{"status":"ok","timestamp":1611837122251,"user_tz":-60,"elapsed":9683638,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"9c53c88b-4e50-4199-f5a5-c024eee4121f"},"source":["episodes = {}\r\n","for l2norm in np.arange(0,0.51,0.05):\r\n","    episodes[np.round(l2norm, 2)] = []\r\n","\r\n","fgsm_t = {}\r\n","fgsm_ut = {}\r\n","for eps in np.arange(0.0, 0.201, 0.02):\r\n","    fgsm_t[eps] = []\r\n","    fgsm_ut[eps] = []\r\n","\r\n","n_observations = env.observation_space.shape[0]\r\n","n_actions = env.action_space.shape[0]\r\n","\r\n","i = 0\r\n","while i < 10:\r\n","    #agent = train_model()\r\n","    agent = TD3(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"td3_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        #eval_model(agent, episodes)\r\n","        #apply_fgsm(agent, fgsm_t, True)\r\n","        apply_fgsm(agent, fgsm_ut, False)\r\n","        #print(f\"{i} noise: {episodes}\")\r\n","        #print(f\"{i} fgsm (t): {fgsm_t}\")\r\n","        print(f\"{i} fgsm (ut): {fgsm_ut}\")\r\n","        i += 1\r\n","\r\n","print(\"---\")\r\n","#print(f\"noise: {episodes}\")\r\n","#print(f\"fgsm (t): {fgsm_t}\")\r\n","print(f\"fgsm (ut): {fgsm_ut}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 fgsm (ut): {0.0: [95.87099999999282], 0.02: [97.62799999999568], 0.04: [42.79100000000615], 0.06: [20.54100000001381], 0.08: [16.828000000000614], 0.1: [-31.282999999971825], 0.12: [-42.30899999997428], 0.14: [-50.00000000000659], 0.16: [-45.40499999998737], 0.18: [-45.43399999998747], 0.2: [-47.78399999999711]}\n","1 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587], 0.02: [97.62799999999568, 80.97399999998805], 0.04: [42.79100000000615, -23.00199999997912], 0.06: [20.54100000001381, -5.463000000006698], 0.08: [16.828000000000614, -21.93799999998347], 0.1: [-31.282999999971825, -1.848000000002547], 0.12: [-42.30899999997428, -7.750000000008004], 0.14: [-50.00000000000659, -26.161999999977898], 0.16: [-45.40499999998737, -17.730999999981762], 0.18: [-45.43399999998747, -33.53799999997343], 0.2: [-47.78399999999711, -18.815999999991664]}\n","2 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659]}\n","3 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659]}\n","4 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659]}\n","5 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173]}\n","6 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407, 91.98999999999171], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861, -48.54800000000039], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964, -14.392999999995578], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652, -20.6369999999792], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953, -45.86199999999051], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811, -48.58000000000051], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326, -48.60500000000149], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836, -50.00000000000659], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194, -50.00000000000659], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173, -50.00000000000659]}\n","7 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407, 91.98999999999171, 92.91099999999419], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861, -48.54800000000039, 8.99699999999714], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964, -14.392999999995578, 9.937999999997976], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652, -20.6369999999792, -23.36699999998115], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953, -45.86199999999051, -36.11999999997662], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811, -48.58000000000051, -39.04599999997061], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326, -48.60500000000149, -39.60899999996773], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836, -50.00000000000659, -43.734999999978335], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194, -50.00000000000659, -48.95400000000187], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834, -50.00000000000659, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173, -50.00000000000659, -50.00000000000659]}\n","8 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407, 91.98999999999171, 92.91099999999419, 97.70399999999532], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861, -48.54800000000039, 8.99699999999714, 88.55299999998954], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964, -14.392999999995578, 9.937999999997976, 46.295000000000236], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652, -20.6369999999792, -23.36699999998115, -32.30099999997311], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953, -45.86199999999051, -36.11999999997662, -50.00000000000659], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811, -48.58000000000051, -39.04599999997061, -47.31100000000112], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326, -48.60500000000149, -39.60899999996773, -50.00000000000659], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836, -50.00000000000659, -43.734999999978335, -50.00000000000659], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194, -50.00000000000659, -48.95400000000187, -50.00000000000659], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834, -50.00000000000659, -50.00000000000659, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173, -50.00000000000659, -50.00000000000659, -50.00000000000659]}\n","9 fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407, 91.98999999999171, 92.91099999999419, 97.70399999999532, 97.89999999999614], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861, -48.54800000000039, 8.99699999999714, 88.55299999998954, 91.51199999998843], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964, -14.392999999995578, 9.937999999997976, 46.295000000000236, 5.828999999995112], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652, -20.6369999999792, -23.36699999998115, -32.30099999997311, -17.600999999992716], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953, -45.86199999999051, -36.11999999997662, -50.00000000000659, 10.52999999999848], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811, -48.58000000000051, -39.04599999997061, -47.31100000000112, -12.969999999993547], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326, -48.60500000000149, -39.60899999996773, -50.00000000000659, -38.68499999997037], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836, -50.00000000000659, -43.734999999978335, -50.00000000000659, -48.871000000001565], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194, -50.00000000000659, -48.95400000000187, -50.00000000000659, -48.92100000000175], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834, -50.00000000000659, -50.00000000000659, -50.00000000000659, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173, -50.00000000000659, -50.00000000000659, -50.00000000000659, -48.98600000000312]}\n","---\n","fgsm (ut): {0.0: [95.87099999999282, 97.76799999999587, 92.32999999999089, 93.51799999999284, 96.21899999999297, 96.34199999999407, 91.98999999999171, 92.91099999999419, 97.70399999999532, 97.89999999999614], 0.02: [97.62799999999568, 80.97399999998805, -42.69199999997886, 28.001000000008677, 89.45899999998754, 91.68599999998861, -48.54800000000039, 8.99699999999714, 88.55299999998954, 91.51199999998843], 0.04: [42.79100000000615, -23.00199999997912, -48.96300000000645, 0.8509999999982455, 71.38699999997453, 98.0569999999964, -14.392999999995578, 9.937999999997976, 46.295000000000236, 5.828999999995112], 0.06: [20.54100000001381, -5.463000000006698, -50.00000000000659, -35.56899999997388, 57.848999999992486, 98.10699999999652, -20.6369999999792, -23.36699999998115, -32.30099999997311, -17.600999999992716], 0.08: [16.828000000000614, -21.93799999998347, -47.778999999996685, -29.653999999979195, -3.6890000000020984, 78.61099999997953, -45.86199999999051, -36.11999999997662, -50.00000000000659, 10.52999999999848], 0.1: [-31.282999999971825, -1.848000000002547, -50.00000000000659, -50.00000000000659, -38.00299999996934, 57.52399999999811, -48.58000000000051, -39.04599999997061, -47.31100000000112, -12.969999999993547], 0.12: [-42.30899999997428, -7.750000000008004, -50.00000000000659, -50.00000000000659, -44.72999999998709, -22.125999999978326, -48.60500000000149, -39.60899999996773, -50.00000000000659, -38.68499999997037], 0.14: [-50.00000000000659, -26.161999999977898, -50.00000000000659, -50.00000000000659, -36.51899999996956, -47.231999999995836, -50.00000000000659, -43.734999999978335, -50.00000000000659, -48.871000000001565], 0.16: [-45.40499999998737, -17.730999999981762, -50.00000000000659, -50.00000000000659, -39.24199999996799, -23.715999999987194, -50.00000000000659, -48.95400000000187, -50.00000000000659, -48.92100000000175], 0.18: [-45.43399999998747, -33.53799999997343, -50.00000000000659, -50.00000000000659, -47.30099999999609, -41.756999999972834, -50.00000000000659, -50.00000000000659, -50.00000000000659, -50.00000000000659], 0.2: [-47.78399999999711, -18.815999999991664, -50.00000000000659, -50.00000000000659, -50.00000000000659, -13.092999999986173, -50.00000000000659, -50.00000000000659, -50.00000000000659, -48.98600000000312]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWgS-yClVNHg","executionInfo":{"status":"ok","timestamp":1611826260569,"user_tz":-60,"elapsed":830,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"7a70067d-2b52-4774-8c17-ad7adf69fa34"},"source":["print(\"fgsm (t): {0.0: [95.87499999999261, 97.77399999999591, 94.40799999999314, 96.49599999999695, 96.05199999999255, 93.26499999999466, 97.67499999999583, 96.19599999999672, 96.38699999999682, 97.90299999999614], 0.02: [79.72499999998196, 21.991000000009002, -3.1010000000024833, 41.113000000007496, 85.9739999999861, 9.863000000004849, -13.443999999999521, -35.91399999997348, 26.180000000020556, 54.89999999998844], 0.04: [73.9719999999884, -23.595999999986894, -23.778999999989086, 20.395000000016086, 35.00600000001057, 44.89400000000183, 14.32600000000494, -4.275000000004516, 53.81599999999942, 63.61199999999205], 0.06: [24.829000000017007, -45.642999999989144, -13.146999999987187, -2.91899999999977, 17.378000000015206, 29.93000000001121, -39.78299999997068, 2.9480000000004143, 41.63500000001305, 72.57899999998226], 0.08: [6.6309999999976705, -34.36599999997397, -8.729000000003882, -42.810999999986116, -25.77299999997859, 42.20100000001005, -47.15799999999459, -19.246999999983736, 61.10699999999787, 73.96399999998457], 0.1: [13.876000000002794, -43.61399999998562, -26.5579999999776, -37.31899999997468, -15.181000000000543, 32.47100000001505, -43.334999999978926, -37.311999999973004, 59.75999999999233, 61.70599999998308], 0.12: [29.658000000014457, -45.04099999998945, -13.630999999999093, -43.71199999998144, -12.977999999999417, 47.40900000000926, -26.055999999978848, -30.412999999977384, 51.740999999990784, 0.6499999999996606], 0.14: [-15.67999999999861, -48.97600000000195, -35.42999999997022, -32.84999999997244, -30.01599999997857, 20.647000000005374, -24.083999999978936, -40.279999999968815, 36.544000000019366, -22.462999999981506], 0.16: [-48.688000000000905, -45.91499999999012, -33.186999999973494, -38.71399999997188, -37.35399999997284, -1.7050000000007588, -27.89899999997665, -44.2919999999831, 24.02100000001258, -32.91799999997237], 0.18: [-48.56400000000045, -45.32499999999101, -35.79399999997332, -23.90199999998022, -23.642999999983036, -21.72199999998669, -30.350999999976317, -45.728999999989455, 2.421999999999141, -45.74699999999016], 0.2: [-50.00000000000659, -50.00000000000659, -46.65799999999266, -25.24599999997427, -9.83500000000743, -36.045999999972196, -38.621999999972644, -50.00000000000659, -39.09699999996903, -47.124999999995055]}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fgsm (t): {0.0: [95.87499999999261, 97.77399999999591, 94.40799999999314, 96.49599999999695, 96.05199999999255, 93.26499999999466, 97.67499999999583, 96.19599999999672, 96.38699999999682, 97.90299999999614], 0.02: [79.72499999998196, 21.991000000009002, -3.1010000000024833, 41.113000000007496, 85.9739999999861, 9.863000000004849, -13.443999999999521, -35.91399999997348, 26.180000000020556, 54.89999999998844], 0.04: [73.9719999999884, -23.595999999986894, -23.778999999989086, 20.395000000016086, 35.00600000001057, 44.89400000000183, 14.32600000000494, -4.275000000004516, 53.81599999999942, 63.61199999999205], 0.06: [24.829000000017007, -45.642999999989144, -13.146999999987187, -2.91899999999977, 17.378000000015206, 29.93000000001121, -39.78299999997068, 2.9480000000004143, 41.63500000001305, 72.57899999998226], 0.08: [6.6309999999976705, -34.36599999997397, -8.729000000003882, -42.810999999986116, -25.77299999997859, 42.20100000001005, -47.15799999999459, -19.246999999983736, 61.10699999999787, 73.96399999998457], 0.1: [13.876000000002794, -43.61399999998562, -26.5579999999776, -37.31899999997468, -15.181000000000543, 32.47100000001505, -43.334999999978926, -37.311999999973004, 59.75999999999233, 61.70599999998308], 0.12: [29.658000000014457, -45.04099999998945, -13.630999999999093, -43.71199999998144, -12.977999999999417, 47.40900000000926, -26.055999999978848, -30.412999999977384, 51.740999999990784, 0.6499999999996606], 0.14: [-15.67999999999861, -48.97600000000195, -35.42999999997022, -32.84999999997244, -30.01599999997857, 20.647000000005374, -24.083999999978936, -40.279999999968815, 36.544000000019366, -22.462999999981506], 0.16: [-48.688000000000905, -45.91499999999012, -33.186999999973494, -38.71399999997188, -37.35399999997284, -1.7050000000007588, -27.89899999997665, -44.2919999999831, 24.02100000001258, -32.91799999997237], 0.18: [-48.56400000000045, -45.32499999999101, -35.79399999997332, -23.90199999998022, -23.642999999983036, -21.72199999998669, -30.350999999976317, -45.728999999989455, 2.421999999999141, -45.74699999999016], 0.2: [-50.00000000000659, -50.00000000000659, -46.65799999999266, -25.24599999997427, -9.83500000000743, -36.045999999972196, -38.621999999972644, -50.00000000000659, -39.09699999996903, -47.124999999995055]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMU2iQ0HfYMB","executionInfo":{"status":"ok","timestamp":1611677931564,"user_tz":-60,"elapsed":1475,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"fc713cf2-0b8b-4232-fda0-3d3913eca00c"},"source":["print(\"noise: {0.0: [95.84299999999237, 97.7699999999959, 94.83099999999098, 94.98799999999737, 96.63299999999461, 93.457999999995, 94.84499999999221, 90.14699999999331, 96.33899999999399, 97.90899999999614], 0.05: [81.38499999999286, 1.518999999999962, 25.856000000017605, 50.32099999999123, 41.773000000015244, 65.34799999999119, 2.906999999999274, -23.120999999979528, 58.1009999999882, 66.32899999998857], 0.1: [56.43899999999991, -7.056000000005732, 10.625000000001517, 14.278000000010868, 6.115999999997395, 61.41799999998866, -2.766000000006798, -13.371999999993127, 80.32399999998538, 56.840999999987986], 0.15: [44.458000000001604, 6.343999999995318, 44.91200000000099, 25.281000000013545, 6.320999999997017, 76.73299999998343, 30.108000000007845, 6.625000000001936, 87.63199999999286, 75.76499999998076], 0.2: [35.54700000001017, 49.008000000004074, 18.23200000002292, 57.43399999997138, -11.933000000001636, 70.42399999999164, 65.46499999997067, 14.3760000000066, 78.03199999998415, 74.47799999998215], 0.25: [29.995000000020138, 54.97999999997475, 10.650999999994085, 61.34699999997909, -30.576999999973562, 65.66899999997031, 72.30299999996966, 15.57100000000391, 63.02999999997938, 62.241999999967426], 0.3: [17.133000000009297, 42.36000000002272, 3.421999999994482, 66.00399999998352, -37.381999999971896, 63.350999999968536, 71.97299999997163, 8.074999999998646, 25.287000000012924, 27.91300000001797], 0.35: [17.181000000006282, 35.287000000022665, -7.517000000002699, 74.87299999997555, -42.91299999997626, 55.74399999999955, 68.34099999997001, 17.96100000001002, -0.6950000000019384, 15.565999999996926], 0.4: [17.51000000001047, 26.875000000016986, -8.581000000004389, 76.24399999997742, -33.78999999997332, 50.316000000003186, 44.792000000018014, -3.6930000000017897, -21.92899999997987, 15.904000000008962], 0.45: [-7.397000000008017, 18.74100000001584, -10.991999999998422, 67.11699999999045, -34.330999999969706, 41.14800000001356, 14.901000000005427, 1.891999999995767, -29.359999999979426, -8.438000000003507], 0.5: [-6.232000000004591, 16.731000000005352, -19.90699999998307, 67.55499999998452, -32.70099999997604, 46.18500000001505, -2.5990000000007227, 8.785999999996113, -28.49299999997531, 1.7389999999947081]}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["noise: {0.0: [95.84299999999237, 97.7699999999959, 94.83099999999098, 94.98799999999737, 96.63299999999461, 93.457999999995, 94.84499999999221, 90.14699999999331, 96.33899999999399, 97.90899999999614], 0.05: [81.38499999999286, 1.518999999999962, 25.856000000017605, 50.32099999999123, 41.773000000015244, 65.34799999999119, 2.906999999999274, -23.120999999979528, 58.1009999999882, 66.32899999998857], 0.1: [56.43899999999991, -7.056000000005732, 10.625000000001517, 14.278000000010868, 6.115999999997395, 61.41799999998866, -2.766000000006798, -13.371999999993127, 80.32399999998538, 56.840999999987986], 0.15: [44.458000000001604, 6.343999999995318, 44.91200000000099, 25.281000000013545, 6.320999999997017, 76.73299999998343, 30.108000000007845, 6.625000000001936, 87.63199999999286, 75.76499999998076], 0.2: [35.54700000001017, 49.008000000004074, 18.23200000002292, 57.43399999997138, -11.933000000001636, 70.42399999999164, 65.46499999997067, 14.3760000000066, 78.03199999998415, 74.47799999998215], 0.25: [29.995000000020138, 54.97999999997475, 10.650999999994085, 61.34699999997909, -30.576999999973562, 65.66899999997031, 72.30299999996966, 15.57100000000391, 63.02999999997938, 62.241999999967426], 0.3: [17.133000000009297, 42.36000000002272, 3.421999999994482, 66.00399999998352, -37.381999999971896, 63.350999999968536, 71.97299999997163, 8.074999999998646, 25.287000000012924, 27.91300000001797], 0.35: [17.181000000006282, 35.287000000022665, -7.517000000002699, 74.87299999997555, -42.91299999997626, 55.74399999999955, 68.34099999997001, 17.96100000001002, -0.6950000000019384, 15.565999999996926], 0.4: [17.51000000001047, 26.875000000016986, -8.581000000004389, 76.24399999997742, -33.78999999997332, 50.316000000003186, 44.792000000018014, -3.6930000000017897, -21.92899999997987, 15.904000000008962], 0.45: [-7.397000000008017, 18.74100000001584, -10.991999999998422, 67.11699999999045, -34.330999999969706, 41.14800000001356, 14.901000000005427, 1.891999999995767, -29.359999999979426, -8.438000000003507], 0.5: [-6.232000000004591, 16.731000000005352, -19.90699999998307, 67.55499999998452, -32.70099999997604, 46.18500000001505, -2.5990000000007227, 8.785999999996113, -28.49299999997531, 1.7389999999947081]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g2OC9xKleOJI"},"source":["def eval_scale(agent, episode_durations):\r\n","    agent.eval()\r\n","    agent.is_training = False\r\n","\r\n","    max_episode_length = 500\r\n","    num_episodes = 100\r\n","\r\n","    for scale in np.arange(1.0,7.01,0.5):\r\n","        env = NormalizedEnv(PointMazeEnv(scale))\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","\r\n","                action = agent.select_action(state, False, False)\r\n","                action_i = action.detach().cpu().squeeze(0).numpy()\r\n","\r\n","                observation, reward, done, info = env.step(action_i) \r\n","                \r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                \r\n","                episode_steps += 1 \r\n","\r\n","                overall_reward += reward\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[np.round(scale, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latQhuUQq8sk","executionInfo":{"status":"ok","timestamp":1611564427453,"user_tz":-60,"elapsed":869897,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"c08eae64-c925-4bbd-a940-f4996d3b0828"},"source":["episodes = {}\r\n","for scale in np.arange(1.0,7.01,0.5):\r\n","    episodes[np.round(scale, 2)] = []\r\n","\r\n","n_observations = env.observation_space.shape[0]\r\n","n_actions = env.action_space.shape[0]\r\n","\r\n","i = 0\r\n","while i < 10:\r\n","    agent = TD3(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"td3_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        eval_scale(agent, episodes)\r\n","        print(f\"{i} scale: {episodes}\")\r\n","        i += 1\r\n","\r\n","print(\"---\")\r\n","print(f\"scale: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 scale: {1.0: [-46.26199999999026], 1.5: [9.208999999998532], 2.0: [46.14100000000284], 2.5: [81.18899999999132], 3.0: [95.42299999999166], 3.5: [96.07499999999308], 4.0: [95.81599999999266], 4.5: [59.16300000000002], 5.0: [42.33100000001287], 5.5: [26.155000000020546], 6.0: [37.65700000001437], 6.5: [63.94899999997307], 7.0: [80.91899999998493]}\n","1 scale: {1.0: [-46.26199999999026, 71.73299999998741], 1.5: [9.208999999998532, 58.73799999999155], 2.0: [46.14100000000284, 75.06799999999193], 2.5: [81.18899999999132, 91.8009999999888], 3.0: [95.42299999999166, 96.48099999999627], 3.5: [96.07499999999308, 97.99799999999632], 4.0: [95.81599999999266, 97.77499999999591], 4.5: [59.16300000000002, 97.52799999999552], 5.0: [42.33100000001287, 97.30099999999514], 5.5: [26.155000000020546, 97.07599999999475], 6.0: [37.65700000001437, 96.86099999999436], 6.5: [63.94899999997307, 96.64399999999395], 7.0: [80.91899999998493, 96.42899999999355]}\n","2 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897]}\n","3 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081]}\n","4 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392]}\n","5 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819]}\n","6 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052, -48.581000000000515], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827, -38.61799999997026], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531, 97.22299999999628], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315, 85.31599999999264], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766, 98.50999999999725], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265, 96.8389999999975], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233, 91.85799999999327], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099, 94.98899999999504], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715, 95.79999999999536], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715, 97.61599999999562], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965, 92.91099999999231], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048, 94.16999999999557], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819, 63.03999999999411]}\n","7 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052, -48.581000000000515, 32.06600000000971], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827, -38.61799999997026, 16.371000000006816], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531, 97.22299999999628, 99.00099999999814], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315, 85.31599999999264, 98.77499999999773], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766, 98.50999999999725, 98.51099999999725], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265, 96.8389999999975, 95.06299999999527], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233, 91.85799999999327, 88.86299999998957], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099, 94.98899999999504, 71.96599999998296], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715, 95.79999999999536, 52.93000000000079], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715, 97.61599999999562, 26.376000000012144], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965, 92.91099999999231, 0.5909999999981583], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048, 94.16999999999557, -28.1229999999766], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819, 63.03999999999411, -47.079000000003234]}\n","8 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052, -48.581000000000515, 32.06600000000971, 56.287999999982546], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827, -38.61799999997026, 16.371000000006816, 96.0169999999937], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531, 97.22299999999628, 99.00099999999814, 86.37599999998845], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315, 85.31599999999264, 98.77499999999773, 94.46699999999436], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766, 98.50999999999725, 98.51099999999725, 90.31799999999149], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265, 96.8389999999975, 95.06299999999527, 94.70199999999498], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233, 91.85799999999327, 88.86299999998957, 97.88499999999598], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099, 94.98899999999504, 71.96599999998296, 97.75899999999588], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715, 95.79999999999536, 52.93000000000079, 97.56699999999553], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715, 97.61599999999562, 26.376000000012144, 97.37599999999529], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965, 92.91099999999231, 0.5909999999981583, 97.17799999999492], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048, 94.16999999999557, -28.1229999999766, 96.96299999999454], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819, 63.03999999999411, -47.079000000003234, 96.70599999999405]}\n","9 scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052, -48.581000000000515, 32.06600000000971, 56.287999999982546, -26.205999999978655], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827, -38.61799999997026, 16.371000000006816, 96.0169999999937, -50.00000000000659], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531, 97.22299999999628, 99.00099999999814, 86.37599999998845, 12.187999999997281], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315, 85.31599999999264, 98.77499999999773, 94.46699999999436, 88.02799999999337], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766, 98.50999999999725, 98.51099999999725, 90.31799999999149, 98.3379999999969], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265, 96.8389999999975, 95.06299999999527, 94.70199999999498, 98.12599999999655], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233, 91.85799999999327, 88.86299999998957, 97.88499999999598, 97.90899999999614], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099, 94.98899999999504, 71.96599999998296, 97.75899999999588, 97.71199999999578], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715, 95.79999999999536, 52.93000000000079, 97.56699999999553, 97.4979999999955], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715, 97.61599999999562, 26.376000000012144, 97.37599999999529, 97.31199999999515], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965, 92.91099999999231, 0.5909999999981583, 97.17799999999492, 94.20199999999309], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048, 94.16999999999557, -28.1229999999766, 96.96299999999454, 47.00699999999961], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819, 63.03999999999411, -47.079000000003234, 96.70599999999405, 1.3799999999999368]}\n","---\n","scale: {1.0: [-46.26199999999026, 71.73299999998741, -35.67299999997372, -50.00000000000659, 10.40099999999426, -48.6190000000052, -48.581000000000515, 32.06600000000971, 56.287999999982546, -26.205999999978655], 1.5: [9.208999999998532, 58.73799999999155, 58.895999999981996, -12.950999999993222, 87.32199999998994, -43.15499999997827, -38.61799999997026, 16.371000000006816, 96.0169999999937, -50.00000000000659], 2.0: [46.14100000000284, 75.06799999999193, 96.65699999999428, 98.76399999999776, 96.77099999999643, -0.9950000000051531, 97.22299999999628, 99.00099999999814, 86.37599999998845, 12.187999999997281], 2.5: [81.18899999999132, 91.8009999999888, 97.90599999999613, 98.51299999999719, 98.29299999999746, 57.283999999983315, 85.31599999999264, 98.77499999999773, 94.46699999999436, 88.02799999999337], 3.0: [95.42299999999166, 96.48099999999627, 98.00699999999635, 98.14299999999656, 98.32599999999691, 76.82699999998766, 98.50999999999725, 98.51099999999725, 90.31799999999149, 98.3379999999969], 3.5: [96.07499999999308, 97.99799999999632, 97.51399999999506, 97.96299999999627, 97.90899999999608, 95.65099999999265, 96.8389999999975, 95.06299999999527, 94.70199999999498, 98.12599999999655], 4.0: [95.81599999999266, 97.77499999999591, 91.72099999998716, 92.04699999998924, 96.11299999999255, 93.35699999999233, 91.85799999999327, 88.86299999998957, 97.88499999999598, 97.90899999999614], 4.5: [59.16300000000002, 97.52799999999552, 97.37699999999535, 78.06299999999182, 96.89699999999439, 79.76299999998099, 94.98899999999504, 71.96599999998296, 97.75899999999588, 97.71199999999578], 5.0: [42.33100000001287, 97.30099999999514, 91.23499999999026, 33.46200000001252, 96.05499999999269, 76.62799999998715, 95.79999999999536, 52.93000000000079, 97.56699999999553, 97.4979999999955], 5.5: [26.155000000020546, 97.07599999999475, 92.44899999998917, -13.45699999998755, 96.2129999999931, 79.18699999998715, 97.61599999999562, 26.376000000012144, 97.37599999999529, 97.31199999999515], 6.0: [37.65700000001437, 96.86099999999436, 93.70299999999283, -45.61299999998875, 95.91599999999251, 66.74099999998965, 92.91099999999231, 0.5909999999981583, 97.17799999999492, 94.20199999999309], 6.5: [63.94899999997307, 96.64399999999395, 93.54299999999499, -50.00000000000659, 96.72299999999416, 42.78100000001048, 94.16999999999557, -28.1229999999766, 96.96299999999454, 47.00699999999961], 7.0: [80.91899999998493, 96.42899999999355, 90.36199999998897, -48.66400000000081, 96.61999999999392, 44.44600000000819, 63.03999999999411, -47.079000000003234, 96.70599999999405, 1.3799999999999368]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yLne6pfQrBV6"},"source":["def eval_starting_position(agent, episode_durations):\r\n","    agent.eval()\r\n","    agent.is_training = False\r\n","\r\n","    max_episode_length = 500\r\n","    num_episodes = 100\r\n","\r\n","    for extra_range in np.arange(0.0, 0.401, 0.05):\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","\r\n","            extra = np.random.uniform(-0.1 - extra_range, 0.1 + extra_range, env.starting_point.shape)\r\n","            #extra = np.random.uniform(0.1, 0.1 + extra_range, env.starting_point.shape)\r\n","            #extra = extra * (2*np.random.randint(0,2,size=env.starting_point.shape)-1)\r\n","            env.unwrapped.state = np.array(env.starting_point + extra, dtype=np.float32)\r\n","            env.unwrapped.state[2] = env.state[2] % (2 * math.pi)\r\n","            observation = env.normalised_state()\r\n","\r\n","            # unsqueeze adds batch dimension\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","\r\n","                action = agent.select_action(state, False, False)\r\n","                action_i = action.detach().cpu().squeeze(0).numpy()\r\n","\r\n","                observation, reward, done, info = env.step(action_i) \r\n","                \r\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                    done = True\r\n","                \r\n","                episode_steps += 1 \r\n","\r\n","                overall_reward += reward\r\n","\r\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_durations[np.round(extra_range, 3)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSQuwvxyrDdS","executionInfo":{"status":"ok","timestamp":1612551176625,"user_tz":-60,"elapsed":343154,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"c35e50af-1bd3-4e61-a1ce-85275013ad7e"},"source":["episodes = {}\r\n","for extra_range in np.arange(0.0, 0.401, 0.05):\r\n","    episodes[np.round(extra_range, 3)] = []\r\n","\r\n","n_observations = env.observation_space.shape[0]\r\n","n_actions = env.action_space.shape[0]\r\n","\r\n","env = NormalizedEnv(PointMazeEnv(4))\r\n","\r\n","i = 0\r\n","while i < 10:\r\n","    agent = TD3(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"td3_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        eval_starting_position(agent, episodes)\r\n","        print(f\"{i} extra_range: {episodes}\")\r\n","        i += 1\r\n","\r\n","print(\"---\")\r\n","print(f\"extra_range: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 extra_range: {0.0: [95.8299999999922], 0.05: [95.78499999999227], 0.1: [96.04899999999284], 0.15: [95.89699999999267], 0.2: [92.87899999998905], 0.25: [88.58699999998639], 0.3: [84.1349999999902], 0.35: [81.15699999998394], 0.4: [74.01099999998468]}\n","1 extra_range: {0.0: [95.8299999999922, 97.76899999999588], 0.05: [95.78499999999227, 97.7669999999959], 0.1: [96.04899999999284, 91.83599999999355], 0.15: [95.89699999999267, 91.8379999999913], 0.2: [92.87899999998905, 90.35599999999647], 0.25: [88.58699999998639, 91.82399999999352], 0.3: [84.1349999999902, 74.02799999997728], 0.35: [81.15699999998394, 87.31999999998813], 0.4: [74.01099999998468, 88.77599999998944]}\n","2 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138]}\n","3 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365]}\n","4 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989]}\n","5 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424]}\n","6 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622, 94.9619999999923], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927, 96.59299999999457], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349, 95.18799999999311], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262, 81.85099999999704], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777, 87.4669999999929], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718, 71.31399999998739], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053, 62.54199999998586], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594, 59.27699999997548], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424, 65.32599999997791]}\n","7 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622, 94.9619999999923, 88.62499999998877], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927, 96.59299999999457, 91.84699999999157], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349, 95.18799999999311, 81.4719999999816], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262, 81.85099999999704, 79.75199999999718], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777, 87.4669999999929, 69.66799999998364], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718, 71.31399999998739, 69.66999999997914], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053, 62.54199999998586, 60.186999999982774], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594, 59.27699999997548, 50.03899999998781], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424, 65.32599999997791, 41.49500000001424]}\n","8 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622, 94.9619999999923, 88.62499999998877, 97.95299999999621], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927, 96.59299999999457, 91.84699999999157, 94.51099999999256], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349, 95.18799999999311, 81.4719999999816, 94.28999999999625], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262, 81.85099999999704, 79.75199999999718, 91.230999999992], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777, 87.4669999999929, 69.66799999998364, 81.74299999998408], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718, 71.31399999998739, 69.66999999997914, 78.92499999998756], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053, 62.54199999998586, 60.186999999982774, 75.15899999997941], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594, 59.27699999997548, 50.03899999998781, 75.90599999999867], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424, 65.32599999997791, 41.49500000001424, 64.49399999999169]}\n","9 extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622, 94.9619999999923, 88.62499999998877, 97.95299999999621, 97.89799999999613], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927, 96.59299999999457, 91.84699999999157, 94.51099999999256, 97.90799999999614], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349, 95.18799999999311, 81.4719999999816, 94.28999999999625, 97.91199999999615], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262, 81.85099999999704, 79.75199999999718, 91.230999999992, 97.90199999999614], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777, 87.4669999999929, 69.66799999998364, 81.74299999998408, 97.89899999999612], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718, 71.31399999998739, 69.66999999997914, 78.92499999998756, 97.87399999999604], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053, 62.54199999998586, 60.186999999982774, 75.15899999997941, 96.33899999999649], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594, 59.27699999997548, 50.03899999998781, 75.90599999999867, 87.51399999999086], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424, 65.32599999997791, 41.49500000001424, 64.49399999999169, 77.16299999999461]}\n","---\n","extra_range: {0.0: [95.8299999999922, 97.76899999999588, 92.70199999998871, 92.01999999999097, 95.86499999999346, 92.01099999999622, 94.9619999999923, 88.62499999998877, 97.95299999999621, 97.89799999999613], 0.05: [95.78499999999227, 97.7669999999959, 91.99799999998872, 94.57399999999129, 96.39199999999475, 93.4539999999927, 96.59299999999457, 91.84699999999157, 94.51099999999256, 97.90799999999614], 0.1: [96.04899999999284, 91.83599999999355, 83.50999999998798, 89.97899999999026, 96.74799999999422, 91.64799999999349, 95.18799999999311, 81.4719999999816, 94.28999999999625, 97.91199999999615], 0.15: [95.89699999999267, 91.8379999999913, 84.95799999999127, 90.18099999999166, 96.88799999999341, 87.35399999999262, 81.85099999999704, 79.75199999999718, 91.230999999992, 97.90199999999614], 0.2: [92.87899999998905, 90.35599999999647, 79.21199999998386, 81.69899999998813, 93.7899999999925, 79.83699999999777, 87.4669999999929, 69.66799999998364, 81.74299999998408, 97.89899999999612], 0.25: [88.58699999998639, 91.82399999999352, 72.83699999996924, 69.82099999998886, 86.38899999998819, 64.99399999998718, 71.31399999998739, 69.66999999997914, 78.92499999998756, 97.87399999999604], 0.3: [84.1349999999902, 74.02799999997728, 66.04299999998042, 60.3519999999875, 89.24499999999254, 64.85399999999053, 62.54199999998586, 60.186999999982774, 75.15899999997941, 96.33899999999649], 0.35: [81.15699999998394, 87.31999999998813, 54.37899999999956, 62.341999999986356, 73.11499999998489, 69.02899999998594, 59.27699999997548, 50.03899999998781, 75.90599999999867, 87.51399999999086], 0.4: [74.01099999998468, 88.77599999998944, 39.53400000001138, 62.29299999998365, 84.61599999997989, 48.36599999999424, 65.32599999997791, 41.49500000001424, 64.49399999999169, 77.16299999999461]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TOvxBEptrKxQ","executionInfo":{"status":"ok","timestamp":1612799832155,"user_tz":-60,"elapsed":654,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\r\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\r\n","state_mid = (state_max + state_min) / 2.\r\n","state_range = (state_max - state_min)\r\n","def save_trajectories(agent, episode_durations, dirty):\r\n","    agent.eval()\r\n","\r\n","    max_episode_length = 500\r\n","    agent.is_training = False\r\n","\r\n","    num_episodes = 10\r\n","\r\n","    l2norm = 0.3\r\n","    episode_durations.append([])\r\n","    \r\n","    for i_episode in range(num_episodes):\r\n","        path = {\"overall_reward\": 0, \"worker\": []}\r\n","\r\n","        observation = env.reset()\r\n","\r\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","        state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        episode_steps = 0\r\n","        overall_reward = 0\r\n","        done = False\r\n","        while not done:\r\n","            if dirty:\r\n","                state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\r\n","                state = torch.max(torch.min(state, state_max), state_min).float()\r\n","\r\n","            action = agent.select_action(state, False, False)\r\n","            action_i = action.detach().cpu().squeeze(0).numpy()\r\n","            path[\"worker\"].append((episode_steps, state_.detach().cpu().squeeze(0).numpy(), action.detach().cpu().squeeze(0).numpy()))\r\n","\r\n","            observation, reward, done, info = env.step(action_i) \r\n","            \r\n","            if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                done = True\r\n","            \r\n","            episode_steps += 1 \r\n","\r\n","            overall_reward += reward\r\n","\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","            state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","        path[\"overall_reward\"] = overall_reward\r\n","        episode_durations[-1].append(path)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoYiJ43jWW74","executionInfo":{"status":"ok","timestamp":1612799891524,"user_tz":-60,"elapsed":25763,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"4bfdadc2-5bbe-4297-e9cb-e550c98492d2"},"source":["episodes = []\r\n","\r\n","n_observations = env.observation_space.shape[0]\r\n","n_actions = env.action_space.shape[0]\r\n","\r\n","i = 0\r\n","while i < 10:\r\n","    #agent = train_model()\r\n","    agent = TD3(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"td3_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        # goal_attack, action_attack, same_noise\r\n","        save_trajectories(agent, episodes, True)\r\n","        #print(f\"{i} paths: {episodes}\")\r\n","        i += 1\r\n","\r\n","print(\"----\")\r\n","#print(f\"paths: {episodes}\")\r\n","\r\n","torch.save(episodes, \"td3_PointMaze_dirty_eps.pt\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uOZDxN3EWeww"},"source":[""],"execution_count":null,"outputs":[]}]}