{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"hiro_pointpush_random.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-Y3vLeDo4pG","executionInfo":{"status":"ok","timestamp":1617453094205,"user_tz":-60,"elapsed":21555,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"4052a0e8-187f-457f-be4e-014682cfb2f1"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!cp \"/content/drive/My Drive/Dissertation/envs/point_push.py\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eaaz1IRfpF1l","executionInfo":{"status":"ok","timestamp":1617453094206,"user_tz":-60,"elapsed":21553,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# for inference, not continued training\n","def save_model(model, name):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_push_random/{name}\" \n","\n","    torch.save({\n","      'meta_controller': {\n","          'critic': model.meta_controller.critic.state_dict(),\n","          'actor': model.meta_controller.actor.state_dict(),\n","      },\n","      'controller': {\n","          'critic': model.controller.critic.state_dict(),\n","          'actor': model.controller.actor.state_dict(),\n","      }\n","    }, path)\n","\n","import copy\n","def load_model(model, name, dir=\"point_push_random\"):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{dir}/{name}\" \n","    checkpoint = torch.load(path)\n","\n","    model.meta_controller.critic.load_state_dict(checkpoint['meta_controller']['critic'])\n","    model.meta_controller.critic_target = copy.deepcopy(model.meta_controller.critic)\n","    model.meta_controller.actor.load_state_dict(checkpoint['meta_controller']['actor'])\n","    model.meta_controller.actor_target = copy.deepcopy(model.meta_controller.actor)\n","\n","    model.controller.critic.load_state_dict(checkpoint['controller']['critic'])\n","    model.controller.critic_target = copy.deepcopy(model.controller.critic)\n","    model.controller.actor.load_state_dict(checkpoint['controller']['actor'])\n","    model.controller.actor_target = copy.deepcopy(model.controller.actor)\n","\n","    # model.eval() for evaluation instead\n","    model.eval()\n","    model.meta_controller.eval()\n","    model.controller.eval()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1617453098005,"user_tz":-60,"elapsed":3795,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1617453098005,"user_tz":-60,"elapsed":3793,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1617453098006,"user_tz":-60,"elapsed":3790,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["from point_push import PointPushEnv \n","env = NormalizedEnv(PointPushEnv(4))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1617453098006,"user_tz":-60,"elapsed":3788,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1617453098007,"user_tz":-60,"elapsed":3787,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1617453098008,"user_tz":-60,"elapsed":3786,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","  \n","# (state, action) -> (next_state, reward, done)\n","transition_meta = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done', 'state_seq', 'action_seq'))\n","\n","# replay memory D with capacity N\n","class ReplayMemoryMeta(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition_meta(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1617453098294,"user_tz":-60,"elapsed":4070,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["DEPTH = 128\n","\n","class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, DEPTH)\n","        self.fc2 = nn.Linear(DEPTH, DEPTH)\n","        self.head = nn.Linear(DEPTH, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l2 = nn.Linear(DEPTH, DEPTH)\n","        self.l3 = nn.Linear(DEPTH, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l5 = nn.Linear(DEPTH, DEPTH)\n","        self.l6 = nn.Linear(DEPTH, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1617453098295,"user_tz":-60,"elapsed":4069,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions, is_meta=False):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        self.is_meta = is_meta\n","\n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000) if not self.is_meta else ReplayMemoryMeta(100000)\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 20000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self, off_policy_correction=None):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","\n","        if not self.is_meta:\n","            batch = transition(*zip(*transitions))\n","            action_batch = torch.cat(batch.action)\n","        else:\n","            batch = transition_meta(*zip(*transitions))\n","\n","            action_batch = torch.cat(batch.action)\n","            state_seq_batch = torch.stack(batch.state_seq)\n","            action_seq_batch = torch.stack(batch.action_seq)\n","\n","            action_batch = off_policy_correction(action_batch.cpu().numpy(), state_seq_batch.cpu().numpy(), action_seq_batch.cpu().numpy())\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            \n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # print losses\n","            #if self.total_it % (50 * 50 if self.is_meta else 500 * 50) == 0:\n","            #    print(f\"{self.is_meta} controller;\\n\\tcritic loss: {critic_loss.item()}\\n\\tactor loss: {actor_loss.item()}\")\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, 2 * self.tau / 5)\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup, decay_epsilon):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,1)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u23kJqHhvw8","executionInfo":{"status":"ok","timestamp":1617453098295,"user_tz":-60,"elapsed":4065,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class HIRO(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(HIRO, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        self.goal_dim = [0, 1]\n","        self.goal_dimen = 2\n","      \n","        self.meta_controller = TD3(nb_states, len(self.goal_dim), True).to(device)\n","        self.max_goal_dist = torch.from_numpy(np.array([2.5, 2.5])).to(device)\n","        self.goal_offset = torch.from_numpy(np.array([0., 1.])).to(device)\n","        #self.meta_controller.depsilon = 1.0 / 10000\n","\n","        self.controller = TD3(nb_states + len(self.goal_dim), nb_actions).to(device)\n","        #self.controller.depsilon = 1.0 / 10000\n","\n","    def teach_controller(self):\n","        self.controller.update_policy()\n","    def teach_meta_controller(self):\n","        self.meta_controller.update_policy(self.off_policy_corrections)\n","\n","    def h(self, state, goal, next_state):\n","        #return goal\n","        return state[:,self.goal_dim] + goal - next_state[:,self.goal_dim]\n","    #def intrinsic_reward(self, action, goal):\n","    #    return torch.tensor(1.0 if self.goal_reached(action, goal) else 0.0, device=device) \n","    #def goal_reached(self, action, goal, threshold = 0.1):\n","    #    return torch.abs(action - goal) <= threshold\n","    def intrinsic_reward(self, reward, state, goal, next_state):\n","        #return torch.tensor(2 * reward if self.goal_reached(state, goal, next_state) else reward / 10, device=device) #reward / 2\n","        # just L2 norm\n","        return -torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5)\n","    def goal_reached(self, state, goal, next_state, threshold = 0.1):\n","        return torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5) <= threshold\n","        #return torch.pow(sum(goal.squeeze(0), 2), 0.5) <= threshold\n","\n","    # correct goals to allow for use in experience replay\n","    def off_policy_corrections(self, sgoals, states, actions, candidate_goals=8):\n","        first_s = [s[0] for s in states] # First x\n","        last_s = [s[-1] for s in states] # Last x\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # diff = 1\n","        diff_goal = (np.array(last_s) - np.array(first_s))[:, np.newaxis, :self.goal_dimen]\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # original = 1\n","        # random = candidate_goals\n","        scale = self.max_goal_dist.cpu().numpy()\n","        original_goal = np.array(sgoals)[:, np.newaxis, :]\n","        random_goals = np.random.normal(loc=diff_goal, scale=.5*scale,\n","                                        size=(BATCH_SIZE, candidate_goals, original_goal.shape[-1]))\n","        random_goals = random_goals.clip(-scale, scale)\n","\n","        # Shape: (batch_size, 10, subgoal_dim)\n","        candidates = np.concatenate([original_goal, diff_goal, random_goals], axis=1)\n","        #states = np.array(states)[:, :-1, :]\n","        actions = np.array(actions)\n","        seq_len = len(states[0])\n","\n","        # For ease\n","        new_batch_sz = seq_len * BATCH_SIZE\n","        action_dim = actions[0][0].shape\n","        obs_dim = states[0][0].shape\n","        ncands = candidates.shape[1]\n","\n","        true_actions = actions.reshape((new_batch_sz,) + action_dim)\n","        observations = states.reshape((new_batch_sz,) + obs_dim)\n","        goal_shape = (new_batch_sz, self.goal_dimen)\n","        # observations = get_obs_tensor(observations, sg_corrections=True)\n","\n","        # batched_candidates = np.tile(candidates, [seq_len, 1, 1])\n","        # batched_candidates = batched_candidates.transpose(1, 0, 2)\n","\n","        policy_actions = np.zeros((ncands, new_batch_sz) + action_dim)\n","\n","        observations = torch.from_numpy(observations).to(device)\n","        for c in range(ncands):\n","            subgoal = candidates[:,c]\n","            candidate = (subgoal + states[:, 0, :self.goal_dimen])[:, None] - states[:, :, :self.goal_dimen]\n","            candidate = candidate.reshape(*goal_shape)\n","            policy_actions[c] = self.controller.actor(torch.cat([observations, torch.from_numpy(candidate).to(device)], 1).float()).detach().cpu().numpy()\n","\n","        difference = (policy_actions - true_actions)\n","        difference = np.where(difference != -np.inf, difference, 0)\n","        difference = difference.reshape((ncands, BATCH_SIZE, seq_len) + action_dim).transpose(1, 0, 2, 3)\n","\n","        logprob = -0.5*np.sum(np.linalg.norm(difference, axis=-1)**2, axis=-1)\n","        max_indices = np.argmax(logprob, axis=-1)\n","\n","        return torch.from_numpy(candidates[np.arange(BATCH_SIZE), max_indices]).to(device).float()\n","\n","    def observe_controller(self, s_t, a_t, s_t1, r_t, done):\n","        self.controller.memory.store(s_t, a_t, s_t1, r_t, done)\n","    def observe_meta_controller(self, s_t, a_t, s_t1, r_t, done, state_seq, action_seq):\n","        self.meta_controller.memory.store(s_t, a_t, s_t1, r_t, done, state_seq, action_seq)\n","\n","    def select_goal(self, s_t, warmup, decay_epsilon):\n","        return self.meta_controller.select_action(s_t, warmup, decay_epsilon) * self.max_goal_dist + self.goal_offset\n","    def select_action(self, s_t, g_t, warmup, decay_epsilon):\n","        sg_t = torch.cat([s_t, g_t], 1).float()\n","        return self.controller.select_action(sg_t, warmup, decay_epsilon)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI"},"source":["import time\n","SAVE_OFFSET = 7\n","def train_model():\n","    global SAVE_OFFSET\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = HIRO(n_observations, n_actions).to(device)\n","    \n","    max_episode_length = 500\n","    observation = None\n","    \n","    warmup = 100\n","    num_episodes = 10000 # M\n","    episode_durations = []\n","    goal_durations = []\n","\n","    steps = 0\n","    c = 10\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        overall_intrinsic = 0\n","        episode_steps = 0\n","        done = False\n","        goals_done = 0\n","\n","        while not done:\n","            # random goal\n","            goal = agent.select_goal(state, True, False)\n","            #goal_durations.append((steps, goal[:,0]))\n","\n","            state_seq, action_seq = None, None\n","            first_goal = goal\n","            goal_done = False\n","            total_extrinsic = 0\n","\n","            while not done and not goal_done:\n","                joint_goal_state = torch.cat([state, goal], axis=1).float()\n","\n","                # agent pick action ...\n","                action = agent.select_action(state, goal, i_episode <= warmup, True)\n","                \n","                # env response with next_observation, reward, terminate_info\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                steps += 1\n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                next_goal = agent.h(state, goal, next_state)\n","                joint_next_state = torch.cat([next_state, next_goal], axis=1).float()\n","                \n","                if max_episode_length and episode_steps >= max_episode_length -1:\n","                    done = True\n","                    \n","                extrinsic_reward = torch.tensor([reward], device=device)\n","                intrinsic_reward = agent.intrinsic_reward(reward, state, goal, next_state).unsqueeze(0)\n","                #intrinsic_reward = agent.intrinsic_reward(action, goal).unsqueeze(0)\n","\n","                overall_reward += reward\n","                total_extrinsic += reward\n","                overall_intrinsic += intrinsic_reward\n","\n","                goal_reached = agent.goal_reached(state, goal, next_state)\n","                #goal_done = agent.goal_reached(action, goal)\n","\n","                # agent observe and update policy\n","                agent.observe_controller(joint_goal_state, action, joint_next_state, intrinsic_reward, done) #goal_done.item())\n","\n","                if state_seq is None:\n","                    state_seq = state\n","                else:\n","                    state_seq = torch.cat([state_seq, state])\n","                if action_seq is None:\n","                    action_seq = action\n","                else:\n","                    action_seq = torch.cat([action_seq, action])\n","\n","                episode_steps += 1\n","\n","                if goal_reached:\n","                    goals_done += 1\n","                \n","                if (episode_steps % c) == 0:\n","                    agent.observe_meta_controller(state_seq[0].unsqueeze(0), goal, next_state, torch.tensor([total_extrinsic], device=device), done,\\\n","                                                  state_seq, action_seq)\n","                    goal_done = True\n","\n","                    #if i_episode > warmup:\n","                    #    agent.teach_meta_controller()\n","\n","                state = next_state\n","                goal = next_goal\n","                \n","                if i_episode > warmup:\n","                    agent.teach_controller()\n","\n","        goal_durations.append((i_episode, overall_intrinsic / episode_steps))\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations, goal_durations)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0:\n","                print(f\"{i_episode}: {np.mean(dur[-100:])}\")\n","            if i_episode >= 300 and i_episode % 100 == 0 and np.mean(dur[-100:]) <= -49.0:\n","                print(f\"Unlucky after {i_episode} eps! Terminating...\")\n","                return None\n","            if np.mean(dur[-100:]) >= 90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"hiro_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","\n","    return None # did not train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5kgVRwJErwO"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def eval_model(agent, episode_durations, goal_attack, action_attack, same_noise):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for l2norm in np.arange(0.0,0.51,0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","            if goal_attack:\n","                g_state = g_state + state_range * noise\n","                g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","            if action_attack:\n","                if same_noise:\n","                    state = state + state_range * noise\n","                else:\n","                    state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    if goal_attack:\n","                        g_next_state = g_next_state + state_range * noise\n","                        g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                    if action_attack:\n","                        if same_noise:\n","                            next_state = next_state + state_range * noise\n","                        else:\n","                            next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                        next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(l2norm, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-GH33rpv6-Z"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def fgsm_attack(data, eps, data_grad):\n","    sign_data_grad = data_grad.sign()\n","\n","    perturbed_data = data + eps * sign_data_grad * state_range\n","\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\n","\n","    return clipped_perturbed_data\n","\n","def fgsm_action(state, goal, agent, eps, target, targeted):\n","    #state = torch.tensor(state, requires_grad=True)\n","    state = state.clone().detach().requires_grad_(True)\n","    goal = goal.clone().detach()\n","\n","    sg_t = torch.cat([state, goal], 1).float()\n","\n","    if targeted:\n","        # initial forward pass\n","        action = agent.controller.actor(sg_t)\n","        action = torch.clamp(action, -1., 1.)\n","\n","        loss = F.mse_loss(action, target)\n","    else:\n","        loss = agent.controller.critic.Q1(sg_t, agent.controller.actor(sg_t)).mean()\n","\n","    agent.controller.actor.zero_grad()\n","\n","    # calc loss\n","    loss.backward()\n","    data_grad = state.grad.data\n","    # perturb state\n","    state_p = fgsm_attack(state, eps, data_grad).float()\n","    return state_p\n","\n","def apply_fgsm(agent, episode_durations, targeted):\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0]], device=device, dtype=torch.float)\n","\n","    agent.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for eps in np.arange(0.0, 0.201, 0.02):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            goal = agent.select_goal(og_state, True, False)\n","            state = fgsm_action(og_state, goal, agent, eps, TARGET_ACTION, targeted)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                goal = agent.select_goal(state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    \n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","\n","                    next_og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    goal_temp = agent.h(state, goal, next_og_state)\n","                    next_state = fgsm_action(next_og_state, goal_temp, agent, eps, TARGET_ACTION, targeted)\n","\n","                    next_goal = agent.h(state, goal, next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(state, goal, next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    goal = next_goal\n","\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nrR0kvDhFwRa","executionInfo":{"status":"error","timestamp":1617087383125,"user_tz":-60,"elapsed":17362989,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"654e6d2b-6521-45c9-e7cf-58656f025fee"},"source":["noise_hrl = {'both': {}, 'action_only': {}, 'goal_only': {}, 'both_same': {}}\n","for l2norm in np.arange(0,0.51,0.05):\n","    for i in [noise_hrl['both'], noise_hrl['action_only'], noise_hrl['goal_only'], noise_hrl['both_same']]:\n","        i[np.round(l2norm, 2)] = []\n","\n","targeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\n","untargeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    for x in ['both', 'goal_only', 'action_only']:\n","        targeted[x][eps] = []\n","        untargeted[x][eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 2\n","while i < 6:\n","    agent = train_model()\n","    #agent = HIRO(n_observations, n_actions).to(device)\n","    #load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_model(agent, noise_hrl['both_same'], True, True, True)\n","        eval_model(agent, noise_hrl['both'], True, True, False)\n","        eval_model(agent, noise_hrl['action_only'], False, True, False)\n","        eval_model(agent, noise_hrl['goal_only'], True, False, False)\n","        print(f\"{i} noise_hrl: {noise_hrl}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"noise_hrl: {noise_hrl}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100: -44.042000000000414\n","200: -38.048000000000414\n","300: -27.782000000000384\n","400: -18.841000000000374\n","500: -23.39300000000038\n","600: -27.85200000000038\n","700: -30.70600000000039\n","800: -14.352000000000348\n","900: -20.551000000000364\n","1000: -16.107000000000344\n","1100: -15.276000000000334\n","1200: -1.5050000000002928\n","1300: -8.125000000000316\n","1400: -13.261000000000323\n","1500: -25.62500000000037\n","1600: -35.1160000000004\n","1700: -19.616000000000348\n","1800: -24.330000000000364\n","1900: -14.251000000000335\n","2000: 4.38999999999973\n","2100: -6.332000000000306\n","2200: -16.645000000000344\n","2300: -12.915000000000326\n","2400: -28.65100000000038\n","2500: -29.84800000000038\n","2600: -21.20100000000036\n","2700: -7.790000000000313\n","2800: -8.796000000000321\n","2900: -5.451000000000303\n","3000: -9.923000000000318\n","3100: -0.5610000000002989\n","3200: -6.180000000000314\n","3300: 0.7049999999997172\n","3400: 11.46699999999975\n","3500: 13.802999999999745\n","3600: 10.185999999999751\n","3700: 19.538999999999778\n","3800: 29.23899999999979\n","3900: 12.867999999999746\n","4000: 10.573999999999742\n","4100: 3.485999999999718\n","4200: 5.0099999999997245\n","4300: 25.223999999999783\n","4400: 19.629999999999754\n","4500: 43.15099999999985\n","4600: 25.13599999999979\n","4700: 23.752999999999773\n","4800: 33.51099999999982\n","4900: 34.86299999999981\n","5000: -7.98700000000032\n","5100: 20.825999999999773\n","5200: 12.504999999999747\n","5300: -5.859000000000317\n","5400: 5.489999999999707\n","5500: 33.960999999999814\n","5600: 38.64299999999983\n","5700: 40.402999999999835\n","5800: 43.54499999999984\n","5900: 68.01799999999994\n","6000: 53.41199999999989\n","6100: 53.7379999999999\n","6200: 62.695999999999934\n","6300: 33.73099999999982\n","6400: 53.57599999999989\n","6500: 53.13999999999988\n","6600: 45.46099999999987\n","6700: 54.03399999999991\n","6800: 51.54999999999988\n","6900: 42.014999999999844\n","7000: 53.6719999999999\n","7100: 60.0479999999999\n","7200: 65.0099999999999\n","7300: 65.80199999999992\n","7400: 77.66199999999995\n","7500: 82.49299999999998\n","7600: 85.535\n","7700: 82.69799999999998\n","7800: 88.37999999999998\n","7900: 79.58599999999996\n","8000: 79.01899999999995\n","8100: 84.89199999999997\n","8200: 48.24299999999985\n","8300: 53.58799999999988\n","8400: 72.97799999999994\n","8500: 81.79099999999995\n","Solved after 8525 episodes!\n","2 noise_hrl: {'both': {0.0: [84.39799999998418], 0.05: [81.24299999998449], 0.1: [46.06900000000408], 0.15: [13.369000000000169], 0.2: [-10.648999999998377], 0.25: [-17.678999999987738], 0.3: [-20.908999999990577], 0.35: [-20.208999999985984], 0.4: [-25.34099999997451], 0.45: [-30.237999999972754], 0.5: [-33.726999999971355]}, 'action_only': {0.0: [86.16799999998634], 0.05: [73.67299999998892], 0.1: [56.122999999992565], 0.15: [10.931000000016843], 0.2: [-9.454000000002548], 0.25: [-14.475999999993476], 0.3: [-25.45199999998025], 0.35: [-31.010999999973656], 0.4: [-24.91999999997124], 0.45: [-29.95299999997211], 0.5: [-32.359999999975926]}, 'goal_only': {0.0: [87.6469999999883], 0.05: [91.30799999999286], 0.1: [86.96999999998779], 0.15: [77.02799999998477], 0.2: [88.67399999998693], 0.25: [85.80399999998794], 0.3: [79.82499999999318], 0.35: [85.83899999998896], 0.4: [82.58499999998689], 0.45: [73.90899999999519], 0.5: [75.28099999998858]}, 'both_same': {0.0: [84.55599999998685], 0.05: [66.33999999999033], 0.1: [50.61099999998198], 0.15: [33.915000000012874], 0.2: [2.9809999999990064], 0.25: [-17.112999999980925], 0.3: [-28.638999999981007], 0.35: [-29.027999999979098], 0.4: [-27.97499999997789], 0.45: [-36.01499999997246], 0.5: [-36.41299999996897]}}\n","100: -44.42300000000043\n","200: -34.5420000000004\n","300: -32.6700000000004\n","400: -20.852000000000363\n","500: -27.462000000000383\n","600: -26.908000000000374\n","700: -26.31500000000038\n","800: -24.232000000000372\n","900: -13.625000000000346\n","1000: -23.690000000000364\n","1100: -32.433000000000405\n","1200: -37.34800000000041\n","1300: -39.29500000000041\n","1400: -38.09100000000041\n","1500: -33.692000000000405\n","1600: -23.947000000000372\n","1700: -42.364000000000416\n","1800: -39.83500000000042\n","1900: -31.48100000000039\n","2000: -35.778000000000404\n","2100: -43.459000000000415\n","2200: -46.334000000000415\n","2300: -30.94300000000039\n","2400: -29.499000000000386\n","2500: -8.632000000000316\n","2600: -20.08700000000035\n","2700: -31.881000000000395\n","2800: -30.739000000000388\n","2900: -28.620000000000374\n","3000: -19.330000000000346\n","3100: -22.71300000000036\n","3200: -27.156000000000375\n","3300: -16.61400000000034\n","3400: -19.572000000000347\n","3500: -19.302000000000348\n","3600: -15.376000000000332\n","3700: -25.284000000000365\n","3800: -6.19100000000031\n","3900: -15.036000000000335\n","4000: 6.467999999999738\n","4100: -21.734000000000357\n","4200: -19.78600000000035\n","4300: -23.286000000000353\n","4400: -18.560000000000347\n","4500: -17.78700000000034\n","4600: -12.99300000000033\n","4700: -20.57000000000035\n","4800: -4.614000000000299\n","4900: -4.150000000000301\n","5000: 6.759999999999734\n","5100: 12.169999999999742\n","5200: -7.400000000000311\n","5300: -1.3350000000002933\n","5400: 22.48999999999977\n","5500: 20.68899999999977\n","5600: 20.87999999999978\n","5700: 12.319999999999748\n","5800: 15.688999999999758\n","5900: 29.4099999999998\n","6000: 25.11999999999979\n","6100: 32.43099999999981\n","6200: 18.550999999999775\n","6300: 33.71799999999982\n","6400: 43.456999999999844\n","6500: 36.062999999999825\n","6600: 38.47599999999982\n","6700: 36.81199999999982\n","6800: 50.037999999999855\n","6900: 46.299999999999855\n","7000: 38.431999999999825\n","7100: 42.62499999999986\n","7200: 25.952999999999783\n","7300: 15.539999999999763\n","7400: 0.2519999999997157\n","7500: 1.4249999999997192\n","7600: -3.541000000000302\n","7700: -16.165000000000337\n","7800: -10.184000000000319\n","7900: 1.8259999999997125\n","8000: -25.91900000000037\n","8100: -9.69700000000032\n","8200: -21.096000000000355\n","8300: -17.161000000000353\n","8400: -10.557000000000322\n","8500: 16.67899999999976\n","8600: 19.95499999999977\n","8700: 30.751999999999803\n","8800: 24.26899999999978\n","8900: 39.90899999999982\n","9000: 30.0159999999998\n","9100: 32.40099999999981\n","9200: 32.70199999999981\n","9300: 28.9629999999998\n","9400: 45.95199999999987\n","9500: 52.014999999999866\n","9600: 63.04999999999992\n","9700: 77.97899999999993\n","9800: 75.76399999999995\n","9900: 74.69699999999995\n","100: -46.36400000000042\n","200: -34.7250000000004\n","300: -23.381000000000373\n","400: -9.009000000000325\n","500: -23.922000000000377\n","600: -24.734000000000368\n","700: -20.31800000000036\n","800: -15.209000000000344\n","900: 0.11999999999969788\n","1000: 1.82099999999971\n","1100: 2.9149999999997265\n","1200: -8.75000000000031\n","1300: 2.8479999999997276\n","1400: 2.99799999999973\n","1500: 14.077999999999763\n","1600: -3.1190000000002907\n","1700: -8.10900000000031\n","1800: 0.3169999999997208\n","1900: 3.7269999999997263\n","2000: 9.69999999999974\n","2100: -30.354000000000386\n","2200: -9.438000000000311\n","2300: 3.969999999999731\n","2400: 20.02499999999978\n","2500: 10.891999999999745\n","2600: 10.33599999999975\n","2700: 21.905999999999786\n","2800: 17.618999999999765\n","2900: 3.5329999999997237\n","3000: 9.67799999999975\n","3100: 13.78799999999976\n","3200: 15.984999999999765\n","3300: 35.785999999999824\n","3400: 7.698999999999739\n","3500: 17.878999999999767\n","3600: 22.296999999999784\n","3700: 31.190999999999814\n","3800: 47.12799999999987\n","3900: 32.383999999999816\n","4000: 46.61499999999987\n","4100: 57.09299999999989\n","4200: 60.14299999999991\n","4300: 56.728999999999886\n","4400: 44.59399999999985\n","4500: 48.70199999999986\n","4600: 34.58899999999982\n","4700: 26.933999999999795\n","4800: 25.68399999999979\n","4900: 25.12699999999979\n","5000: 24.913999999999792\n","5100: 20.855999999999778\n","5200: 19.202999999999772\n","5300: 12.13099999999975\n","5400: 1.8489999999997218\n","5500: 10.407999999999745\n","5600: 18.242999999999768\n","5700: 17.40099999999976\n","5800: 8.638999999999736\n","5900: 42.419999999999845\n","6000: 20.763999999999772\n","6100: 25.118999999999787\n","6200: 19.35699999999977\n","6300: 21.65899999999978\n","6400: 24.537999999999787\n","6500: 55.844999999999885\n","6600: 49.08199999999986\n","6700: 57.70299999999989\n","6800: 56.48299999999989\n","6900: 61.4099999999999\n","7000: 62.8789999999999\n","7100: 62.92199999999992\n","7200: 64.35299999999991\n","7300: 71.25399999999993\n","7400: 72.79899999999994\n","7500: 83.76599999999996\n","Solved after 7558 episodes!\n","3 noise_hrl: {'both': {0.0: [84.39799999998418, 91.60399999999292], 0.05: [81.24299999998449, 63.81999999998437], 0.1: [46.06900000000408, 33.979000000011816], 0.15: [13.369000000000169, -5.725000000002775], 0.2: [-10.648999999998377, -27.662999999977302], 0.25: [-17.678999999987738, -20.92799999998064], 0.3: [-20.908999999990577, -20.545999999982314], 0.35: [-20.208999999985984, -35.75499999997244], 0.4: [-25.34099999997451, -26.208999999979678], 0.45: [-30.237999999972754, -23.830999999984925], 0.5: [-33.726999999971355, -40.25199999997113]}, 'action_only': {0.0: [86.16799999998634, 89.44599999998574], 0.05: [73.67299999998892, 65.41999999998957], 0.1: [56.122999999992565, 16.78699999999977], 0.15: [10.931000000016843, -5.5000000000030855], 0.2: [-9.454000000002548, -26.497999999983094], 0.25: [-14.475999999993476, -27.526999999975914], 0.3: [-25.45199999998025, -27.567999999981854], 0.35: [-31.010999999973656, -26.352999999972408], 0.4: [-24.91999999997124, -27.19699999998373], 0.45: [-29.95299999997211, -23.658999999982566], 0.5: [-32.359999999975926, -29.46599999997592]}, 'goal_only': {0.0: [87.6469999999883, 90.82399999999171], 0.05: [91.30799999999286, 95.12799999999211], 0.1: [86.96999999998779, 96.89199999999455], 0.15: [77.02799999998477, 92.26399999998962], 0.2: [88.67399999998693, 88.262999999986], 0.25: [85.80399999998794, 73.80099999998896], 0.3: [79.82499999999318, 84.04999999998958], 0.35: [85.83899999998896, 83.68399999998181], 0.4: [82.58499999998689, 75.28999999999246], 0.45: [73.90899999999519, 73.23599999998838], 0.5: [75.28099999998858, 76.72299999998471]}, 'both_same': {0.0: [84.55599999998685, 92.08999999999008], 0.05: [66.33999999999033, 52.67099999999499], 0.1: [50.61099999998198, 21.270000000015894], 0.15: [33.915000000012874, -16.097999999999498], 0.2: [2.9809999999990064, -27.500999999983897], 0.25: [-17.112999999980925, -22.356999999981568], 0.3: [-28.638999999981007, -28.23399999997186], 0.35: [-29.027999999979098, -24.964999999981796], 0.4: [-27.97499999997789, -24.17699999998227], 0.45: [-36.01499999997246, -30.09699999997815], 0.5: [-36.41299999996897, -33.76599999997054]}}\n","100: -46.42300000000042\n","200: -30.86900000000039\n","300: -24.062000000000367\n","400: -15.932000000000352\n","500: -6.721000000000307\n","600: -15.743000000000338\n","700: -18.925000000000356\n","800: -17.19800000000035\n","900: -26.81300000000038\n","1000: -7.48000000000031\n","1100: -5.750000000000297\n","1200: -9.40200000000032\n","1300: -8.899000000000317\n","1400: 4.315999999999731\n","1500: -20.73600000000035\n","1600: -29.671000000000376\n","1700: -20.556000000000353\n","1800: -28.548000000000375\n","1900: -23.23200000000036\n","2000: -19.119000000000348\n","2100: -5.302000000000302\n","2200: -12.56700000000033\n","2300: -21.038000000000352\n","2400: -28.45700000000038\n","2500: -21.505000000000354\n","2600: -24.267000000000365\n","2700: -11.96900000000033\n","2800: -25.18200000000037\n","2900: -19.305000000000348\n","3000: -17.336000000000343\n","3100: -15.303000000000338\n","3200: -6.9530000000003085\n","3300: -1.200000000000291\n","3400: -3.368000000000304\n","3500: 1.4789999999997172\n","3600: -11.91300000000032\n","3700: -19.94000000000035\n","3800: -23.692000000000363\n","3900: -27.32600000000038\n","4000: -31.40300000000039\n","4100: -33.2320000000004\n","4200: -23.51000000000036\n","4300: -21.198000000000363\n","4400: -19.42200000000036\n","4500: -4.944000000000302\n","4600: 3.828999999999723\n","4700: -4.384000000000301\n","4800: 3.057999999999717\n","4900: 10.874999999999746\n","5000: -12.667000000000325\n","5100: -14.23200000000033\n","5200: -12.653000000000329\n","5300: -0.2600000000002885\n","5400: 6.064999999999737\n","5500: 11.26299999999974\n","5600: 0.6939999999997184\n","5700: -5.039000000000307\n","5800: -25.366000000000362\n","5900: -5.6130000000003\n","6000: -2.79000000000031\n","6100: -0.9700000000002995\n","6200: 9.170999999999726\n","6300: 5.421999999999724\n","6400: 29.3399999999998\n","6500: 30.606999999999807\n","6600: 15.476999999999757\n","6700: 30.44499999999981\n","6800: 47.45399999999988\n","6900: 34.610999999999834\n","7000: 46.45599999999985\n","7100: 48.30399999999987\n","7200: 48.945999999999884\n","7300: 57.976999999999904\n","7400: 77.03199999999995\n","7500: 67.42299999999993\n","7600: 72.08899999999993\n","7700: 69.69199999999994\n","7800: 72.59299999999996\n","7900: 50.92499999999988\n","8000: 38.02699999999984\n","8100: 45.34399999999983\n","8200: 71.17199999999994\n","8300: 73.05099999999995\n","8400: 71.56299999999993\n","8500: 66.68099999999993\n","8600: 78.88599999999995\n","8700: 61.2869999999999\n","8800: 68.80199999999991\n","8900: 78.95899999999996\n","9000: 69.68099999999991\n","9100: 71.09499999999994\n","9200: 69.51499999999993\n","9300: 67.1179999999999\n","9400: 71.71199999999993\n","9500: 72.82599999999994\n","9600: 75.78999999999994\n","9700: 84.60599999999997\n","9800: 86.00599999999997\n","9900: 89.05099999999999\n","Solved after 9907 episodes!\n","4 noise_hrl: {'both': {0.0: [84.39799999998418, 91.60399999999292, 89.26899999998801], 0.05: [81.24299999998449, 63.81999999998437, 87.1229999999881], 0.1: [46.06900000000408, 33.979000000011816, 48.29699999999753], 0.15: [13.369000000000169, -5.725000000002775, 29.801000000006514], 0.2: [-10.648999999998377, -27.662999999977302, 4.829999999999236], 0.25: [-17.678999999987738, -20.92799999998064, -9.39600000000651], 0.3: [-20.908999999990577, -20.545999999982314, 1.8349999999951092], 0.35: [-20.208999999985984, -35.75499999997244, -4.661000000002129], 0.4: [-25.34099999997451, -26.208999999979678, -19.08299999999252], 0.45: [-30.237999999972754, -23.830999999984925, -8.775000000005582], 0.5: [-33.726999999971355, -40.25199999997113, -28.36499999998271]}, 'action_only': {0.0: [86.16799999998634, 89.44599999998574, 89.33399999999011], 0.05: [73.67299999998892, 65.41999999998957, 79.8419999999934], 0.1: [56.122999999992565, 16.78699999999977, 46.66900000000867], 0.15: [10.931000000016843, -5.5000000000030855, 27.628000000015273], 0.2: [-9.454000000002548, -26.497999999983094, 9.278999999996678], 0.25: [-14.475999999993476, -27.526999999975914, 3.811999999995667], 0.3: [-25.45199999998025, -27.567999999981854, -5.046000000006478], 0.35: [-31.010999999973656, -26.352999999972408, -7.0920000000031225], 0.4: [-24.91999999997124, -27.19699999998373, -6.97800000000537], 0.45: [-29.95299999997211, -23.658999999982566, -7.250000000003798], 0.5: [-32.359999999975926, -29.46599999997592, -14.10699999999513]}, 'goal_only': {0.0: [87.6469999999883, 90.82399999999171, 93.744999999995], 0.05: [91.30799999999286, 95.12799999999211, 88.49999999999314], 0.1: [86.96999999998779, 96.89199999999455, 91.86199999999143], 0.15: [77.02799999998477, 92.26399999998962, 96.2089999999954], 0.2: [88.67399999998693, 88.262999999986, 89.1079999999946], 0.25: [85.80399999998794, 73.80099999998896, 93.47599999999574], 0.3: [79.82499999999318, 84.04999999998958, 92.00799999999109], 0.35: [85.83899999998896, 83.68399999998181, 93.53999999999348], 0.4: [82.58499999998689, 75.28999999999246, 85.93599999999105], 0.45: [73.90899999999519, 73.23599999998838, 83.16799999999648], 0.5: [75.28099999998858, 76.72299999998471, 90.52399999999139]}, 'both_same': {0.0: [84.55599999998685, 92.08999999999008, 92.05499999998777], 0.05: [66.33999999999033, 52.67099999999499, 76.95199999998873], 0.1: [50.61099999998198, 21.270000000015894, 49.21399999998093], 0.15: [33.915000000012874, -16.097999999999498, 39.41400000001159], 0.2: [2.9809999999990064, -27.500999999983897, 20.0410000000179], 0.25: [-17.112999999980925, -22.356999999981568, 10.370000000017317], 0.3: [-28.638999999981007, -28.23399999997186, 4.966000000003962], 0.35: [-29.027999999979098, -24.964999999981796, -2.8960000000058455], 0.4: [-27.97499999997789, -24.17699999998227, -0.023000000006989985], 0.45: [-36.01499999997246, -30.09699999997815, -9.765999999988287], 0.5: [-36.41299999996897, -33.76599999997054, -14.336999999996248]}}\n","100: -42.70400000000041\n","200: -36.07900000000041\n","300: -25.257000000000374\n","400: -23.388000000000375\n","500: -15.416000000000343\n","600: 8.069999999999736\n","700: 10.092999999999742\n","800: -10.053000000000328\n","900: -24.38900000000037\n","1000: -35.422000000000395\n","1100: -31.40100000000039\n","1200: -28.963000000000378\n","1300: -22.534000000000365\n","1400: -27.025000000000386\n","1500: -14.108000000000331\n","1600: -11.509000000000333\n","1700: -19.538000000000345\n","1800: -27.11900000000037\n","1900: -17.66800000000034\n","2000: -30.19200000000039\n","2100: -20.495000000000346\n","2200: -15.789000000000337\n","2300: -25.82000000000037\n","2400: -22.058000000000348\n","2500: -30.899000000000388\n","2600: -26.947000000000372\n","2700: -20.993000000000357\n","2800: -25.154000000000366\n","2900: -17.997000000000348\n","3000: -25.145000000000366\n","3100: -22.858000000000366\n","3200: -27.38200000000037\n","3300: -19.222000000000342\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-24cef9ce6404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#agent = HIRO(n_observations, n_actions).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#load_model(agent, f\"hiro_freeze_{i}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-199f0e27ac7c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mgoal_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverall_intrinsic\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepisode_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-dd6e698b382c>\u001b[0m in \u001b[0;36mteach_controller\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteach_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteach_meta_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff_policy_corrections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-0db120f86941>\u001b[0m in \u001b[0;36mupdate_policy\u001b[0;34m(self, off_policy_correction)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Delayed policy updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"52wvCFTmBoRh"},"source":["Solved after 8608 episodes!\n","Solved after 7321 episodes!\n","1 noise_hrl: {'both': {0.0: [86.3469999999895, 87.65399999998935], 0.05: [55.524999999985376, 74.7739999999933], 0.1: [24.802000000008366, 55.677000000000916], 0.15: [-1.874000000001195, 58.548999999982826], 0.2: [-26.797999999980362, 56.17599999999996], 0.25: [-27.88699999998136, 22.825000000012075], 0.3: [-35.85899999996834, 29.907000000016346], 0.35: [-28.625999999977736, 16.396000000008303], 0.4: [-38.03599999996919, -5.017000000005212], 0.45: [-33.44099999997778, -9.225000000006728], 0.5: [-38.69199999996758, -21.327999999988982]}, 'action_only': {0.0: [79.6429999999958, 94.0169999999898], 0.05: [61.07699999998948, 70.41599999999465], 0.1: [17.214000000005058, 57.116999999985964], 0.15: [-9.359000000004709, 60.63999999998295], 0.2: [-19.129999999992027, 55.055999999994555], 0.25: [-27.182999999975063, 33.216000000015825], 0.3: [-29.666999999980558, 26.390000000018247], 0.35: [-40.639999999969625, 7.551999999994045], 0.4: [-34.6259999999731, 1.4060000000002901], 0.45: [-40.4169999999701, -3.8350000000067213], 0.5: [-38.426999999971706, -15.964999999984284]}, 'goal_only': {0.0: [85.49999999998208, 90.27299999998779], 0.05: [73.7489999999876, 86.13199999998803], 0.1: [90.36599999998974, 94.00499999999145], 0.15: [79.74099999998283, 88.13899999998452], 0.2: [83.35299999999079, 86.9519999999878], 0.25: [91.39099999998592, 75.3839999999887], 0.3: [93.32899999998921, 85.58099999999193], 0.35: [88.41699999999129, 82.73099999998767], 0.4: [94.34699999999287, 75.23299999999354], 0.45: [90.43399999998728, 69.14999999998544], 0.5: [76.46999999999348, 76.51199999999781]}, 'both_same': {0.0: [79.26799999998829, 88.93599999998618], 0.05: [65.02099999999031, 79.44799999998877], 0.1: [30.39500000000683, 60.743999999989825], 0.15: [-9.751000000007506, 62.986999999985464], 0.2: [-19.30999999998804, 44.62099999998817], 0.25: [-26.904999999973917, 37.94800000001537], 0.3: [-36.647999999968626, 16.14300000001135], 0.35: [-22.282999999974464, 15.069000000016723], 0.4: [-32.69299999997167, -6.546000000001744], 0.45: [-38.29099999997223, -8.963999999998231], 0.5: [-32.8609999999713, -8.572000000001363]}}\n","Solved after 8525 episodes!\n","Solved after 7558 episodes!\n","Solved after 9907 episodes!\n","4 noise_hrl: {'both': {0.0: [84.39799999998418, 91.60399999999292, 89.26899999998801], 0.05: [81.24299999998449, 63.81999999998437, 87.1229999999881], 0.1: [46.06900000000408, 33.979000000011816, 48.29699999999753], 0.15: [13.369000000000169, -5.725000000002775, 29.801000000006514], 0.2: [-10.648999999998377, -27.662999999977302, 4.829999999999236], 0.25: [-17.678999999987738, -20.92799999998064, -9.39600000000651], 0.3: [-20.908999999990577, -20.545999999982314, 1.8349999999951092], 0.35: [-20.208999999985984, -35.75499999997244, -4.661000000002129], 0.4: [-25.34099999997451, -26.208999999979678, -19.08299999999252], 0.45: [-30.237999999972754, -23.830999999984925, -8.775000000005582], 0.5: [-33.726999999971355, -40.25199999997113, -28.36499999998271]}, 'action_only': {0.0: [86.16799999998634, 89.44599999998574, 89.33399999999011], 0.05: [73.67299999998892, 65.41999999998957, 79.8419999999934], 0.1: [56.122999999992565, 16.78699999999977, 46.66900000000867], 0.15: [10.931000000016843, -5.5000000000030855, 27.628000000015273], 0.2: [-9.454000000002548, -26.497999999983094, 9.278999999996678], 0.25: [-14.475999999993476, -27.526999999975914, 3.811999999995667], 0.3: [-25.45199999998025, -27.567999999981854, -5.046000000006478], 0.35: [-31.010999999973656, -26.352999999972408, -7.0920000000031225], 0.4: [-24.91999999997124, -27.19699999998373, -6.97800000000537], 0.45: [-29.95299999997211, -23.658999999982566, -7.250000000003798], 0.5: [-32.359999999975926, -29.46599999997592, -14.10699999999513]}, 'goal_only': {0.0: [87.6469999999883, 90.82399999999171, 93.744999999995], 0.05: [91.30799999999286, 95.12799999999211, 88.49999999999314], 0.1: [86.96999999998779, 96.89199999999455, 91.86199999999143], 0.15: [77.02799999998477, 92.26399999998962, 96.2089999999954], 0.2: [88.67399999998693, 88.262999999986, 89.1079999999946], 0.25: [85.80399999998794, 73.80099999998896, 93.47599999999574], 0.3: [79.82499999999318, 84.04999999998958, 92.00799999999109], 0.35: [85.83899999998896, 83.68399999998181, 93.53999999999348], 0.4: [82.58499999998689, 75.28999999999246, 85.93599999999105], 0.45: [73.90899999999519, 73.23599999998838, 83.16799999999648], 0.5: [75.28099999998858, 76.72299999998471, 90.52399999999139]}, 'both_same': {0.0: [84.55599999998685, 92.08999999999008, 92.05499999998777], 0.05: [66.33999999999033, 52.67099999999499, 76.95199999998873], 0.1: [50.61099999998198, 21.270000000015894, 49.21399999998093], 0.15: [33.915000000012874, -16.097999999999498, 39.41400000001159], 0.2: [2.9809999999990064, -27.500999999983897, 20.0410000000179], 0.25: [-17.112999999980925, -22.356999999981568, 10.370000000017317], 0.3: [-28.638999999981007, -28.23399999997186, 4.966000000003962], 0.35: [-29.027999999979098, -24.964999999981796, -2.8960000000058455], 0.4: [-27.97499999997789, -24.17699999998227, -0.023000000006989985], 0.45: [-36.01499999997246, -30.09699999997815, -9.765999999988287], 0.5: [-36.41299999996897, -33.76599999997054, -14.336999999996248]}}\n","...\n","Solved after 9584 episodes!\n","Solved after 8327 episodes!\n","6 noise_hrl: {'both': {0.0: [88.74599999998608, 82.8799999999944], 0.05: [41.05300000000923, 29.047000000017405], 0.1: [22.91600000001603, 23.634000000015444], 0.15: [-2.393000000003058, 15.102000000003233], 0.2: [-15.586999999986508, 6.132999999996659], 0.25: [-23.793999999983075, -9.679000000005368], 0.3: [-25.64999999997912, -20.640999999977566], 0.35: [-30.269999999973102, -25.930999999988153], 0.4: [-31.572999999975192, -20.195999999984856], 0.45: [-33.13399999997293, -29.55499999997742], 0.5: [-32.52299999997181, -21.92599999997624]}, 'action_only': {0.0: [85.35299999999093, 80.03899999998228], 0.05: [35.81100000001877, 32.036000000015875], 0.1: [7.328999999997956, 27.08700000001365], 0.15: [-6.937000000006416, 14.70000000000065], 0.2: [-23.018999999982128, -4.39200000000317], 0.25: [-26.143999999972852, -9.280000000004925], 0.3: [-15.495999999986859, -12.578999999991717], 0.35: [-14.878999999990691, -23.083999999981415], 0.4: [-23.958999999976573, -18.15899999997716], 0.45: [-40.337999999970236, -20.479999999989044], 0.5: [-37.4899999999682, -20.309999999987678]}, 'goal_only': {0.0: [88.5589999999948, 76.8569999999862], 0.05: [91.12199999998634, 86.38599999999033], 0.1: [93.16699999998929, 83.09399999998537], 0.15: [92.15199999999291, 79.9049999999913], 0.2: [87.40299999998467, 81.41399999998505], 0.25: [90.52799999998905, 68.79999999997658], 0.3: [84.34499999999312, 72.6959999999797], 0.35: [84.58599999998464, 71.1739999999851], 0.4: [91.74999999999517, 73.50499999999285], 0.45: [89.57099999999318, 68.29699999999609], 0.5: [84.93699999998427, 62.84499999999364]}, 'both_same': {0.0: [88.02199999998318, 71.5009999999796], 0.05: [50.38699999999266, 17.033000000007473], 0.1: [8.824000000003691, 6.6549999999985445], 0.15: [-6.045000000004539, 14.105000000000341], 0.2: [-14.559999999982583, -4.93200000000467], 0.25: [-23.125999999976575, -8.962000000004327], 0.3: [-34.607999999974524, -15.90099999998204], 0.35: [-33.547999999973314, -15.44899999999859], 0.4: [-32.10699999997676, -19.078999999984436], 0.45: [-31.193999999974068, -15.150999999991019], 0.5: [-35.047999999971346, -32.65699999997801]}}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhC6f7N6sJoa","executionInfo":{"status":"ok","timestamp":1617445398836,"user_tz":-60,"elapsed":12865396,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"b6d75350-9033-4d7d-b3e9-10fd54c5c0ec"},"source":["targeted = {'goal': {}, 'action': {}}\n","untargeted = {'goal': {}, 'action': {}}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    for x in ['goal', 'action']:\n","        targeted[x][eps] = []\n","        untargeted[x][eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        apply_fgsm(agent, untargeted['action'], False)   \n","        print(f\"{i} fgsm (ut): {untargeted}\")\n","\n","        apply_fgsm(agent, targeted['action'], True)   \n","        print(f\"{i} fgsm (t): {targeted}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"fgsm (ut): {untargeted}\")\n","print(f\"fgsm (t): {targeted}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944], 0.02: [23.447000000012828], 0.04: [-19.637999999989162], 0.06: [-31.40499999997273], 0.08: [-39.537999999970914], 0.1: [-44.25499999998204], 0.12: [-47.54600000000038], 0.14: [-39.11599999996947], 0.16: [-43.18899999997968], 0.18: [-48.90400000000169], 0.2: [-43.070999999977055]}}\n","0 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999], 0.02: [70.7049999999916], 0.04: [54.36999999999334], 0.06: [20.67700000001389], 0.08: [-10.994000000001629], 0.1: [-23.623999999975545], 0.12: [-27.37599999997537], 0.14: [-34.46299999997086], 0.16: [-28.70299999997426], 0.18: [-38.80299999997152], 0.2: [-45.982999999995265]}}\n","1 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699], 0.02: [23.447000000012828, 68.72999999997602], 0.04: [-19.637999999989162, 30.153000000017027], 0.06: [-31.40499999997273, 7.875999999993737], 0.08: [-39.537999999970914, -6.2580000000082405], 0.1: [-44.25499999998204, -13.274999999995554], 0.12: [-47.54600000000038, -20.095999999986997], 0.14: [-39.11599999996947, -29.6009999999805], 0.16: [-43.18899999997968, -22.701999999972486], 0.18: [-48.90400000000169, -6.072000000004152], 0.2: [-43.070999999977055, -6.088000000005629]}}\n","1 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236], 0.02: [70.7049999999916, 82.84499999998019], 0.04: [54.36999999999334, 64.93599999999796], 0.06: [20.67700000001389, 52.75599999999038], 0.08: [-10.994000000001629, 36.1220000000105], 0.1: [-23.623999999975545, 17.00300000000361], 0.12: [-27.37599999997537, 0.9269999999970665], 0.14: [-34.46299999997086, -3.8530000000002427], 0.16: [-28.70299999997426, -7.080000000003926], 0.18: [-38.80299999997152, -6.978000000007928], 0.2: [-45.982999999995265, -6.028000000002816]}}\n","2 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567]}}\n","2 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068]}}\n","3 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866, 88.64699999998987], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087, 36.59300000001905], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004, 1.7989999999984747], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878, -22.43699999998859], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497, -40.83599999996841], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523, -38.667999999968735], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942, -47.80099999999677], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871, -39.851999999969486], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727, -46.158999999998976], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925, -44.81199999998635], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567, -44.30899999998133]}}\n","3 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759, 95.94799999999238], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082, 86.67499999998881], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568, 59.599999999985044], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875, 56.01999999998311], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195, 16.038000000007397], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437, 13.682000000011767], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036, -6.997000000007259], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873, -23.142999999980344], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495, -28.722999999975485], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792, -26.23699999997413], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068, -27.563999999976566]}}\n","4 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866, 88.64699999998987, 89.20899999999179], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087, 36.59300000001905, 86.24899999998615], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004, 1.7989999999984747, 75.673999999973], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878, -22.43699999998859, 57.51300000000258], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497, -40.83599999996841, 14.117000000002104], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523, -38.667999999968735, 1.204000000000723], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942, -47.80099999999677, -30.15599999997159], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871, -39.851999999969486, -37.967999999970274], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727, -46.158999999998976, -45.43099999998746], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925, -44.81199999998635, -44.77499999998394], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567, -44.30899999998133, -44.1049999999843]}}\n","4 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759, 95.94799999999238, 89.52699999999521], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082, 86.67499999998881, 79.57699999998749], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568, 59.599999999985044, 70.75699999999459], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875, 56.01999999998311, 68.34899999998629], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195, 16.038000000007397, 58.876999999987355], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437, 13.682000000011767, 39.37500000001748], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036, -6.997000000007259, 24.03800000001666], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873, -23.142999999980344, 0.9579999999963646], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495, -28.722999999975485, -17.85099999999503], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792, -26.23699999997413, -23.659999999982098], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068, -27.563999999976566, -19.806999999978842]}}\n","5 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866, 88.64699999998987, 89.20899999999179, 86.19699999998588], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087, 36.59300000001905, 86.24899999998615, 6.93399999999711], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004, 1.7989999999984747, 75.673999999973, -32.94399999997325], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878, -22.43699999998859, 57.51300000000258, -47.104999999994234], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497, -40.83599999996841, 14.117000000002104, -48.563000000005], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523, -38.667999999968735, 1.204000000000723, -50.00000000000659], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942, -47.80099999999677, -30.15599999997159, -50.00000000000659], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871, -39.851999999969486, -37.967999999970274, -50.00000000000659], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727, -46.158999999998976, -45.43099999998746, -50.00000000000659], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925, -44.81199999998635, -44.77499999998394, -50.00000000000659], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567, -44.30899999998133, -44.1049999999843, -50.00000000000659]}}\n","5 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759, 95.94799999999238, 89.52699999999521, 90.27299999999076], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082, 86.67499999998881, 79.57699999998749, 61.351999999991506], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568, 59.599999999985044, 70.75699999999459, 34.508000000016324], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875, 56.01999999998311, 68.34899999998629, 27.7420000000162], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195, 16.038000000007397, 58.876999999987355, 24.999000000013567], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437, 13.682000000011767, 39.37500000001748, -18.58599999998739], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036, -6.997000000007259, 24.03800000001666, -28.200999999977075], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873, -23.142999999980344, 0.9579999999963646, -34.050999999975176], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495, -28.722999999975485, -17.85099999999503, -41.98899999997297], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792, -26.23699999997413, -23.659999999982098, -44.66999999998647], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068, -27.563999999976566, -19.806999999978842, -44.93399999998906]}}\n","6 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866, 88.64699999998987, 89.20899999999179, 86.19699999998588, 87.25799999999273], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087, 36.59300000001905, 86.24899999998615, 6.93399999999711, 61.92399999998572], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004, 1.7989999999984747, 75.673999999973, -32.94399999997325, 42.70000000001441], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878, -22.43699999998859, 57.51300000000258, -47.104999999994234, 25.322000000017898], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497, -40.83599999996841, 14.117000000002104, -48.563000000005, 5.886999999997783], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523, -38.667999999968735, 1.204000000000723, -50.00000000000659, -24.875999999975775], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942, -47.80099999999677, -30.15599999997159, -50.00000000000659, -38.29499999996997], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871, -39.851999999969486, -37.967999999970274, -50.00000000000659, -39.87299999996947], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727, -46.158999999998976, -45.43099999998746, -50.00000000000659, -40.16799999996918], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925, -44.81199999998635, -44.77499999998394, -50.00000000000659, -42.697999999978336], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567, -44.30899999998133, -44.1049999999843, -50.00000000000659, -46.346999999991446]}}\n","6 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759, 95.94799999999238, 89.52699999999521, 90.27299999999076, 83.06699999998759], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082, 86.67499999998881, 79.57699999998749, 61.351999999991506, 57.44199999998243], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568, 59.599999999985044, 70.75699999999459, 34.508000000016324, 58.362999999994045], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875, 56.01999999998311, 68.34899999998629, 27.7420000000162, 39.76400000001761], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195, 16.038000000007397, 58.876999999987355, 24.999000000013567, 33.47500000001383], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437, 13.682000000011767, 39.37500000001748, -18.58599999998739, 21.19500000001973], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036, -6.997000000007259, 24.03800000001666, -28.200999999977075, 8.085999999995579], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873, -23.142999999980344, 0.9579999999963646, -34.050999999975176, 4.015999999994208], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495, -28.722999999975485, -17.85099999999503, -41.98899999997297, 7.518999999998274], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792, -26.23699999997413, -23.659999999982098, -44.66999999998647, 4.287999999998551], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068, -27.563999999976566, -19.806999999978842, -44.93399999998906, -8.103000000006652]}}\n","----\n","fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [82.87999999998944, 84.93899999998699, 86.3959999999866, 88.64699999998987, 89.20899999999179, 86.19699999998588, 87.25799999999273], 0.02: [23.447000000012828, 68.72999999997602, 26.115000000013087, 36.59300000001905, 86.24899999998615, 6.93399999999711, 61.92399999998572], 0.04: [-19.637999999989162, 30.153000000017027, 15.666000000004, 1.7989999999984747, 75.673999999973, -32.94399999997325, 42.70000000001441], 0.06: [-31.40499999997273, 7.875999999993737, -16.737999999993878, -22.43699999998859, 57.51300000000258, -47.104999999994234, 25.322000000017898], 0.08: [-39.537999999970914, -6.2580000000082405, -36.12799999997497, -40.83599999996841, 14.117000000002104, -48.563000000005, 5.886999999997783], 0.1: [-44.25499999998204, -13.274999999995554, -35.06499999997523, -38.667999999968735, 1.204000000000723, -50.00000000000659, -24.875999999975775], 0.12: [-47.54600000000038, -20.095999999986997, -37.64699999996942, -47.80099999999677, -30.15599999997159, -50.00000000000659, -38.29499999996997], 0.14: [-39.11599999996947, -29.6009999999805, -39.70099999996871, -39.851999999969486, -37.967999999970274, -50.00000000000659, -39.87299999996947], 0.16: [-43.18899999997968, -22.701999999972486, -36.5409999999727, -46.158999999998976, -45.43099999998746, -50.00000000000659, -40.16799999996918], 0.18: [-48.90400000000169, -6.072000000004152, -39.79699999996925, -44.81199999998635, -44.77499999998394, -50.00000000000659, -42.697999999978336], 0.2: [-43.070999999977055, -6.088000000005629, -36.54199999997567, -44.30899999998133, -44.1049999999843, -50.00000000000659, -46.346999999991446]}}\n","fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [79.21899999999, 94.41399999999236, 81.95399999999759, 95.94799999999238, 89.52699999999521, 90.27299999999076, 83.06699999998759], 0.02: [70.7049999999916, 82.84499999998019, 86.06499999999082, 86.67499999998881, 79.57699999998749, 61.351999999991506, 57.44199999998243], 0.04: [54.36999999999334, 64.93599999999796, 73.02499999997568, 59.599999999985044, 70.75699999999459, 34.508000000016324, 58.362999999994045], 0.06: [20.67700000001389, 52.75599999999038, 21.845000000009875, 56.01999999998311, 68.34899999998629, 27.7420000000162, 39.76400000001761], 0.08: [-10.994000000001629, 36.1220000000105, 3.6319999999996195, 16.038000000007397, 58.876999999987355, 24.999000000013567, 33.47500000001383], 0.1: [-23.623999999975545, 17.00300000000361, -35.04999999997437, 13.682000000011767, 39.37500000001748, -18.58599999998739, 21.19500000001973], 0.12: [-27.37599999997537, 0.9269999999970665, -40.54399999997036, -6.997000000007259, 24.03800000001666, -28.200999999977075, 8.085999999995579], 0.14: [-34.46299999997086, -3.8530000000002427, -44.33899999998873, -23.142999999980344, 0.9579999999963646, -34.050999999975176, 4.015999999994208], 0.16: [-28.70299999997426, -7.080000000003926, -48.55000000000495, -28.722999999975485, -17.85099999999503, -41.98899999997297, 7.518999999998274], 0.18: [-38.80299999997152, -6.978000000007928, -43.7219999999792, -26.23699999997413, -23.659999999982098, -44.66999999998647, 4.287999999998551], 0.2: [-45.982999999995265, -6.028000000002816, -48.62600000000068, -27.563999999976566, -19.806999999978842, -44.93399999998906, -8.103000000006652]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8pnki1eCngGQ","executionInfo":{"status":"ok","timestamp":1617453116606,"user_tz":-60,"elapsed":637,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def eval_scale(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for scale in np.arange(1.0,7.01,0.5):\n","        env = NormalizedEnv(PointPushEnv(scale))\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(scale, 2)].append(overall_reward / num_episodes)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmUPiWlPqUts","executionInfo":{"status":"ok","timestamp":1617454386165,"user_tz":-60,"elapsed":1269584,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"a9730044-eb58-4e9e-9f70-564d0322f459"},"source":["episodes = {}\n","for scale in np.arange(1.0,7.01,0.5):\n","    episodes[np.round(scale, 2)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_scale(agent, episodes)\n","        print(f\"{i} scale: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"scale: {episodes}\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["0 scale: {1.0: [8.311999999995733], 1.5: [8.463999999997394], 2.0: [37.05800000001532], 2.5: [41.425000000012176], 3.0: [71.9749999999868], 3.5: [81.74699999999113], 4.0: [83.85999999998506], 4.5: [74.47799999999648], 5.0: [89.55799999999176], 5.5: [84.67499999998314], 6.0: [84.96299999998129], 6.5: [78.30199999998203], 7.0: [71.70199999998422]}\n","1 scale: {1.0: [8.311999999995733, -34.695999999973466], 1.5: [8.463999999997394, -2.3850000000050775], 2.0: [37.05800000001532, 84.14599999999155], 2.5: [41.425000000012176, 89.92199999999156], 3.0: [71.9749999999868, 94.20299999999418], 3.5: [81.74699999999113, 92.73299999999094], 4.0: [83.85999999998506, 90.29699999999053], 4.5: [74.47799999999648, 87.62099999998861], 5.0: [89.55799999999176, 80.01399999998684], 5.5: [84.67499999998314, 80.4539999999833], 6.0: [84.96299999998129, 76.06499999998928], 6.5: [78.30199999998203, 84.98199999998687], 7.0: [71.70199999998422, 72.30399999998355]}\n","2 scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561]}\n","3 scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485, 14.657000000006022], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461, 30.24800000001275], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113, 72.77799999998525], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948, 69.90899999997225], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136, 88.93799999998835], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598, 95.70399999999272], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728, 87.38599999998894], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953, 85.89199999998827], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874, 84.16199999998597], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358, 82.96999999998806], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805, 92.81499999999279], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875, 86.77699999999417], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561, 86.54699999998664]}\n","4 scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485, 14.657000000006022, 3.9929999999963273], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461, 30.24800000001275, 47.208000000008305], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113, 72.77799999998525, 88.56399999999026], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948, 69.90899999997225, 87.5069999999851], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136, 88.93799999998835, 90.37299999999041], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598, 95.70399999999272, 93.5989999999921], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728, 87.38599999998894, 94.90799999999375], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953, 85.89199999998827, 86.67199999999437], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874, 84.16199999998597, 92.09599999998838], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358, 82.96999999998806, 89.19899999998968], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805, 92.81499999999279, 86.1419999999904], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875, 86.77699999999417, 93.30599999999227], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561, 86.54699999998664, 84.57699999999593]}\n","5 scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485, 14.657000000006022, 3.9929999999963273, -10.679000000006392], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461, 30.24800000001275, 47.208000000008305, -12.742000000002456], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113, 72.77799999998525, 88.56399999999026, 17.916000000017327], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948, 69.90899999997225, 87.5069999999851, 78.03599999997827], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136, 88.93799999998835, 90.37299999999041, 87.47899999999424], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598, 95.70399999999272, 93.5989999999921, 86.24999999998907], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728, 87.38599999998894, 94.90799999999375, 83.49699999998444], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953, 85.89199999998827, 86.67199999999437, 79.6979999999898], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874, 84.16199999998597, 92.09599999998838, 74.23999999998917], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358, 82.96999999998806, 89.19899999998968, 74.59399999998587], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805, 92.81499999999279, 86.1419999999904, 77.12999999998564], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875, 86.77699999999417, 93.30599999999227, 90.2669999999893], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561, 86.54699999998664, 84.57699999999593, 87.41499999998773]}\n","6 scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485, 14.657000000006022, 3.9929999999963273, -10.679000000006392, 5.75499999999639], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461, 30.24800000001275, 47.208000000008305, -12.742000000002456, 3.713999999994584], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113, 72.77799999998525, 88.56399999999026, 17.916000000017327, 35.372000000016], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948, 69.90899999997225, 87.5069999999851, 78.03599999997827, 58.31199999997629], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136, 88.93799999998835, 90.37299999999041, 87.47899999999424, 78.08999999998791], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598, 95.70399999999272, 93.5989999999921, 86.24999999998907, 89.54999999999187], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728, 87.38599999998894, 94.90799999999375, 83.49699999998444, 77.769999999992], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953, 85.89199999998827, 86.67199999999437, 79.6979999999898, 51.613999999991684], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874, 84.16199999998597, 92.09599999998838, 74.23999999998917, 28.2510000000109], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358, 82.96999999998806, 89.19899999998968, 74.59399999998587, -13.782999999998243], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805, 92.81499999999279, 86.1419999999904, 77.12999999998564, -20.499999999987708], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875, 86.77699999999417, 93.30599999999227, 90.2669999999893, -4.424000000003249], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561, 86.54699999998664, 84.57699999999593, 87.41499999998773, -33.882999999972405]}\n","----\n","scale: {1.0: [8.311999999995733, -34.695999999973466, 6.1029999999985485, 14.657000000006022, 3.9929999999963273, -10.679000000006392, 5.75499999999639], 1.5: [8.463999999997394, -2.3850000000050775, 38.06800000001461, 30.24800000001275, 47.208000000008305, -12.742000000002456, 3.713999999994584], 2.0: [37.05800000001532, 84.14599999999155, 73.90699999999113, 72.77799999998525, 88.56399999999026, 17.916000000017327, 35.372000000016], 2.5: [41.425000000012176, 89.92199999999156, 87.46999999998948, 69.90899999997225, 87.5069999999851, 78.03599999997827, 58.31199999997629], 3.0: [71.9749999999868, 94.20299999999418, 88.00199999999136, 88.93799999998835, 90.37299999999041, 87.47899999999424, 78.08999999998791], 3.5: [81.74699999999113, 92.73299999999094, 90.74999999999598, 95.70399999999272, 93.5989999999921, 86.24999999998907, 89.54999999999187], 4.0: [83.85999999998506, 90.29699999999053, 87.63399999998728, 87.38599999998894, 94.90799999999375, 83.49699999998444, 77.769999999992], 4.5: [74.47799999999648, 87.62099999998861, 83.3209999999953, 85.89199999998827, 86.67199999999437, 79.6979999999898, 51.613999999991684], 5.0: [89.55799999999176, 80.01399999998684, 85.9839999999874, 84.16199999998597, 92.09599999998838, 74.23999999998917, 28.2510000000109], 5.5: [84.67499999998314, 80.4539999999833, 79.88299999998358, 82.96999999998806, 89.19899999998968, 74.59399999998587, -13.782999999998243], 6.0: [84.96299999998129, 76.06499999998928, 75.28299999998805, 92.81499999999279, 86.1419999999904, 77.12999999998564, -20.499999999987708], 6.5: [78.30199999998203, 84.98199999998687, 79.40599999998875, 86.77699999999417, 93.30599999999227, 90.2669999999893, -4.424000000003249], 7.0: [71.70199999998422, 72.30399999998355, 72.08999999998561, 86.54699999998664, 84.57699999999593, 87.41499999998773, -33.882999999972405]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gd2_86AIqOt4","executionInfo":{"status":"ok","timestamp":1617454387846,"user_tz":-60,"elapsed":770,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def eval_starting_position(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for extra_range in np.arange(0.0, 0.401, 0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            extra = np.random.uniform(-0.1 - extra_range, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = np.random.uniform(0.1, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = extra * (2*np.random.randint(0,2,size=env.starting_point.shape)-1)\n","            env.unwrapped.state = np.array(env.starting_point + extra, dtype=np.float32)\n","            env.unwrapped.state[2] += math.pi / 2. # start facing up\n","            env.unwrapped.state[2] = env.state[2] % (2 * math.pi)\n","            observation = env.normalised_state()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(extra_range, 3)].append(overall_reward / num_episodes)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJjpZcCLqjua","executionInfo":{"status":"ok","timestamp":1617455175108,"user_tz":-60,"elapsed":788019,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"e6e956d5-cf51-4e25-b5d6-35f692467ad6"},"source":["episodes = {}\n","for extra_range in np.arange(0.0, 0.401, 0.05):\n","    episodes[np.round(extra_range, 3)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","env = NormalizedEnv(PointPushEnv(4))\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_starting_position(agent, episodes)\n","        print(f\"{i} range: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"range: {episodes}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["0 range: {0.0: [85.04899999998874], 0.05: [77.76299999998585], 0.1: [77.93999999998756], 0.15: [66.57199999999374], 0.2: [54.99799999999712], 0.25: [70.42100000000063], 0.3: [54.90199999998741], 0.35: [50.533000000004535], 0.4: [57.31599999998752]}\n","1 range: {0.0: [85.04899999998874, 86.22499999998706], 0.05: [77.76299999998585, 90.06999999998408], 0.1: [77.93999999998756, 86.28199999998846], 0.15: [66.57199999999374, 82.01399999997837], 0.2: [54.99799999999712, 75.09299999998919], 0.25: [70.42100000000063, 70.28999999998335], 0.3: [54.90199999998741, 52.96599999999454], 0.35: [50.533000000004535, 40.31400000001508], 0.4: [57.31599999998752, 36.1020000000172]}\n","2 range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349]}\n","3 range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735, 90.20399999999412], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479, 74.66299999998876], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273, 79.8029999999843], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028, 74.24199999998633], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479, 67.04299999998996], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113, 74.18999999998745], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515, 53.01399999998791], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604, 48.9439999999919], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349, 43.29300000000907]}\n","4 range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735, 90.20399999999412, 92.28699999999375], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479, 74.66299999998876, 87.85099999998802], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273, 79.8029999999843, 83.44299999998968], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028, 74.24199999998633, 89.29399999998869], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479, 67.04299999998996, 74.41299999998631], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113, 74.18999999998745, 74.20099999998574], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515, 53.01399999998791, 66.93999999998067], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604, 48.9439999999919, 75.66199999998734], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349, 43.29300000000907, 71.29099999998752]}\n","5 range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735, 90.20399999999412, 92.28699999999375, 93.3999999999895], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479, 74.66299999998876, 87.85099999998802, 79.19899999998674], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273, 79.8029999999843, 83.44299999998968, 82.4399999999879], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028, 74.24199999998633, 89.29399999998869, 61.47499999999331], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479, 67.04299999998996, 74.41299999998631, 63.982999999994696], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113, 74.18999999998745, 74.20099999998574, 56.97099999998479], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515, 53.01399999998791, 66.93999999998067, 68.51899999998204], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604, 48.9439999999919, 75.66199999998734, 50.021000000001884], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349, 43.29300000000907, 71.29099999998752, 51.010000000002336]}\n","6 range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735, 90.20399999999412, 92.28699999999375, 93.3999999999895, 80.75599999999025], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479, 74.66299999998876, 87.85099999998802, 79.19899999998674, 72.31499999997867], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273, 79.8029999999843, 83.44299999998968, 82.4399999999879, 62.13999999998458], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028, 74.24199999998633, 89.29399999998869, 61.47499999999331, 43.78800000001334], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479, 67.04299999998996, 74.41299999998631, 63.982999999994696, 45.02900000001133], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113, 74.18999999998745, 74.20099999998574, 56.97099999998479, 35.60100000001167], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515, 53.01399999998791, 66.93999999998067, 68.51899999998204, 34.11100000001101], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604, 48.9439999999919, 75.66199999998734, 50.021000000001884, 17.549000000017653], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349, 43.29300000000907, 71.29099999998752, 51.010000000002336, 26.570000000016318]}\n","----\n","range: {0.0: [85.04899999998874, 86.22499999998706, 87.45999999998735, 90.20399999999412, 92.28699999999375, 93.3999999999895, 80.75599999999025], 0.05: [77.76299999998585, 90.06999999998408, 83.24899999998479, 74.66299999998876, 87.85099999998802, 79.19899999998674, 72.31499999997867], 0.1: [77.93999999998756, 86.28199999998846, 71.34899999999273, 79.8029999999843, 83.44299999998968, 82.4399999999879, 62.13999999998458], 0.15: [66.57199999999374, 82.01399999997837, 75.57699999999028, 74.24199999998633, 89.29399999998869, 61.47499999999331, 43.78800000001334], 0.2: [54.99799999999712, 75.09299999998919, 59.62099999998479, 67.04299999998996, 74.41299999998631, 63.982999999994696, 45.02900000001133], 0.25: [70.42100000000063, 70.28999999998335, 69.95499999998113, 74.18999999998745, 74.20099999998574, 56.97099999998479, 35.60100000001167], 0.3: [54.90199999998741, 52.96599999999454, 66.96699999999515, 53.01399999998791, 66.93999999998067, 68.51899999998204, 34.11100000001101], 0.35: [50.533000000004535, 40.31400000001508, 59.437999999991604, 48.9439999999919, 75.66199999998734, 50.021000000001884, 17.549000000017653], 0.4: [57.31599999998752, 36.1020000000172, 61.10999999999349, 43.29300000000907, 71.29099999998752, 51.010000000002336, 26.570000000016318]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BhvsIWF-qrHj"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def save_trajectories(agent, episode_durations, dirty):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    for i_episode in range(num_episodes):\n","        path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","        if dirty:\n","            g_state = g_state + state_range * noise\n","            g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","        if dirty:\n","            state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","            state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","        episode_steps = 0\n","        overall_reward = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","            path[\"manager\"].append((episode_steps, g_state_.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                path[\"worker\"].append((episode_steps, torch.cat([state_, goal], 1).detach().cpu().squeeze(0).numpy(), action.detach().cpu().squeeze(0).numpy()))\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                if dirty:\n","                    g_next_state = g_next_state + state_range * noise\n","                    g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                if dirty:\n","                    next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","\n","        path[\"overall_reward\"] = overall_reward\n","        episode_durations[-1].append(path)\n","\n","def save_random_manager(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_points = 10000\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","    for _ in range(num_points):\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        noise = torch.FloatTensor(state.shape).uniform_(0.0, 1.0).to(device)\n","\n","        g_state = state_min + state_range * noise\n","        g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","\n","        goal = agent.select_goal(g_state, False, False)\n","        path[\"manager\"].append((0, g_state.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","    episode_durations[-1].append(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWeLBDKTP3Ao","executionInfo":{"status":"ok","timestamp":1616493270550,"user_tz":0,"elapsed":38321,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"0107b42c-f0dc-4328-af79-819acc958d8a"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        #save_trajectories(agent, episodes, False)\n","        save_random_manager(agent, episodes)\n","        #print(f\"{i} paths: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","#print(f\"paths: {episodes}\")\n","\n","episodes.pop(1)\n","torch.save(episodes, \"PointMaze_Freeze_manager.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y6VhJjD8QHJl"},"source":["def get_intrinsic_reward(agent):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    overall_reward = 0\n","    intr_rews = []\n","\n","    for i_episode in range(num_episodes):\n","        cur_intr = []\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_steps = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                cur_intr.append(agent.intrinsic_reward(reward, state, goal, next_state).detach().item())\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","        intr_rews.append(cur_intr)\n","    print(overall_reward / num_episodes)\n","    return intr_rews"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"SBjnn7HWZTyF","executionInfo":{"status":"ok","timestamp":1616492202635,"user_tz":0,"elapsed":868,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"8fdc8c67-b902-442f-b4f1-c33f9b6077ad"},"source":["import matplotlib.pyplot as plt\n","\n","episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 6\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_freeze_{i}\")\n","episodes = get_intrinsic_reward(agent)\n","\n","print(\"Freeze\")\n","\n","eps = np.array([np.array(l) for l in episodes])\n","#eps = np.mean(eps, 0)\n","\n","plt.plot(eps[3])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["97.31999999999961\n","Freeze\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"11oJHE1hZknp","executionInfo":{"status":"ok","timestamp":1616492002184,"user_tz":0,"elapsed":1263,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"b31e2135-12e2-4224-8ae0-c3f0be8a00d7"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 3\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_{i}\", \"point_maze_time\")\n","episodes = get_intrinsic_reward(agent)\n","\n","print(\"Standard\")\n","\n","eps = np.array([np.array(l) for l in episodes])\n","#eps = np.mean(eps, 0)\n","\n","plt.plot(eps[2])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["95.64999999999947\n","Standard\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"cpUcYkH1afDr"},"source":[""],"execution_count":null,"outputs":[]}]}