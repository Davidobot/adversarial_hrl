{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"hiro_pointfall_random.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-Y3vLeDo4pG","executionInfo":{"status":"ok","timestamp":1617432417689,"user_tz":-60,"elapsed":33550,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"44a16e4f-7a2b-4995-d38b-f69e78fe8097"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!cp \"/content/drive/My Drive/Dissertation/envs/point_fall.py\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eaaz1IRfpF1l","executionInfo":{"status":"ok","timestamp":1617432436369,"user_tz":-60,"elapsed":2319,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["# for inference, not continued training\n","def save_model(model, name):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_fall_random/{name}\" \n","\n","    torch.save({\n","      'meta_controller': {\n","          'critic': model.meta_controller.critic.state_dict(),\n","          'actor': model.meta_controller.actor.state_dict(),\n","      },\n","      'controller': {\n","          'critic': model.controller.critic.state_dict(),\n","          'actor': model.controller.actor.state_dict(),\n","      }\n","    }, path)\n","\n","import copy\n","def load_model(model, name, dir=\"point_fall_random\"):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{dir}/{name}\" \n","    checkpoint = torch.load(path)\n","\n","    model.meta_controller.critic.load_state_dict(checkpoint['meta_controller']['critic'])\n","    model.meta_controller.critic_target = copy.deepcopy(model.meta_controller.critic)\n","    model.meta_controller.actor.load_state_dict(checkpoint['meta_controller']['actor'])\n","    model.meta_controller.actor_target = copy.deepcopy(model.meta_controller.actor)\n","\n","    model.controller.critic.load_state_dict(checkpoint['controller']['critic'])\n","    model.controller.critic_target = copy.deepcopy(model.controller.critic)\n","    model.controller.actor.load_state_dict(checkpoint['controller']['actor'])\n","    model.controller.actor_target = copy.deepcopy(model.controller.actor)\n","\n","    # model.eval() for evaluation instead\n","    model.eval()\n","    model.meta_controller.eval()\n","    model.controller.eval()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1617432438435,"user_tz":-60,"elapsed":4353,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1617432438437,"user_tz":-60,"elapsed":4338,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1617432438443,"user_tz":-60,"elapsed":4333,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["from point_fall import PointFallEnv \n","env = NormalizedEnv(PointFallEnv(4))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1617432438446,"user_tz":-60,"elapsed":3545,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1617432438450,"user_tz":-60,"elapsed":3220,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1617432438452,"user_tz":-60,"elapsed":2858,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","  \n","# (state, action) -> (next_state, reward, done)\n","transition_meta = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done', 'state_seq', 'action_seq'))\n","\n","# replay memory D with capacity N\n","class ReplayMemoryMeta(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition_meta(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1617432438454,"user_tz":-60,"elapsed":1799,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["DEPTH = 128\n","\n","class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, DEPTH)\n","        self.fc2 = nn.Linear(DEPTH, DEPTH)\n","        self.head = nn.Linear(DEPTH, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l2 = nn.Linear(DEPTH, DEPTH)\n","        self.l3 = nn.Linear(DEPTH, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l5 = nn.Linear(DEPTH, DEPTH)\n","        self.l6 = nn.Linear(DEPTH, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1617432438769,"user_tz":-60,"elapsed":1687,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions, is_meta=False):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        self.is_meta = is_meta\n","\n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000) if not self.is_meta else ReplayMemoryMeta(100000)\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 20000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self, off_policy_correction=None):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","\n","        if not self.is_meta:\n","            batch = transition(*zip(*transitions))\n","            action_batch = torch.cat(batch.action)\n","        else:\n","            batch = transition_meta(*zip(*transitions))\n","\n","            action_batch = torch.cat(batch.action)\n","            state_seq_batch = torch.stack(batch.state_seq)\n","            action_seq_batch = torch.stack(batch.action_seq)\n","\n","            action_batch = off_policy_correction(action_batch.cpu().numpy(), state_seq_batch.cpu().numpy(), action_seq_batch.cpu().numpy())\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            \n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # print losses\n","            #if self.total_it % (50 * 50 if self.is_meta else 500 * 50) == 0:\n","            #    print(f\"{self.is_meta} controller;\\n\\tcritic loss: {critic_loss.item()}\\n\\tactor loss: {actor_loss.item()}\")\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, 2 * self.tau / 5)\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup, decay_epsilon):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,1)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u23kJqHhvw8","executionInfo":{"status":"ok","timestamp":1617432438772,"user_tz":-60,"elapsed":1161,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["class HIRO(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(HIRO, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        self.goal_dim = [0, 1]\n","        self.goal_dimen = 2\n","      \n","        self.meta_controller = TD3(nb_states, len(self.goal_dim), True).to(device)\n","        self.max_goal_dist = torch.from_numpy(np.array([2., 3.])).to(device)\n","        self.goal_offset = torch.from_numpy(np.array([0.5, 1.5])).to(device)\n","        #self.meta_controller.depsilon = 1.0 / 10000\n","\n","        self.controller = TD3(nb_states + len(self.goal_dim), nb_actions).to(device)\n","        #self.controller.depsilon = 1.0 / 10000\n","\n","    def teach_controller(self):\n","        self.controller.update_policy()\n","    def teach_meta_controller(self):\n","        self.meta_controller.update_policy(self.off_policy_corrections)\n","\n","    def h(self, state, goal, next_state):\n","        #return goal\n","        return state[:,self.goal_dim] + goal - next_state[:,self.goal_dim]\n","    #def intrinsic_reward(self, action, goal):\n","    #    return torch.tensor(1.0 if self.goal_reached(action, goal) else 0.0, device=device) \n","    #def goal_reached(self, action, goal, threshold = 0.1):\n","    #    return torch.abs(action - goal) <= threshold\n","    def intrinsic_reward(self, reward, state, goal, next_state):\n","        #return torch.tensor(2 * reward if self.goal_reached(state, goal, next_state) else reward / 10, device=device) #reward / 2\n","        # just L2 norm\n","        return -torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5)\n","    def goal_reached(self, state, goal, next_state, threshold = 0.1):\n","        return torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5) <= threshold\n","        #return torch.pow(sum(goal.squeeze(0), 2), 0.5) <= threshold\n","\n","    # correct goals to allow for use in experience replay\n","    def off_policy_corrections(self, sgoals, states, actions, candidate_goals=8):\n","        first_s = [s[0] for s in states] # First x\n","        last_s = [s[-1] for s in states] # Last x\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # diff = 1\n","        diff_goal = (np.array(last_s) - np.array(first_s))[:, np.newaxis, :self.goal_dimen]\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # original = 1\n","        # random = candidate_goals\n","        scale = self.max_goal_dist.cpu().numpy()\n","        original_goal = np.array(sgoals)[:, np.newaxis, :]\n","        random_goals = np.random.normal(loc=diff_goal, scale=.5*scale,\n","                                        size=(BATCH_SIZE, candidate_goals, original_goal.shape[-1]))\n","        random_goals = random_goals.clip(-scale, scale)\n","\n","        # Shape: (batch_size, 10, subgoal_dim)\n","        candidates = np.concatenate([original_goal, diff_goal, random_goals], axis=1)\n","        #states = np.array(states)[:, :-1, :]\n","        actions = np.array(actions)\n","        seq_len = len(states[0])\n","\n","        # For ease\n","        new_batch_sz = seq_len * BATCH_SIZE\n","        action_dim = actions[0][0].shape\n","        obs_dim = states[0][0].shape\n","        ncands = candidates.shape[1]\n","\n","        true_actions = actions.reshape((new_batch_sz,) + action_dim)\n","        observations = states.reshape((new_batch_sz,) + obs_dim)\n","        goal_shape = (new_batch_sz, self.goal_dimen)\n","        # observations = get_obs_tensor(observations, sg_corrections=True)\n","\n","        # batched_candidates = np.tile(candidates, [seq_len, 1, 1])\n","        # batched_candidates = batched_candidates.transpose(1, 0, 2)\n","\n","        policy_actions = np.zeros((ncands, new_batch_sz) + action_dim)\n","\n","        observations = torch.from_numpy(observations).to(device)\n","        for c in range(ncands):\n","            subgoal = candidates[:,c]\n","            candidate = (subgoal + states[:, 0, :self.goal_dimen])[:, None] - states[:, :, :self.goal_dimen]\n","            candidate = candidate.reshape(*goal_shape)\n","            policy_actions[c] = self.controller.actor(torch.cat([observations, torch.from_numpy(candidate).to(device)], 1).float()).detach().cpu().numpy()\n","\n","        difference = (policy_actions - true_actions)\n","        difference = np.where(difference != -np.inf, difference, 0)\n","        difference = difference.reshape((ncands, BATCH_SIZE, seq_len) + action_dim).transpose(1, 0, 2, 3)\n","\n","        logprob = -0.5*np.sum(np.linalg.norm(difference, axis=-1)**2, axis=-1)\n","        max_indices = np.argmax(logprob, axis=-1)\n","\n","        return torch.from_numpy(candidates[np.arange(BATCH_SIZE), max_indices]).to(device).float()\n","\n","    def observe_controller(self, s_t, a_t, s_t1, r_t, done):\n","        self.controller.memory.store(s_t, a_t, s_t1, r_t, done)\n","    def observe_meta_controller(self, s_t, a_t, s_t1, r_t, done, state_seq, action_seq):\n","        self.meta_controller.memory.store(s_t, a_t, s_t1, r_t, done, state_seq, action_seq)\n","\n","    def select_goal(self, s_t, warmup, decay_epsilon):\n","        return self.meta_controller.select_action(s_t, warmup, decay_epsilon) * self.max_goal_dist + self.goal_offset\n","    def select_action(self, s_t, g_t, warmup, decay_epsilon):\n","        sg_t = torch.cat([s_t, g_t], 1).float()\n","        return self.controller.select_action(sg_t, warmup, decay_epsilon)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI"},"source":["SAVE_OFFSET = 6\n","def train_model():\n","    global SAVE_OFFSET\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = HIRO(n_observations, n_actions).to(device)\n","    \n","    max_episode_length = 500\n","    observation = None\n","    \n","    warmup = 200\n","    num_episodes = 4000 # M\n","    episode_durations = []\n","    goal_durations = []\n","\n","    steps = 0\n","    c = 10\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        overall_intrinsic = 0\n","        episode_steps = 0\n","        done = False\n","        goals_done = 0\n","\n","        while not done:\n","            # random goal\n","            goal = agent.select_goal(state, True, False)\n","            #goal_durations.append((steps, goal[:,0]))\n","\n","            state_seq, action_seq = None, None\n","            first_goal = goal\n","            goal_done = False\n","            total_extrinsic = 0\n","\n","            while not done and not goal_done:\n","                joint_goal_state = torch.cat([state, goal], axis=1).float()\n","\n","                # agent pick action ...\n","                action = agent.select_action(state, goal, i_episode <= warmup, True)\n","                \n","                # env response with next_observation, reward, terminate_info\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                steps += 1\n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                next_goal = agent.h(state, goal, next_state)\n","                joint_next_state = torch.cat([next_state, next_goal], axis=1).float()\n","                \n","                if max_episode_length and episode_steps >= max_episode_length -1:\n","                    done = True\n","                    \n","                extrinsic_reward = torch.tensor([reward], device=device)\n","                intrinsic_reward = agent.intrinsic_reward(reward, state, goal, next_state).unsqueeze(0)\n","                #intrinsic_reward = agent.intrinsic_reward(action, goal).unsqueeze(0)\n","\n","                overall_reward += reward\n","                total_extrinsic += reward\n","                overall_intrinsic += intrinsic_reward\n","\n","                goal_reached = agent.goal_reached(state, goal, next_state)\n","                #goal_done = agent.goal_reached(action, goal)\n","\n","                # agent observe and update policy\n","                agent.observe_controller(joint_goal_state, action, joint_next_state, intrinsic_reward, done) #goal_done.item())\n","\n","                if state_seq is None:\n","                    state_seq = state\n","                else:\n","                    state_seq = torch.cat([state_seq, state])\n","                if action_seq is None:\n","                    action_seq = action\n","                else:\n","                    action_seq = torch.cat([action_seq, action])\n","\n","                episode_steps += 1\n","\n","                if goal_reached:\n","                    goals_done += 1\n","                \n","                if (episode_steps % c) == 0:\n","                    agent.observe_meta_controller(state_seq[0].unsqueeze(0), goal, next_state, torch.tensor([total_extrinsic], device=device), done,\\\n","                                                  state_seq, action_seq)\n","                    goal_done = True\n","\n","                    #if i_episode > warmup:\n","                    #    agent.teach_meta_controller()\n","\n","                state = next_state\n","                goal = next_goal\n","                \n","                if i_episode > warmup:\n","                    agent.teach_controller()\n","\n","        goal_durations.append((i_episode, overall_intrinsic / episode_steps))\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations, goal_durations)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0:\n","                print(f\"{i_episode}: {np.mean(dur[-100:])}\")\n","            if i_episode >= 400 and i_episode % 100 == 0 and np.mean(dur[-100:]) <= -49.0:\n","                print(f\"Unlucky after {i_episode} eps! Terminating...\")\n","                return None\n","            if np.mean(dur[-100:]) >= 90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"hiro_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","\n","    return None # did not train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5kgVRwJErwO"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def eval_model(agent, episode_durations, goal_attack, action_attack, same_noise):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for l2norm in np.arange(0.0,0.51,0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","            if goal_attack:\n","                g_state = g_state + state_range * noise\n","                g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","            if action_attack:\n","                if same_noise:\n","                    state = state + state_range * noise\n","                else:\n","                    state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    if goal_attack:\n","                        g_next_state = g_next_state + state_range * noise\n","                        g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                    if action_attack:\n","                        if same_noise:\n","                            next_state = next_state + state_range * noise\n","                        else:\n","                            next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                        next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(l2norm, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-GH33rpv6-Z","executionInfo":{"status":"ok","timestamp":1617432463042,"user_tz":-60,"elapsed":6682,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def fgsm_attack(data, eps, data_grad):\n","    sign_data_grad = data_grad.sign()\n","\n","    perturbed_data = data + eps * sign_data_grad * state_range\n","\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\n","\n","    return clipped_perturbed_data\n","\n","def fgsm_action(state, goal, agent, eps, target, targeted):\n","    #state = torch.tensor(state, requires_grad=True)\n","    state = state.clone().detach().requires_grad_(True)\n","    goal = goal.clone().detach()\n","\n","    sg_t = torch.cat([state, goal], 1).float()\n","\n","    if targeted:\n","        # initial forward pass\n","        action = agent.controller.actor(sg_t)\n","        action = torch.clamp(action, -1., 1.)\n","\n","        loss = F.mse_loss(action, target)\n","    else:\n","        loss = agent.controller.critic.Q1(sg_t, agent.controller.actor(sg_t)).mean()\n","\n","    agent.controller.actor.zero_grad()\n","\n","    # calc loss\n","    loss.backward()\n","    data_grad = state.grad.data\n","    # perturb state\n","    state_p = fgsm_attack(state, eps, data_grad).float()\n","    return state_p\n","\n","def apply_fgsm(agent, episode_durations, targeted):\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0]], device=device, dtype=torch.float)\n","\n","    agent.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for eps in np.arange(0.0, 0.201, 0.02):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            goal = agent.select_goal(og_state, True, False)\n","            state = fgsm_action(og_state, goal, agent, eps, TARGET_ACTION, targeted)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                goal = agent.select_goal(state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    \n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","\n","                    next_og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    goal_temp = agent.h(state, goal, next_og_state)\n","                    next_state = fgsm_action(next_og_state, goal_temp, agent, eps, TARGET_ACTION, targeted)\n","\n","                    next_goal = agent.h(state, goal, next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(state, goal, next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    goal = next_goal\n","\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrR0kvDhFwRa","executionInfo":{"status":"ok","timestamp":1616821474167,"user_tz":0,"elapsed":20143741,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"3ea0096d-0383-4cf1-f978-fe4c7153809c"},"source":["noise_hrl = {'both': {}, 'action_only': {}, 'goal_only': {}, 'both_same': {}}\n","for l2norm in np.arange(0,0.51,0.05):\n","    for i in [noise_hrl['both'], noise_hrl['action_only'], noise_hrl['goal_only'], noise_hrl['both_same']]:\n","        i[np.round(l2norm, 2)] = []\n","\n","targeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\n","untargeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    for x in ['both', 'goal_only', 'action_only']:\n","        targeted[x][eps] = []\n","        untargeted[x][eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    agent = train_model()\n","    #agent = HIRO(n_observations, n_actions).to(device)\n","    #load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_model(agent, noise_hrl['both_same'], True, True, True)\n","        eval_model(agent, noise_hrl['both'], True, True, False)\n","        eval_model(agent, noise_hrl['action_only'], False, True, False)\n","        eval_model(agent, noise_hrl['goal_only'], True, False, False)\n","        print(f\"{i} noise_hrl: {noise_hrl}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"noise_hrl: {noise_hrl}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100: -48.68600000000042\n","200: -50.000000000000426\n","300: -34.087000000000415\n","400: -16.509000000000345\n","500: -20.562000000000364\n","600: -7.803000000000319\n","700: 10.032999999999737\n","800: 5.901999999999723\n","900: 23.794999999999785\n","1000: 24.905999999999775\n","1100: 19.17799999999977\n","1200: 5.9299999999997315\n","1300: -4.690000000000307\n","1400: -2.5960000000003074\n","1500: 20.773999999999784\n","1600: 37.98099999999984\n","1700: 37.88099999999983\n","1800: 41.67299999999984\n","1900: 44.61499999999985\n","2000: 50.62499999999988\n","2100: 54.242999999999874\n","2200: 66.93899999999991\n","2300: 68.23099999999991\n","2400: 70.71299999999992\n","2500: 71.14199999999991\n","2600: 74.44099999999995\n","2700: 66.46699999999991\n","2800: 71.58299999999993\n","2900: 64.5079999999999\n","3000: 71.83099999999993\n","3100: 72.16999999999993\n","3200: 81.02599999999997\n","3300: 85.67099999999996\n","Solved after 3369 episodes!\n","0 noise_hrl: {'both': {0.0: [89.79999999998823], 0.05: [85.89999999998871], 0.1: [64.1159999999965], 0.15: [55.05099999999851], 0.2: [24.27700000001135], 0.25: [21.681000000013785], 0.3: [5.58499999999894], 0.35: [7.813999999997176], 0.4: [-9.73000000000673], 0.45: [-4.133000000006307], 0.5: [13.52700000000348]}, 'action_only': {0.0: [91.14599999999187], 0.05: [76.28499999998583], 0.1: [64.33299999997963], 0.15: [49.37900000000134], 0.2: [29.050000000021846], 0.25: [16.215000000003393], 0.3: [2.2769999999984303], 0.35: [8.938000000000587], 0.4: [1.5539999999970706], 0.45: [-5.948000000002885], 0.5: [-11.078999999999008]}, 'goal_only': {0.0: [91.47599999999082], 0.05: [82.71099999998385], 0.1: [89.65099999999113], 0.15: [94.78199999999686], 0.2: [85.07399999998715], 0.25: [92.79299999999323], 0.3: [89.88899999998627], 0.35: [91.6289999999907], 0.4: [91.46099999999302], 0.45: [88.27099999999362], 0.5: [84.80599999999008]}, 'both_same': {0.0: [93.1209999999905], 0.05: [86.416999999982], 0.1: [62.36399999998739], 0.15: [30.421000000010487], 0.2: [33.333000000016916], 0.25: [20.860000000020936], 0.3: [3.491999999998643], 0.35: [11.176999999996283], 0.4: [11.172999999998916], 0.45: [-2.7499999999996727], 0.5: [-9.59900000000348]}}\n","100: -50.000000000000426\n","200: -50.000000000000426\n","300: -43.749000000000414\n","400: -37.52900000000042\n","500: -30.421000000000408\n","600: -11.957000000000358\n","700: -20.548000000000386\n","800: -3.838000000000321\n","900: 11.587999999999738\n","1000: 30.289999999999804\n","1100: 30.6789999999998\n","1200: 27.81499999999979\n","1300: 31.287999999999816\n","1400: 31.15799999999981\n","1500: 63.838999999999906\n","1600: 62.51999999999992\n","1700: 42.16899999999983\n","1800: 56.42499999999986\n","1900: 49.35799999999986\n","2000: 43.34499999999984\n","2100: 58.6569999999999\n","2200: 68.27999999999993\n","2300: 56.488999999999876\n","2400: 60.2049999999999\n","2500: 59.17599999999989\n","2600: 64.8879999999999\n","2700: 67.24399999999993\n","2800: 68.63699999999992\n","2900: 55.00099999999988\n","3000: 65.5279999999999\n","3100: 80.31199999999994\n","3200: 85.02599999999998\n","3300: 84.51599999999996\n","Solved after 3377 episodes!\n","1 noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754], 0.05: [85.89999999998871, 79.66199999998655], 0.1: [64.1159999999965, 64.50199999998335], 0.15: [55.05099999999851, 49.64399999999251], 0.2: [24.27700000001135, 49.970000000005], 0.25: [21.681000000013785, 21.03100000000747], 0.3: [5.58499999999894, 9.21699999999442], 0.35: [7.813999999997176, 8.317999999995418], 0.4: [-9.73000000000673, 12.104000000002486], 0.45: [-4.133000000006307, 12.46500000001124], 0.5: [13.52700000000348, -2.344000000000675]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893], 0.05: [76.28499999998583, 81.50799999999407], 0.1: [64.33299999997963, 71.3099999999942], 0.15: [49.37900000000134, 50.7599999999992], 0.2: [29.050000000021846, 19.68100000001134], 0.25: [16.215000000003393, 28.636000000015297], 0.3: [2.2769999999984303, 25.112000000016625], 0.35: [8.938000000000587, 15.546000000002783], 0.4: [1.5539999999970706, 5.4680000000004485], 0.45: [-5.948000000002885, 11.023999999997733], 0.5: [-11.078999999999008, 2.4139999999978268]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752], 0.05: [82.71099999998385, 87.5849999999857], 0.1: [89.65099999999113, 86.26999999998823], 0.15: [94.78199999999686, 89.1359999999922], 0.2: [85.07399999998715, 86.15099999999008], 0.25: [92.79299999999323, 94.8459999999912], 0.3: [89.88899999998627, 93.25799999999249], 0.35: [91.6289999999907, 86.59799999998651], 0.4: [91.46099999999302, 82.35999999998572], 0.45: [88.27099999999362, 87.68299999999131], 0.5: [84.80599999999008, 83.91999999999362]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435], 0.05: [86.416999999982, 74.32599999999498], 0.1: [62.36399999998739, 62.037999999967525], 0.15: [30.421000000010487, 49.639000000002305], 0.2: [33.333000000016916, 25.7550000000216], 0.25: [20.860000000020936, 22.023000000019323], 0.3: [3.491999999998643, 15.312999999998874], 0.35: [11.176999999996283, 11.369000000006137], 0.4: [11.172999999998916, 7.4949999999938814], 0.45: [-2.7499999999996727, 7.2519999999937825], 0.5: [-9.59900000000348, -7.0750000000091084]}}\n","100: -48.95800000000043\n","200: -48.992000000000424\n","300: -33.4820000000004\n","400: -21.932000000000375\n","500: -21.48900000000037\n","600: 5.891999999999705\n","700: 16.292999999999758\n","800: 8.23099999999974\n","900: 54.7969999999999\n","1000: 34.69599999999979\n","1100: 46.93999999999985\n","1200: 56.7969999999999\n","1300: 45.01399999999987\n","1400: 65.5899999999999\n","1500: 52.64199999999988\n","1600: 43.84599999999985\n","1700: 35.925999999999824\n","1800: 42.83599999999983\n","1900: 52.92599999999989\n","2000: 76.18399999999994\n","2100: 55.21299999999987\n","2200: 55.291999999999874\n","2300: 64.77999999999989\n","2400: 52.35799999999988\n","2500: 49.453999999999866\n","2600: 48.53399999999985\n","2700: 46.835999999999856\n","2800: 65.6229999999999\n","2900: 75.63399999999996\n","3000: 88.01899999999998\n","Solved after 3018 episodes!\n","2 noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754, 88.53699999999066], 0.05: [85.89999999998871, 79.66199999998655, 80.93199999998646], 0.1: [64.1159999999965, 64.50199999998335, 73.09299999998349], 0.15: [55.05099999999851, 49.64399999999251, 51.63999999999055], 0.2: [24.27700000001135, 49.970000000005, 45.794999999994104], 0.25: [21.681000000013785, 21.03100000000747, 34.00900000001882], 0.3: [5.58499999999894, 9.21699999999442, 2.7149999999940326], 0.35: [7.813999999997176, 8.317999999995418, -0.9510000000028265], 0.4: [-9.73000000000673, 12.104000000002486, -19.942999999985055], 0.45: [-4.133000000006307, 12.46500000001124, -18.77899999999143], 0.5: [13.52700000000348, -2.344000000000675, -22.12199999997971]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893, 80.73699999998783], 0.05: [76.28499999998583, 81.50799999999407, 82.65999999998269], 0.1: [64.33299999997963, 71.3099999999942, 56.80099999999294], 0.15: [49.37900000000134, 50.7599999999992, 59.75899999998357], 0.2: [29.050000000021846, 19.68100000001134, 34.221000000017334], 0.25: [16.215000000003393, 28.636000000015297, 23.975000000023037], 0.3: [2.2769999999984303, 25.112000000016625, 2.82399999999713], 0.35: [8.938000000000587, 15.546000000002783, 0.5399999999974943], 0.4: [1.5539999999970706, 5.4680000000004485, -14.442999999991832], 0.45: [-5.948000000002885, 11.023999999997733, -17.187999999984633], 0.5: [-11.078999999999008, 2.4139999999978268, -26.27099999997246]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752, 86.29099999999139], 0.05: [82.71099999998385, 87.5849999999857, 89.26499999998838], 0.1: [89.65099999999113, 86.26999999998823, 95.172999999993], 0.15: [94.78199999999686, 89.1359999999922, 93.9389999999911], 0.2: [85.07399999998715, 86.15099999999008, 89.31399999998828], 0.25: [92.79299999999323, 94.8459999999912, 85.9999999999971], 0.3: [89.88899999998627, 93.25799999999249, 81.79099999997939], 0.35: [91.6289999999907, 86.59799999998651, 86.15099999998407], 0.4: [91.46099999999302, 82.35999999998572, 89.6769999999882], 0.45: [88.27099999999362, 87.68299999999131, 88.56499999999195], 0.5: [84.80599999999008, 83.91999999999362, 76.3119999999843]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435, 94.99199999999324], 0.05: [86.416999999982, 74.32599999999498, 87.43599999999228], 0.1: [62.36399999998739, 62.037999999967525, 79.48899999998284], 0.15: [30.421000000010487, 49.639000000002305, 63.51499999999467], 0.2: [33.333000000016916, 25.7550000000216, 49.03499999999667], 0.25: [20.860000000020936, 22.023000000019323, 42.24600000001703], 0.3: [3.491999999998643, 15.312999999998874, 18.038000000006157], 0.35: [11.176999999996283, 11.369000000006137, -5.860000000001422], 0.4: [11.172999999998916, 7.4949999999938814, -11.402999999992977], 0.45: [-2.7499999999996727, 7.2519999999937825, -17.01599999998405], 0.5: [-9.59900000000348, -7.0750000000091084, -18.485999999983186]}}\n","100: -48.89200000000042\n","200: -48.96200000000042\n","300: -36.57100000000041\n","400: -12.597000000000335\n","500: -26.23100000000037\n","600: -15.173000000000354\n","700: -9.189000000000341\n","800: -9.792000000000321\n","900: 11.331999999999748\n","1000: -2.459000000000301\n","1100: 1.5069999999996986\n","1200: 3.2849999999997213\n","1300: 15.372999999999761\n","1400: 23.214999999999783\n","1500: 17.449999999999772\n","1600: 20.277999999999775\n","1700: 30.2309999999998\n","1800: 35.022999999999826\n","1900: 36.952999999999825\n","2000: 33.05199999999981\n","2100: 35.993999999999815\n","2200: 48.58899999999986\n","2300: 43.291999999999845\n","2400: 66.09899999999992\n","2500: 77.73799999999994\n","2600: 74.46399999999993\n","2700: 77.63899999999994\n","2800: 76.27699999999993\n","2900: 75.80399999999995\n","3000: 73.28899999999993\n","3100: 75.98599999999995\n","3200: 84.23799999999996\n","3300: 75.69199999999995\n","3400: 83.53699999999998\n","3500: 88.30699999999999\n","Solved after 3513 episodes!\n","3 noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754, 88.53699999999066, 86.8459999999876], 0.05: [85.89999999998871, 79.66199999998655, 80.93199999998646, 38.88600000001531], 0.1: [64.1159999999965, 64.50199999998335, 73.09299999998349, 20.761000000010096], 0.15: [55.05099999999851, 49.64399999999251, 51.63999999999055, 10.285999999999653], 0.2: [24.27700000001135, 49.970000000005, 45.794999999994104, 16.903000000015105], 0.25: [21.681000000013785, 21.03100000000747, 34.00900000001882, 13.991000000005679], 0.3: [5.58499999999894, 9.21699999999442, 2.7149999999940326, 18.229999999998213], 0.35: [7.813999999997176, 8.317999999995418, -0.9510000000028265, 23.194000000010014], 0.4: [-9.73000000000673, 12.104000000002486, -19.942999999985055, 27.072000000015706], 0.45: [-4.133000000006307, 12.46500000001124, -18.77899999999143, 12.854999999999022], 0.5: [13.52700000000348, -2.344000000000675, -22.12199999997971, 24.939000000014694]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893, 80.73699999998783, 86.86599999998676], 0.05: [76.28499999998583, 81.50799999999407, 82.65999999998269, 37.85800000001429], 0.1: [64.33299999997963, 71.3099999999942, 56.80099999999294, 25.543000000011872], 0.15: [49.37900000000134, 50.7599999999992, 59.75899999998357, 16.67100000001009], 0.2: [29.050000000021846, 19.68100000001134, 34.221000000017334, 18.945000000013994], 0.25: [16.215000000003393, 28.636000000015297, 23.975000000023037, 27.740000000015783], 0.3: [2.2769999999984303, 25.112000000016625, 2.82399999999713, 28.76200000002002], 0.35: [8.938000000000587, 15.546000000002783, 0.5399999999974943, 16.569000000001946], 0.4: [1.5539999999970706, 5.4680000000004485, -14.442999999991832, 23.706000000015738], 0.45: [-5.948000000002885, 11.023999999997733, -17.187999999984633, 21.356000000017108], 0.5: [-11.078999999999008, 2.4139999999978268, -26.27099999997246, 22.04600000001777]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752, 86.29099999999139, 84.03599999999287], 0.05: [82.71099999998385, 87.5849999999857, 89.26499999998838, 81.16899999999146], 0.1: [89.65099999999113, 86.26999999998823, 95.172999999993, 83.73199999998413], 0.15: [94.78199999999686, 89.1359999999922, 93.9389999999911, 78.93799999998342], 0.2: [85.07399999998715, 86.15099999999008, 89.31399999998828, 67.31099999999509], 0.25: [92.79299999999323, 94.8459999999912, 85.9999999999971, 68.49799999997408], 0.3: [89.88899999998627, 93.25799999999249, 81.79099999997939, 80.52099999998772], 0.35: [91.6289999999907, 86.59799999998651, 86.15099999998407, 67.36099999998751], 0.4: [91.46099999999302, 82.35999999998572, 89.6769999999882, 74.31499999999151], 0.45: [88.27099999999362, 87.68299999999131, 88.56499999999195, 57.00199999999553], 0.5: [84.80599999999008, 83.91999999999362, 76.3119999999843, 53.256999999995784]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435, 94.99199999999324, 89.68799999999264], 0.05: [86.416999999982, 74.32599999999498, 87.43599999999228, 41.133000000007925], 0.1: [62.36399999998739, 62.037999999967525, 79.48899999998284, 22.301000000016767], 0.15: [30.421000000010487, 49.639000000002305, 63.51499999999467, 12.836999999999419], 0.2: [33.333000000016916, 25.7550000000216, 49.03499999999667, 13.047999999997677], 0.25: [20.860000000020936, 22.023000000019323, 42.24600000001703, 25.002000000016213], 0.3: [3.491999999998643, 15.312999999998874, 18.038000000006157, 13.76399999999784], 0.35: [11.176999999996283, 11.369000000006137, -5.860000000001422, 23.566000000004507], 0.4: [11.172999999998916, 7.4949999999938814, -11.402999999992977, 9.000999999996667], 0.45: [-2.7499999999996727, 7.2519999999937825, -17.01599999998405, 11.349999999999302], 0.5: [-9.59900000000348, -7.0750000000091084, -18.485999999983186, 19.114000000009447]}}\n","100: -50.000000000000426\n","200: -47.853000000000435\n","300: -33.89400000000042\n","400: -20.61800000000038\n","500: -10.440000000000337\n","600: 8.009999999999717\n","700: 3.1379999999997095\n","800: 5.9999999999997\n","900: 28.389999999999773\n","1000: 43.35799999999984\n","1100: 48.559999999999846\n","1200: 53.30199999999987\n","1300: 50.36299999999986\n","1400: 57.67499999999988\n","1500: 70.36099999999995\n","1600: 67.62999999999992\n","1700: 78.30799999999995\n","1800: 66.98099999999992\n","1900: 59.6209999999999\n","2000: 60.28199999999989\n","2100: 80.33699999999995\n","2200: 83.20499999999998\n","2300: 80.47199999999997\n","2400: 80.48299999999996\n","2500: 84.25099999999996\n","2600: 79.64699999999995\n","Solved after 2693 episodes!\n","4 noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754, 88.53699999999066, 86.8459999999876, 81.50799999998107], 0.05: [85.89999999998871, 79.66199999998655, 80.93199999998646, 38.88600000001531, 87.75599999998349], 0.1: [64.1159999999965, 64.50199999998335, 73.09299999998349, 20.761000000010096, 86.04399999998351], 0.15: [55.05099999999851, 49.64399999999251, 51.63999999999055, 10.285999999999653, 76.97399999998615], 0.2: [24.27700000001135, 49.970000000005, 45.794999999994104, 16.903000000015105, 77.35499999998397], 0.25: [21.681000000013785, 21.03100000000747, 34.00900000001882, 13.991000000005679, 63.967999999978844], 0.3: [5.58499999999894, 9.21699999999442, 2.7149999999940326, 18.229999999998213, 27.679000000010095], 0.35: [7.813999999997176, 8.317999999995418, -0.9510000000028265, 23.194000000010014, 19.7040000000187], 0.4: [-9.73000000000673, 12.104000000002486, -19.942999999985055, 27.072000000015706, -0.2189999999998898], 0.45: [-4.133000000006307, 12.46500000001124, -18.77899999999143, 12.854999999999022, -11.634000000000956], 0.5: [13.52700000000348, -2.344000000000675, -22.12199999997971, 24.939000000014694, -23.118999999987892]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893, 80.73699999998783, 86.86599999998676, 85.94499999999113], 0.05: [76.28499999998583, 81.50799999999407, 82.65999999998269, 37.85800000001429, 88.36999999999016], 0.1: [64.33299999997963, 71.3099999999942, 56.80099999999294, 25.543000000011872, 75.99899999998527], 0.15: [49.37900000000134, 50.7599999999992, 59.75899999998357, 16.67100000001009, 76.52899999998291], 0.2: [29.050000000021846, 19.68100000001134, 34.221000000017334, 18.945000000013994, 54.6399999999877], 0.25: [16.215000000003393, 28.636000000015297, 23.975000000023037, 27.740000000015783, 47.52200000001124], 0.3: [2.2769999999984303, 25.112000000016625, 2.82399999999713, 28.76200000002002, 41.277000000012094], 0.35: [8.938000000000587, 15.546000000002783, 0.5399999999974943, 16.569000000001946, 29.446000000019353], 0.4: [1.5539999999970706, 5.4680000000004485, -14.442999999991832, 23.706000000015738, 4.295999999998698], 0.45: [-5.948000000002885, 11.023999999997733, -17.187999999984633, 21.356000000017108, 0.11100000000084051], 0.5: [-11.078999999999008, 2.4139999999978268, -26.27099999997246, 22.04600000001777, -15.678999999995042]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752, 86.29099999999139, 84.03599999999287, 84.94899999998688], 0.05: [82.71099999998385, 87.5849999999857, 89.26499999998838, 81.16899999999146, 86.314999999986], 0.1: [89.65099999999113, 86.26999999998823, 95.172999999993, 83.73199999998413, 86.30399999998338], 0.15: [94.78199999999686, 89.1359999999922, 93.9389999999911, 78.93799999998342, 89.35599999998773], 0.2: [85.07399999998715, 86.15099999999008, 89.31399999998828, 67.31099999999509, 86.24599999998678], 0.25: [92.79299999999323, 94.8459999999912, 85.9999999999971, 68.49799999997408, 92.91399999998984], 0.3: [89.88899999998627, 93.25799999999249, 81.79099999997939, 80.52099999998772, 86.73499999998532], 0.35: [91.6289999999907, 86.59799999998651, 86.15099999998407, 67.36099999998751, 82.79299999999219], 0.4: [91.46099999999302, 82.35999999998572, 89.6769999999882, 74.31499999999151, 81.54999999998648], 0.45: [88.27099999999362, 87.68299999999131, 88.56499999999195, 57.00199999999553, 87.76699999998625], 0.5: [84.80599999999008, 83.91999999999362, 76.3119999999843, 53.256999999995784, 83.8209999999862]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435, 94.99199999999324, 89.68799999999264, 77.60299999998719], 0.05: [86.416999999982, 74.32599999999498, 87.43599999999228, 41.133000000007925, 81.4729999999869], 0.1: [62.36399999998739, 62.037999999967525, 79.48899999998284, 22.301000000016767, 72.8869999999742], 0.15: [30.421000000010487, 49.639000000002305, 63.51499999999467, 12.836999999999419, 83.49399999998299], 0.2: [33.333000000016916, 25.7550000000216, 49.03499999999667, 13.047999999997677, 66.02499999999308], 0.25: [20.860000000020936, 22.023000000019323, 42.24600000001703, 25.002000000016213, 62.733999999989884], 0.3: [3.491999999998643, 15.312999999998874, 18.038000000006157, 13.76399999999784, 50.016999999993], 0.35: [11.176999999996283, 11.369000000006137, -5.860000000001422, 23.566000000004507, 42.149000000017985], 0.4: [11.172999999998916, 7.4949999999938814, -11.402999999992977, 9.000999999996667, 20.263000000009725], 0.45: [-2.7499999999996727, 7.2519999999937825, -17.01599999998405, 11.349999999999302, 9.128999999991917], 0.5: [-9.59900000000348, -7.0750000000091084, -18.485999999983186, 19.114000000009447, 2.2039999999992848]}}\n","100: -47.72300000000043\n","200: -50.000000000000426\n","300: -25.56000000000037\n","400: -4.859000000000334\n","500: 9.33899999999972\n","600: -16.831000000000355\n","700: 6.124999999999707\n","800: -9.178000000000315\n","900: 30.687999999999793\n","1000: 45.939999999999856\n","1100: 68.21099999999993\n","1200: 60.07999999999989\n","1300: 53.96699999999988\n","1400: 32.71999999999982\n","1500: 26.2899999999998\n","1600: 53.50599999999988\n","1700: 61.71599999999989\n","1800: 54.77699999999985\n","1900: 49.63099999999986\n","2000: 45.42099999999986\n","2100: 44.09199999999985\n","2200: 63.628999999999905\n","2300: 64.86199999999991\n","2400: 59.3419999999999\n","2500: 56.176999999999886\n","2600: 65.28799999999993\n","2700: 57.85099999999988\n","2800: 73.04399999999993\n","2900: 86.43699999999995\n","Solved after 2983 episodes!\n","5 noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754, 88.53699999999066, 86.8459999999876, 81.50799999998107, 91.60699999998806], 0.05: [85.89999999998871, 79.66199999998655, 80.93199999998646, 38.88600000001531, 87.75599999998349, 81.08199999999182], 0.1: [64.1159999999965, 64.50199999998335, 73.09299999998349, 20.761000000010096, 86.04399999998351, 72.82799999998672], 0.15: [55.05099999999851, 49.64399999999251, 51.63999999999055, 10.285999999999653, 76.97399999998615, 76.25499999998087], 0.2: [24.27700000001135, 49.970000000005, 45.794999999994104, 16.903000000015105, 77.35499999998397, 70.07599999998152], 0.25: [21.681000000013785, 21.03100000000747, 34.00900000001882, 13.991000000005679, 63.967999999978844, 68.38799999997833], 0.3: [5.58499999999894, 9.21699999999442, 2.7149999999940326, 18.229999999998213, 27.679000000010095, 61.68599999997475], 0.35: [7.813999999997176, 8.317999999995418, -0.9510000000028265, 23.194000000010014, 19.7040000000187, 42.1720000000163], 0.4: [-9.73000000000673, 12.104000000002486, -19.942999999985055, 27.072000000015706, -0.2189999999998898, 30.908000000017992], 0.45: [-4.133000000006307, 12.46500000001124, -18.77899999999143, 12.854999999999022, -11.634000000000956, 28.27400000001674], 0.5: [13.52700000000348, -2.344000000000675, -22.12199999997971, 24.939000000014694, -23.118999999987892, -1.701999999999015]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893, 80.73699999998783, 86.86599999998676, 85.94499999999113, 83.73199999998612], 0.05: [76.28499999998583, 81.50799999999407, 82.65999999998269, 37.85800000001429, 88.36999999999016, 79.8169999999889], 0.1: [64.33299999997963, 71.3099999999942, 56.80099999999294, 25.543000000011872, 75.99899999998527, 74.12799999999696], 0.15: [49.37900000000134, 50.7599999999992, 59.75899999998357, 16.67100000001009, 76.52899999998291, 76.75399999999108], 0.2: [29.050000000021846, 19.68100000001134, 34.221000000017334, 18.945000000013994, 54.6399999999877, 58.64699999998726], 0.25: [16.215000000003393, 28.636000000015297, 23.975000000023037, 27.740000000015783, 47.52200000001124, 65.0479999999771], 0.3: [2.2769999999984303, 25.112000000016625, 2.82399999999713, 28.76200000002002, 41.277000000012094, 51.99299999999561], 0.35: [8.938000000000587, 15.546000000002783, 0.5399999999974943, 16.569000000001946, 29.446000000019353, 41.390000000023065], 0.4: [1.5539999999970706, 5.4680000000004485, -14.442999999991832, 23.706000000015738, 4.295999999998698, 6.853000000000048], 0.45: [-5.948000000002885, 11.023999999997733, -17.187999999984633, 21.356000000017108, 0.11100000000084051, 5.267999999993027], 0.5: [-11.078999999999008, 2.4139999999978268, -26.27099999997246, 22.04600000001777, -15.678999999995042, 4.752999999991454]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752, 86.29099999999139, 84.03599999999287, 84.94899999998688, 90.76799999999065], 0.05: [82.71099999998385, 87.5849999999857, 89.26499999998838, 81.16899999999146, 86.314999999986, 86.64499999998782], 0.1: [89.65099999999113, 86.26999999998823, 95.172999999993, 83.73199999998413, 86.30399999998338, 92.24499999999038], 0.15: [94.78199999999686, 89.1359999999922, 93.9389999999911, 78.93799999998342, 89.35599999998773, 86.78399999999249], 0.2: [85.07399999998715, 86.15099999999008, 89.31399999998828, 67.31099999999509, 86.24599999998678, 88.3619999999897], 0.25: [92.79299999999323, 94.8459999999912, 85.9999999999971, 68.49799999997408, 92.91399999998984, 86.22199999998988], 0.3: [89.88899999998627, 93.25799999999249, 81.79099999997939, 80.52099999998772, 86.73499999998532, 85.95199999999313], 0.35: [91.6289999999907, 86.59799999998651, 86.15099999998407, 67.36099999998751, 82.79299999999219, 88.86699999998741], 0.4: [91.46099999999302, 82.35999999998572, 89.6769999999882, 74.31499999999151, 81.54999999998648, 88.75899999999028], 0.45: [88.27099999999362, 87.68299999999131, 88.56499999999195, 57.00199999999553, 87.76699999998625, 92.18099999998907], 0.5: [84.80599999999008, 83.91999999999362, 76.3119999999843, 53.256999999995784, 83.8209999999862, 88.4409999999934]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435, 94.99199999999324, 89.68799999999264, 77.60299999998719, 92.7959999999975], 0.05: [86.416999999982, 74.32599999999498, 87.43599999999228, 41.133000000007925, 81.4729999999869, 86.64499999999039], 0.1: [62.36399999998739, 62.037999999967525, 79.48899999998284, 22.301000000016767, 72.8869999999742, 69.11199999998253], 0.15: [30.421000000010487, 49.639000000002305, 63.51499999999467, 12.836999999999419, 83.49399999998299, 74.05199999999203], 0.2: [33.333000000016916, 25.7550000000216, 49.03499999999667, 13.047999999997677, 66.02499999999308, 65.00699999997249], 0.25: [20.860000000020936, 22.023000000019323, 42.24600000001703, 25.002000000016213, 62.733999999989884, 63.08599999997105], 0.3: [3.491999999998643, 15.312999999998874, 18.038000000006157, 13.76399999999784, 50.016999999993, 61.329999999982], 0.35: [11.176999999996283, 11.369000000006137, -5.860000000001422, 23.566000000004507, 42.149000000017985, 50.05300000000255], 0.4: [11.172999999998916, 7.4949999999938814, -11.402999999992977, 9.000999999996667, 20.263000000009725, 35.76400000001385], 0.45: [-2.7499999999996727, 7.2519999999937825, -17.01599999998405, 11.349999999999302, 9.128999999991917, 26.577000000014806], 0.5: [-9.59900000000348, -7.0750000000091084, -18.485999999983186, 19.114000000009447, 2.2039999999992848, 13.22199999999916]}}\n","----\n","noise_hrl: {'both': {0.0: [89.79999999998823, 83.20499999998754, 88.53699999999066, 86.8459999999876, 81.50799999998107, 91.60699999998806], 0.05: [85.89999999998871, 79.66199999998655, 80.93199999998646, 38.88600000001531, 87.75599999998349, 81.08199999999182], 0.1: [64.1159999999965, 64.50199999998335, 73.09299999998349, 20.761000000010096, 86.04399999998351, 72.82799999998672], 0.15: [55.05099999999851, 49.64399999999251, 51.63999999999055, 10.285999999999653, 76.97399999998615, 76.25499999998087], 0.2: [24.27700000001135, 49.970000000005, 45.794999999994104, 16.903000000015105, 77.35499999998397, 70.07599999998152], 0.25: [21.681000000013785, 21.03100000000747, 34.00900000001882, 13.991000000005679, 63.967999999978844, 68.38799999997833], 0.3: [5.58499999999894, 9.21699999999442, 2.7149999999940326, 18.229999999998213, 27.679000000010095, 61.68599999997475], 0.35: [7.813999999997176, 8.317999999995418, -0.9510000000028265, 23.194000000010014, 19.7040000000187, 42.1720000000163], 0.4: [-9.73000000000673, 12.104000000002486, -19.942999999985055, 27.072000000015706, -0.2189999999998898, 30.908000000017992], 0.45: [-4.133000000006307, 12.46500000001124, -18.77899999999143, 12.854999999999022, -11.634000000000956, 28.27400000001674], 0.5: [13.52700000000348, -2.344000000000675, -22.12199999997971, 24.939000000014694, -23.118999999987892, -1.701999999999015]}, 'action_only': {0.0: [91.14599999999187, 92.26399999998893, 80.73699999998783, 86.86599999998676, 85.94499999999113, 83.73199999998612], 0.05: [76.28499999998583, 81.50799999999407, 82.65999999998269, 37.85800000001429, 88.36999999999016, 79.8169999999889], 0.1: [64.33299999997963, 71.3099999999942, 56.80099999999294, 25.543000000011872, 75.99899999998527, 74.12799999999696], 0.15: [49.37900000000134, 50.7599999999992, 59.75899999998357, 16.67100000001009, 76.52899999998291, 76.75399999999108], 0.2: [29.050000000021846, 19.68100000001134, 34.221000000017334, 18.945000000013994, 54.6399999999877, 58.64699999998726], 0.25: [16.215000000003393, 28.636000000015297, 23.975000000023037, 27.740000000015783, 47.52200000001124, 65.0479999999771], 0.3: [2.2769999999984303, 25.112000000016625, 2.82399999999713, 28.76200000002002, 41.277000000012094, 51.99299999999561], 0.35: [8.938000000000587, 15.546000000002783, 0.5399999999974943, 16.569000000001946, 29.446000000019353, 41.390000000023065], 0.4: [1.5539999999970706, 5.4680000000004485, -14.442999999991832, 23.706000000015738, 4.295999999998698, 6.853000000000048], 0.45: [-5.948000000002885, 11.023999999997733, -17.187999999984633, 21.356000000017108, 0.11100000000084051, 5.267999999993027], 0.5: [-11.078999999999008, 2.4139999999978268, -26.27099999997246, 22.04600000001777, -15.678999999995042, 4.752999999991454]}, 'goal_only': {0.0: [91.47599999999082, 88.78799999998752, 86.29099999999139, 84.03599999999287, 84.94899999998688, 90.76799999999065], 0.05: [82.71099999998385, 87.5849999999857, 89.26499999998838, 81.16899999999146, 86.314999999986, 86.64499999998782], 0.1: [89.65099999999113, 86.26999999998823, 95.172999999993, 83.73199999998413, 86.30399999998338, 92.24499999999038], 0.15: [94.78199999999686, 89.1359999999922, 93.9389999999911, 78.93799999998342, 89.35599999998773, 86.78399999999249], 0.2: [85.07399999998715, 86.15099999999008, 89.31399999998828, 67.31099999999509, 86.24599999998678, 88.3619999999897], 0.25: [92.79299999999323, 94.8459999999912, 85.9999999999971, 68.49799999997408, 92.91399999998984, 86.22199999998988], 0.3: [89.88899999998627, 93.25799999999249, 81.79099999997939, 80.52099999998772, 86.73499999998532, 85.95199999999313], 0.35: [91.6289999999907, 86.59799999998651, 86.15099999998407, 67.36099999998751, 82.79299999999219, 88.86699999998741], 0.4: [91.46099999999302, 82.35999999998572, 89.6769999999882, 74.31499999999151, 81.54999999998648, 88.75899999999028], 0.45: [88.27099999999362, 87.68299999999131, 88.56499999999195, 57.00199999999553, 87.76699999998625, 92.18099999998907], 0.5: [84.80599999999008, 83.91999999999362, 76.3119999999843, 53.256999999995784, 83.8209999999862, 88.4409999999934]}, 'both_same': {0.0: [93.1209999999905, 84.90699999998435, 94.99199999999324, 89.68799999999264, 77.60299999998719, 92.7959999999975], 0.05: [86.416999999982, 74.32599999999498, 87.43599999999228, 41.133000000007925, 81.4729999999869, 86.64499999999039], 0.1: [62.36399999998739, 62.037999999967525, 79.48899999998284, 22.301000000016767, 72.8869999999742, 69.11199999998253], 0.15: [30.421000000010487, 49.639000000002305, 63.51499999999467, 12.836999999999419, 83.49399999998299, 74.05199999999203], 0.2: [33.333000000016916, 25.7550000000216, 49.03499999999667, 13.047999999997677, 66.02499999999308, 65.00699999997249], 0.25: [20.860000000020936, 22.023000000019323, 42.24600000001703, 25.002000000016213, 62.733999999989884, 63.08599999997105], 0.3: [3.491999999998643, 15.312999999998874, 18.038000000006157, 13.76399999999784, 50.016999999993, 61.329999999982], 0.35: [11.176999999996283, 11.369000000006137, -5.860000000001422, 23.566000000004507, 42.149000000017985, 50.05300000000255], 0.4: [11.172999999998916, 7.4949999999938814, -11.402999999992977, 9.000999999996667, 20.263000000009725, 35.76400000001385], 0.45: [-2.7499999999996727, 7.2519999999937825, -17.01599999998405, 11.349999999999302, 9.128999999991917, 26.577000000014806], 0.5: [-9.59900000000348, -7.0750000000091084, -18.485999999983186, 19.114000000009447, 2.2039999999992848, 13.22199999999916]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GhC6f7N6sJoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617441655185,"user_tz":-60,"elapsed":9182829,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"37cd8325-87ec-4124-a33b-1c0d3861f685"},"source":["targeted = {'goal': {}, 'action': {}}\n","untargeted = {'goal': {}, 'action': {}}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    for x in ['goal', 'action']:\n","        targeted[x][eps] = []\n","        untargeted[x][eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        apply_fgsm(agent, untargeted['action'], False)   \n","        print(f\"{i} fgsm (ut): {untargeted}\")\n","\n","        apply_fgsm(agent, targeted['action'], True)   \n","        print(f\"{i} fgsm (t): {targeted}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"fgsm (ut): {untargeted}\")\n","print(f\"fgsm (t): {targeted}\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["0 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194], 0.02: [65.66899999999004], 0.04: [49.55500000000247], 0.06: [-15.539999999995167], 0.08: [-30.80899999997043], 0.1: [-42.18099999997973], 0.12: [-41.73699999997243], 0.14: [-47.73999999999768], 0.16: [-45.39399999999188], 0.18: [-47.85299999999874], 0.2: [-47.78899999999763]}}\n","0 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238], 0.02: [91.17799999999372], 0.04: [61.23899999998941], 0.06: [57.88899999997363], 0.08: [53.40300000000178], 0.1: [47.95799999999078], 0.12: [36.42400000001663], 0.14: [31.294000000017377], 0.16: [20.647000000012962], 0.18: [34.57400000001631], 0.2: [19.4450000000063]}}\n","1 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338], 0.02: [65.66899999999004, 85.73099999998483], 0.04: [49.55500000000247, 50.05300000000164], 0.06: [-15.539999999995167, 28.953000000017724], 0.08: [-30.80899999997043, -17.035999999975402], 0.1: [-42.18099999997973, -25.984999999978687], 0.12: [-41.73699999997243, -32.024999999975904], 0.14: [-47.73999999999768, -34.174999999972584], 0.16: [-45.39399999999188, -38.7439999999689], 0.18: [-47.85299999999874, -41.18799999996953], 0.2: [-47.78899999999763, -35.92599999997214]}}\n","1 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979], 0.02: [91.17799999999372, 78.60399999998694], 0.04: [61.23899999998941, 50.546000000001634], 0.06: [57.88899999997363, 21.2430000000141], 0.08: [53.40300000000178, 30.215000000014893], 0.1: [47.95799999999078, 16.65100000000761], 0.12: [36.42400000001663, -7.557000000008777], 0.14: [31.294000000017377, -2.1520000000040636], 0.16: [20.647000000012962, -17.879999999985145], 0.18: [34.57400000001631, -14.954999999989116], 0.2: [19.4450000000063, -25.735999999979864]}}\n","2 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338, 86.00699999998947], 0.02: [65.66899999999004, 85.73099999998483, 79.23499999998218], 0.04: [49.55500000000247, 50.05300000000164, 29.32400000001184], 0.06: [-15.539999999995167, 28.953000000017724, -13.807999999993253], 0.08: [-30.80899999997043, -17.035999999975402, -34.88699999997356], 0.1: [-42.18099999997973, -25.984999999978687, -45.85299999998877], 0.12: [-41.73699999997243, -32.024999999975904, -47.406999999995335], 0.14: [-47.73999999999768, -34.174999999972584, -47.65299999999715], 0.16: [-45.39399999999188, -38.7439999999689, -47.404999999995326], 0.18: [-47.85299999999874, -41.18799999996953, -50.00000000000659], 0.2: [-47.78899999999763, -35.92599999997214, -47.62599999999727]}}\n","2 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979, 90.85899999999071], 0.02: [91.17799999999372, 78.60399999998694, 83.24599999999256], 0.04: [61.23899999998941, 50.546000000001634, 74.21999999998695], 0.06: [57.88899999997363, 21.2430000000141, 59.615999999983714], 0.08: [53.40300000000178, 30.215000000014893, 45.78600000001027], 0.1: [47.95799999999078, 16.65100000000761, 45.22200000000725], 0.12: [36.42400000001663, -7.557000000008777, 32.605000000019594], 0.14: [31.294000000017377, -2.1520000000040636, 17.54600000000915], 0.16: [20.647000000012962, -17.879999999985145, 8.405999999995617], 0.18: [34.57400000001631, -14.954999999989116, -5.67000000000287], 0.2: [19.4450000000063, -25.735999999979864, -12.704000000000274]}}\n","3 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338, 86.00699999998947, 81.08099999999136], 0.02: [65.66899999999004, 85.73099999998483, 79.23499999998218, 54.39399999998658], 0.04: [49.55500000000247, 50.05300000000164, 29.32400000001184, 38.07600000001324], 0.06: [-15.539999999995167, 28.953000000017724, -13.807999999993253, 21.053000000005923], 0.08: [-30.80899999997043, -17.035999999975402, -34.88699999997356, 1.1320000000010844], 0.1: [-42.18099999997973, -25.984999999978687, -45.85299999998877, -17.006999999987205], 0.12: [-41.73699999997243, -32.024999999975904, -47.406999999995335, -33.041999999974585], 0.14: [-47.73999999999768, -34.174999999972584, -47.65299999999715, -38.665999999968456], 0.16: [-45.39399999999188, -38.7439999999689, -47.404999999995326, -34.13599999997078], 0.18: [-47.85299999999874, -41.18799999996953, -50.00000000000659, -38.899999999969666], 0.2: [-47.78899999999763, -35.92599999997214, -47.62599999999727, -33.285999999974536]}}\n","3 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979, 90.85899999999071, 86.96499999999237], 0.02: [91.17799999999372, 78.60399999998694, 83.24599999999256, 50.71799999999719], 0.04: [61.23899999998941, 50.546000000001634, 74.21999999998695, 43.174000000010736], 0.06: [57.88899999997363, 21.2430000000141, 59.615999999983714, 39.476000000016285], 0.08: [53.40300000000178, 30.215000000014893, 45.78600000001027, 40.19000000001335], 0.1: [47.95799999999078, 16.65100000000761, 45.22200000000725, 29.966000000015246], 0.12: [36.42400000001663, -7.557000000008777, 32.605000000019594, 16.526000000008175], 0.14: [31.294000000017377, -2.1520000000040636, 17.54600000000915, 7.392999999997341], 0.16: [20.647000000012962, -17.879999999985145, 8.405999999995617, 4.914999999998553], 0.18: [34.57400000001631, -14.954999999989116, -5.67000000000287, -4.159000000003759], 0.2: [19.4450000000063, -25.735999999979864, -12.704000000000274, -12.685999999982885]}}\n","4 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338, 86.00699999998947, 81.08099999999136, 83.63599999998593], 0.02: [65.66899999999004, 85.73099999998483, 79.23499999998218, 54.39399999998658, 73.52299999998638], 0.04: [49.55500000000247, 50.05300000000164, 29.32400000001184, 38.07600000001324, 46.802000000013116], 0.06: [-15.539999999995167, 28.953000000017724, -13.807999999993253, 21.053000000005923, 0.6679999999999524], 0.08: [-30.80899999997043, -17.035999999975402, -34.88699999997356, 1.1320000000010844, -34.491999999972684], 0.1: [-42.18099999997973, -25.984999999978687, -45.85299999998877, -17.006999999987205, -43.0469999999847], 0.12: [-41.73699999997243, -32.024999999975904, -47.406999999995335, -33.041999999974585, -40.28999999997092], 0.14: [-47.73999999999768, -34.174999999972584, -47.65299999999715, -38.665999999968456, -47.25499999999933], 0.16: [-45.39399999999188, -38.7439999999689, -47.404999999995326, -34.13599999997078, -48.97500000000195], 0.18: [-47.85299999999874, -41.18799999996953, -50.00000000000659, -38.899999999969666, -48.59400000000056], 0.2: [-47.78899999999763, -35.92599999997214, -47.62599999999727, -33.285999999974536, -48.975000000003085]}}\n","4 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979, 90.85899999999071, 86.96499999999237, 79.28699999998702], 0.02: [91.17799999999372, 78.60399999998694, 83.24599999999256, 50.71799999999719, 84.21499999998679], 0.04: [61.23899999998941, 50.546000000001634, 74.21999999998695, 43.174000000010736, 71.76199999998212], 0.06: [57.88899999997363, 21.2430000000141, 59.615999999983714, 39.476000000016285, 73.81099999998823], 0.08: [53.40300000000178, 30.215000000014893, 45.78600000001027, 40.19000000001335, 62.54299999998801], 0.1: [47.95799999999078, 16.65100000000761, 45.22200000000725, 29.966000000015246, 57.017999999981384], 0.12: [36.42400000001663, -7.557000000008777, 32.605000000019594, 16.526000000008175, 44.10400000000913], 0.14: [31.294000000017377, -2.1520000000040636, 17.54600000000915, 7.392999999997341, 6.055999999994253], 0.16: [20.647000000012962, -17.879999999985145, 8.405999999995617, 4.914999999998553, -6.975000000001988], 0.18: [34.57400000001631, -14.954999999989116, -5.67000000000287, -4.159000000003759, -18.00899999998657], 0.2: [19.4450000000063, -25.735999999979864, -12.704000000000274, -12.685999999982885, -27.965999999975516]}}\n","5 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338, 86.00699999998947, 81.08099999999136, 83.63599999998593, 90.83999999999138], 0.02: [65.66899999999004, 85.73099999998483, 79.23499999998218, 54.39399999998658, 73.52299999998638, 84.32599999998938], 0.04: [49.55500000000247, 50.05300000000164, 29.32400000001184, 38.07600000001324, 46.802000000013116, 58.7409999999864], 0.06: [-15.539999999995167, 28.953000000017724, -13.807999999993253, 21.053000000005923, 0.6679999999999524, 6.795999999993877], 0.08: [-30.80899999997043, -17.035999999975402, -34.88699999997356, 1.1320000000010844, -34.491999999972684, -18.87199999998602], 0.1: [-42.18099999997973, -25.984999999978687, -45.85299999998877, -17.006999999987205, -43.0469999999847, -38.921999999968506], 0.12: [-41.73699999997243, -32.024999999975904, -47.406999999995335, -33.041999999974585, -40.28999999997092, -43.63299999998001], 0.14: [-47.73999999999768, -34.174999999972584, -47.65299999999715, -38.665999999968456, -47.25499999999933, -45.65399999998827], 0.16: [-45.39399999999188, -38.7439999999689, -47.404999999995326, -34.13599999997078, -48.97500000000195, -46.04099999998945], 0.18: [-47.85299999999874, -41.18799999996953, -50.00000000000659, -38.899999999969666, -48.59400000000056, -50.00000000000659], 0.2: [-47.78899999999763, -35.92599999997214, -47.62599999999727, -33.285999999974536, -48.975000000003085, -47.43399999999544]}}\n","5 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979, 90.85899999999071, 86.96499999999237, 79.28699999998702, 84.83299999998698], 0.02: [91.17799999999372, 78.60399999998694, 83.24599999999256, 50.71799999999719, 84.21499999998679, 84.51399999999192], 0.04: [61.23899999998941, 50.546000000001634, 74.21999999998695, 43.174000000010736, 71.76199999998212, 81.00499999998763], 0.06: [57.88899999997363, 21.2430000000141, 59.615999999983714, 39.476000000016285, 73.81099999998823, 65.15399999998874], 0.08: [53.40300000000178, 30.215000000014893, 45.78600000001027, 40.19000000001335, 62.54299999998801, 64.83599999998117], 0.1: [47.95799999999078, 16.65100000000761, 45.22200000000725, 29.966000000015246, 57.017999999981384, 57.36699999999308], 0.12: [36.42400000001663, -7.557000000008777, 32.605000000019594, 16.526000000008175, 44.10400000000913, 60.305999999982056], 0.14: [31.294000000017377, -2.1520000000040636, 17.54600000000915, 7.392999999997341, 6.055999999994253, 45.977000000001354], 0.16: [20.647000000012962, -17.879999999985145, 8.405999999995617, 4.914999999998553, -6.975000000001988, 34.46200000002189], 0.18: [34.57400000001631, -14.954999999989116, -5.67000000000287, -4.159000000003759, -18.00899999998657, 11.34200000001343], 0.2: [19.4450000000063, -25.735999999979864, -12.704000000000274, -12.685999999982885, -27.965999999975516, 4.348999999998699]}}\n","----\n","fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [91.30599999999194, 94.81599999999338, 86.00699999998947, 81.08099999999136, 83.63599999998593, 90.83999999999138], 0.02: [65.66899999999004, 85.73099999998483, 79.23499999998218, 54.39399999998658, 73.52299999998638, 84.32599999998938], 0.04: [49.55500000000247, 50.05300000000164, 29.32400000001184, 38.07600000001324, 46.802000000013116, 58.7409999999864], 0.06: [-15.539999999995167, 28.953000000017724, -13.807999999993253, 21.053000000005923, 0.6679999999999524, 6.795999999993877], 0.08: [-30.80899999997043, -17.035999999975402, -34.88699999997356, 1.1320000000010844, -34.491999999972684, -18.87199999998602], 0.1: [-42.18099999997973, -25.984999999978687, -45.85299999998877, -17.006999999987205, -43.0469999999847, -38.921999999968506], 0.12: [-41.73699999997243, -32.024999999975904, -47.406999999995335, -33.041999999974585, -40.28999999997092, -43.63299999998001], 0.14: [-47.73999999999768, -34.174999999972584, -47.65299999999715, -38.665999999968456, -47.25499999999933, -45.65399999998827], 0.16: [-45.39399999999188, -38.7439999999689, -47.404999999995326, -34.13599999997078, -48.97500000000195, -46.04099999998945], 0.18: [-47.85299999999874, -41.18799999996953, -50.00000000000659, -38.899999999969666, -48.59400000000056, -50.00000000000659], 0.2: [-47.78899999999763, -35.92599999997214, -47.62599999999727, -33.285999999974536, -48.975000000003085, -47.43399999999544]}}\n","fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [94.04499999999238, 91.26399999998979, 90.85899999999071, 86.96499999999237, 79.28699999998702, 84.83299999998698], 0.02: [91.17799999999372, 78.60399999998694, 83.24599999999256, 50.71799999999719, 84.21499999998679, 84.51399999999192], 0.04: [61.23899999998941, 50.546000000001634, 74.21999999998695, 43.174000000010736, 71.76199999998212, 81.00499999998763], 0.06: [57.88899999997363, 21.2430000000141, 59.615999999983714, 39.476000000016285, 73.81099999998823, 65.15399999998874], 0.08: [53.40300000000178, 30.215000000014893, 45.78600000001027, 40.19000000001335, 62.54299999998801, 64.83599999998117], 0.1: [47.95799999999078, 16.65100000000761, 45.22200000000725, 29.966000000015246, 57.017999999981384, 57.36699999999308], 0.12: [36.42400000001663, -7.557000000008777, 32.605000000019594, 16.526000000008175, 44.10400000000913, 60.305999999982056], 0.14: [31.294000000017377, -2.1520000000040636, 17.54600000000915, 7.392999999997341, 6.055999999994253, 45.977000000001354], 0.16: [20.647000000012962, -17.879999999985145, 8.405999999995617, 4.914999999998553, -6.975000000001988, 34.46200000002189], 0.18: [34.57400000001631, -14.954999999989116, -5.67000000000287, -4.159000000003759, -18.00899999998657, 11.34200000001343], 0.2: [19.4450000000063, -25.735999999979864, -12.704000000000274, -12.685999999982885, -27.965999999975516, 4.348999999998699]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8pnki1eCngGQ"},"source":["def eval_scale(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for scale in np.arange(1.0,7.01,0.5):\n","        env = NormalizedEnv(PointFallEnv(scale))\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(scale, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmUPiWlPqUts","executionInfo":{"status":"ok","timestamp":1616835326999,"user_tz":0,"elapsed":603315,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"45eb97e1-3c63-4b19-b0f8-563b902909c2"},"source":["episodes = {}\n","for scale in np.arange(1.0,7.01,0.5):\n","    episodes[np.round(scale, 2)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_scale(agent, episodes)\n","        print(f\"{i} scale: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"scale: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 scale: {1.0: [91.1679999999918], 1.5: [72.22999999998729], 2.0: [91.57099999998623], 2.5: [88.2239999999983], 3.0: [94.44199999999532], 3.5: [94.56699999999694], 4.0: [85.69399999999301], 4.5: [83.47999999998547], 5.0: [94.26399999999629], 5.5: [95.14899999999517], 6.0: [93.77299999999086], 6.5: [95.02599999999367], 7.0: [87.4489999999857]}\n","1 scale: {1.0: [91.1679999999918, 40.22800000001615], 1.5: [72.22999999998729, 60.04899999997886], 2.0: [91.57099999998623, 83.99999999998784], 2.5: [88.2239999999983, 81.78499999998633], 3.0: [94.44199999999532, 86.61799999998684], 3.5: [94.56699999999694, 93.94999999999078], 4.0: [85.69399999999301, 82.62599999998461], 4.5: [83.47999999998547, 90.371999999996], 5.0: [94.26399999999629, 87.37699999999], 5.5: [95.14899999999517, 88.49699999998397], 6.0: [93.77299999999086, 95.44799999999182], 6.5: [95.02599999999367, 87.86699999998514], 7.0: [87.4489999999857, 94.93099999999134]}\n","2 scale: {1.0: [91.1679999999918, 40.22800000001615, 70.27299999998115], 1.5: [72.22999999998729, 60.04899999997886, 89.92799999999028], 2.0: [91.57099999998623, 83.99999999998784, 84.26699999998254], 2.5: [88.2239999999983, 81.78499999998633, 90.15599999998938], 3.0: [94.44199999999532, 86.61799999998684, 92.2309999999898], 3.5: [94.56699999999694, 93.94999999999078, 88.04199999999575], 4.0: [85.69399999999301, 82.62599999998461, 85.8799999999951], 4.5: [83.47999999998547, 90.371999999996, 80.21599999998126], 5.0: [94.26399999999629, 87.37699999999, 81.50599999998545], 5.5: [95.14899999999517, 88.49699999998397, 83.09299999998551], 6.0: [93.77299999999086, 95.44799999999182, 83.92699999999041], 6.5: [95.02599999999367, 87.86699999998514, 73.36199999999353], 7.0: [87.4489999999857, 94.93099999999134, 80.46899999999326]}\n","3 scale: {1.0: [91.1679999999918, 40.22800000001615, 70.27299999998115, 68.88099999997873], 1.5: [72.22999999998729, 60.04899999997886, 89.92799999999028, 46.36199999999848], 2.0: [91.57099999998623, 83.99999999998784, 84.26699999998254, 85.80399999999314], 2.5: [88.2239999999983, 81.78499999998633, 90.15599999998938, 87.07899999998979], 3.0: [94.44199999999532, 86.61799999998684, 92.2309999999898, 87.6139999999909], 3.5: [94.56699999999694, 93.94999999999078, 88.04199999999575, 85.71999999998843], 4.0: [85.69399999999301, 82.62599999998461, 85.8799999999951, 82.46899999998539], 4.5: [83.47999999998547, 90.371999999996, 80.21599999998126, 86.51999999999065], 5.0: [94.26399999999629, 87.37699999999, 81.50599999998545, 78.77899999998503], 5.5: [95.14899999999517, 88.49699999998397, 83.09299999998551, 88.91399999999354], 6.0: [93.77299999999086, 95.44799999999182, 83.92699999999041, 87.38899999998797], 6.5: [95.02599999999367, 87.86699999998514, 73.36199999999353, 85.5089999999876], 7.0: [87.4489999999857, 94.93099999999134, 80.46899999999326, 83.57399999998395]}\n","4 scale: {1.0: [91.1679999999918, 40.22800000001615, 70.27299999998115, 68.88099999997873, 65.86199999998716], 1.5: [72.22999999998729, 60.04899999997886, 89.92799999999028, 46.36199999999848, 59.67599999998566], 2.0: [91.57099999998623, 83.99999999998784, 84.26699999998254, 85.80399999999314, 74.2809999999762], 2.5: [88.2239999999983, 81.78499999998633, 90.15599999998938, 87.07899999998979, 86.92699999998615], 3.0: [94.44199999999532, 86.61799999998684, 92.2309999999898, 87.6139999999909, 69.47599999997847], 3.5: [94.56699999999694, 93.94999999999078, 88.04199999999575, 85.71999999998843, 79.61299999998543], 4.0: [85.69399999999301, 82.62599999998461, 85.8799999999951, 82.46899999998539, 88.44099999998605], 4.5: [83.47999999998547, 90.371999999996, 80.21599999998126, 86.51999999999065, 82.82099999998646], 5.0: [94.26399999999629, 87.37699999999, 81.50599999998545, 78.77899999998503, 87.97399999998731], 5.5: [95.14899999999517, 88.49699999998397, 83.09299999998551, 88.91399999999354, 84.27499999998628], 6.0: [93.77299999999086, 95.44799999999182, 83.92699999999041, 87.38899999998797, 82.55799999998345], 6.5: [95.02599999999367, 87.86699999998514, 73.36199999999353, 85.5089999999876, 82.63699999998359], 7.0: [87.4489999999857, 94.93099999999134, 80.46899999999326, 83.57399999998395, 87.17899999998764]}\n","5 scale: {1.0: [91.1679999999918, 40.22800000001615, 70.27299999998115, 68.88099999997873, 65.86199999998716, 53.37399999999147], 1.5: [72.22999999998729, 60.04899999997886, 89.92799999999028, 46.36199999999848, 59.67599999998566, 61.50099999999578], 2.0: [91.57099999998623, 83.99999999998784, 84.26699999998254, 85.80399999999314, 74.2809999999762, 86.02199999999193], 2.5: [88.2239999999983, 81.78499999998633, 90.15599999998938, 87.07899999998979, 86.92699999998615, 81.8799999999888], 3.0: [94.44199999999532, 86.61799999998684, 92.2309999999898, 87.6139999999909, 69.47599999997847, 92.18499999999625], 3.5: [94.56699999999694, 93.94999999999078, 88.04199999999575, 85.71999999998843, 79.61299999998543, 88.30099999999246], 4.0: [85.69399999999301, 82.62599999998461, 85.8799999999951, 82.46899999998539, 88.44099999998605, 86.81999999999015], 4.5: [83.47999999998547, 90.371999999996, 80.21599999998126, 86.51999999999065, 82.82099999998646, 91.9589999999907], 5.0: [94.26399999999629, 87.37699999999, 81.50599999998545, 78.77899999998503, 87.97399999998731, 88.82899999998376], 5.5: [95.14899999999517, 88.49699999998397, 83.09299999998551, 88.91399999999354, 84.27499999998628, 88.944999999989], 6.0: [93.77299999999086, 95.44799999999182, 83.92699999999041, 87.38899999998797, 82.55799999998345, 91.67399999999081], 6.5: [95.02599999999367, 87.86699999998514, 73.36199999999353, 85.5089999999876, 82.63699999998359, 91.3859999999893], 7.0: [87.4489999999857, 94.93099999999134, 80.46899999999326, 83.57399999998395, 87.17899999998764, 91.05699999998798]}\n","----\n","scale: {1.0: [91.1679999999918, 40.22800000001615, 70.27299999998115, 68.88099999997873, 65.86199999998716, 53.37399999999147], 1.5: [72.22999999998729, 60.04899999997886, 89.92799999999028, 46.36199999999848, 59.67599999998566, 61.50099999999578], 2.0: [91.57099999998623, 83.99999999998784, 84.26699999998254, 85.80399999999314, 74.2809999999762, 86.02199999999193], 2.5: [88.2239999999983, 81.78499999998633, 90.15599999998938, 87.07899999998979, 86.92699999998615, 81.8799999999888], 3.0: [94.44199999999532, 86.61799999998684, 92.2309999999898, 87.6139999999909, 69.47599999997847, 92.18499999999625], 3.5: [94.56699999999694, 93.94999999999078, 88.04199999999575, 85.71999999998843, 79.61299999998543, 88.30099999999246], 4.0: [85.69399999999301, 82.62599999998461, 85.8799999999951, 82.46899999998539, 88.44099999998605, 86.81999999999015], 4.5: [83.47999999998547, 90.371999999996, 80.21599999998126, 86.51999999999065, 82.82099999998646, 91.9589999999907], 5.0: [94.26399999999629, 87.37699999999, 81.50599999998545, 78.77899999998503, 87.97399999998731, 88.82899999998376], 5.5: [95.14899999999517, 88.49699999998397, 83.09299999998551, 88.91399999999354, 84.27499999998628, 88.944999999989], 6.0: [93.77299999999086, 95.44799999999182, 83.92699999999041, 87.38899999998797, 82.55799999998345, 91.67399999999081], 6.5: [95.02599999999367, 87.86699999998514, 73.36199999999353, 85.5089999999876, 82.63699999998359, 91.3859999999893], 7.0: [87.4489999999857, 94.93099999999134, 80.46899999999326, 83.57399999998395, 87.17899999998764, 91.05699999998798]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gd2_86AIqOt4"},"source":["def eval_starting_position(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for extra_range in np.arange(0.0, 0.401, 0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            extra = np.random.uniform(-0.1 - extra_range, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = np.random.uniform(0.1, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = extra * (2*np.random.randint(0,2,size=env.starting_point.shape)-1)\n","            env.unwrapped.state = np.array(env.starting_point + extra, dtype=np.float32)\n","            env.unwrapped.state[2] += math.pi / 2. # start facing up\n","            env.unwrapped.state[2] = env.state[2] % (2 * math.pi)\n","            observation = env.normalised_state()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(extra_range, 3)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJjpZcCLqjua","executionInfo":{"status":"ok","timestamp":1616952965133,"user_tz":-60,"elapsed":476075,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"c5812852-d50e-4965-ac02-b812261e7139"},"source":["episodes = {}\n","for extra_range in np.arange(0.0, 0.401, 0.05):\n","    episodes[np.round(extra_range, 3)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","env = NormalizedEnv(PointFallEnv(4))\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_starting_position(agent, episodes)\n","        print(f\"{i} range: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"range: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 range: {0.0: [83.512999999987], 0.05: [87.97299999998933], 0.1: [86.32699999998685], 0.15: [72.5779999999812], 0.2: [72.62499999999773], 0.25: [70.70199999999092], 0.3: [63.52299999998964], 0.35: [64.36499999998743], 0.4: [53.907999999995454]}\n","1 range: {0.0: [83.512999999987, 93.56999999999499], 0.05: [87.97299999998933, 80.02199999999144], 0.1: [86.32699999998685, 90.57699999999095], 0.15: [72.5779999999812, 81.15899999999509], 0.2: [72.62499999999773, 84.52599999998215], 0.25: [70.70199999999092, 78.80899999998455], 0.3: [63.52299999998964, 85.04899999998237], 0.35: [64.36499999998743, 81.8629999999911], 0.4: [53.907999999995454, 75.45299999998343]}\n","2 range: {0.0: [83.512999999987, 93.56999999999499, 86.3789999999866], 0.05: [87.97299999998933, 80.02199999999144, 88.74999999998455], 0.1: [86.32699999998685, 90.57699999999095, 86.49599999998907], 0.15: [72.5779999999812, 81.15899999999509, 77.71799999998262], 0.2: [72.62499999999773, 84.52599999998215, 82.48399999999646], 0.25: [70.70199999999092, 78.80899999998455, 72.20199999997399], 0.3: [63.52299999998964, 85.04899999998237, 71.26099999998642], 0.35: [64.36499999998743, 81.8629999999911, 66.34199999999127], 0.4: [53.907999999995454, 75.45299999998343, 72.27399999999541]}\n","3 range: {0.0: [83.512999999987, 93.56999999999499, 86.3789999999866, 93.85999999999039], 0.05: [87.97299999998933, 80.02199999999144, 88.74999999998455, 82.37999999998434], 0.1: [86.32699999998685, 90.57699999999095, 86.49599999998907, 83.94399999999088], 0.15: [72.5779999999812, 81.15899999999509, 77.71799999998262, 74.36699999998685], 0.2: [72.62499999999773, 84.52599999998215, 82.48399999999646, 74.23299999998608], 0.25: [70.70199999999092, 78.80899999998455, 72.20199999997399, 70.5359999999758], 0.3: [63.52299999998964, 85.04899999998237, 71.26099999998642, 57.18599999999475], 0.35: [64.36499999998743, 81.8629999999911, 66.34199999999127, 62.73899999997625], 0.4: [53.907999999995454, 75.45299999998343, 72.27399999999541, 52.58000000000744]}\n","4 range: {0.0: [83.512999999987, 93.56999999999499, 86.3789999999866, 93.85999999999039, 81.42599999999047], 0.05: [87.97299999998933, 80.02199999999144, 88.74999999998455, 82.37999999998434, 88.24199999999581], 0.1: [86.32699999998685, 90.57699999999095, 86.49599999998907, 83.94399999999088, 87.9779999999825], 0.15: [72.5779999999812, 81.15899999999509, 77.71799999998262, 74.36699999998685, 84.28199999998618], 0.2: [72.62499999999773, 84.52599999998215, 82.48399999999646, 74.23299999998608, 81.86599999998406], 0.25: [70.70199999999092, 78.80899999998455, 72.20199999997399, 70.5359999999758, 79.32299999998325], 0.3: [63.52299999998964, 85.04899999998237, 71.26099999998642, 57.18599999999475, 71.16199999998655], 0.35: [64.36499999998743, 81.8629999999911, 66.34199999999127, 62.73899999997625, 78.88399999999125], 0.4: [53.907999999995454, 75.45299999998343, 72.27399999999541, 52.58000000000744, 71.43999999998378]}\n","5 range: {0.0: [83.512999999987, 93.56999999999499, 86.3789999999866, 93.85999999999039, 81.42599999999047, 91.24899999998941], 0.05: [87.97299999998933, 80.02199999999144, 88.74999999998455, 82.37999999998434, 88.24199999999581, 85.14399999999198], 0.1: [86.32699999998685, 90.57699999999095, 86.49599999998907, 83.94399999999088, 87.9779999999825, 91.05499999999293], 0.15: [72.5779999999812, 81.15899999999509, 77.71799999998262, 74.36699999998685, 84.28199999998618, 86.27899999999136], 0.2: [72.62499999999773, 84.52599999998215, 82.48399999999646, 74.23299999998608, 81.86599999998406, 80.02099999999649], 0.25: [70.70199999999092, 78.80899999998455, 72.20199999997399, 70.5359999999758, 79.32299999998325, 84.31299999999628], 0.3: [63.52299999998964, 85.04899999998237, 71.26099999998642, 57.18599999999475, 71.16199999998655, 75.9229999999889], 0.35: [64.36499999998743, 81.8629999999911, 66.34199999999127, 62.73899999997625, 78.88399999999125, 70.3919999999908], 0.4: [53.907999999995454, 75.45299999998343, 72.27399999999541, 52.58000000000744, 71.43999999998378, 66.0969999999819]}\n","----\n","range: {0.0: [83.512999999987, 93.56999999999499, 86.3789999999866, 93.85999999999039, 81.42599999999047, 91.24899999998941], 0.05: [87.97299999998933, 80.02199999999144, 88.74999999998455, 82.37999999998434, 88.24199999999581, 85.14399999999198], 0.1: [86.32699999998685, 90.57699999999095, 86.49599999998907, 83.94399999999088, 87.9779999999825, 91.05499999999293], 0.15: [72.5779999999812, 81.15899999999509, 77.71799999998262, 74.36699999998685, 84.28199999998618, 86.27899999999136], 0.2: [72.62499999999773, 84.52599999998215, 82.48399999999646, 74.23299999998608, 81.86599999998406, 80.02099999999649], 0.25: [70.70199999999092, 78.80899999998455, 72.20199999997399, 70.5359999999758, 79.32299999998325, 84.31299999999628], 0.3: [63.52299999998964, 85.04899999998237, 71.26099999998642, 57.18599999999475, 71.16199999998655, 75.9229999999889], 0.35: [64.36499999998743, 81.8629999999911, 66.34199999999127, 62.73899999997625, 78.88399999999125, 70.3919999999908], 0.4: [53.907999999995454, 75.45299999998343, 72.27399999999541, 52.58000000000744, 71.43999999998378, 66.0969999999819]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BhvsIWF-qrHj"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def save_trajectories(agent, episode_durations, dirty):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    for i_episode in range(num_episodes):\n","        path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","        if dirty:\n","            g_state = g_state + state_range * noise\n","            g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","        if dirty:\n","            state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","            state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","        episode_steps = 0\n","        overall_reward = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","            path[\"manager\"].append((episode_steps, g_state_.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                path[\"worker\"].append((episode_steps, torch.cat([state_, goal], 1).detach().cpu().squeeze(0).numpy(), action.detach().cpu().squeeze(0).numpy()))\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                if dirty:\n","                    g_next_state = g_next_state + state_range * noise\n","                    g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                if dirty:\n","                    next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","\n","        path[\"overall_reward\"] = overall_reward\n","        episode_durations[-1].append(path)\n","\n","def save_random_manager(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_points = 10000\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","    for _ in range(num_points):\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        noise = torch.FloatTensor(state.shape).uniform_(0.0, 1.0).to(device)\n","\n","        g_state = state_min + state_range * noise\n","        g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","\n","        goal = agent.select_goal(g_state, False, False)\n","        path[\"manager\"].append((0, g_state.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","    episode_durations[-1].append(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWeLBDKTP3Ao","executionInfo":{"status":"ok","timestamp":1616493270550,"user_tz":0,"elapsed":38321,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"0107b42c-f0dc-4328-af79-819acc958d8a"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        #save_trajectories(agent, episodes, False)\n","        save_random_manager(agent, episodes)\n","        #print(f\"{i} paths: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","#print(f\"paths: {episodes}\")\n","\n","episodes.pop(1)\n","torch.save(episodes, \"PointMaze_Freeze_manager.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iCL5ZZqTjleO"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_2\")\n","\n","save_trajectories(agent, episodes, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"3fRbRytzj5Ek","executionInfo":{"status":"ok","timestamp":1616947714655,"user_tz":-60,"elapsed":1514,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"8c8938ff-254e-48a3-e38f-4e2ad57d6210"},"source":["i = 1\n","\n","x = [t[1][0] for t in episodes[0][i]['worker']]\n","y = [t[1][1] for t in episodes[0][i]['worker']]\n","\n","x2 = [t[2][0] for t in episodes[0][i]['manager']]\n","y2 = [t[2][1] for t in episodes[0][i]['manager']]\n","\n","plt.scatter(x, y)\n","plt.scatter(x2, y2, c='r')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWrElEQVR4nO3df5Dc9X3f8eebQxCpLhG2NDEcEoddhRSqFDk3WCkzCXZ+gJkEqYQ0oiLGrjNqHLuN05QpRIzdemBwwkw88eAxvbGp7fgG02JyVWp5VBzwOOlY1IclIwOVLZMCOmiQIYIwUjCS3/1jvydWp93b3bv98d3vPR8zN7f7+X73u2++u7zuq8/38/18IzORJA2/0wZdgCSpOwx0SaoIA12SKsJAl6SKMNAlqSJOH9Qbr1q1KsfGxgb19pI0lB555JEfZObqRssGFuhjY2NMT08P6u0laShFxFPNltnlIkkVYaBLUkUY6JJUEQa6JFWEgS5JFTGwUS6Sym1qzwx37NrPs4ePcu7K5dx4xYVs3jA66LI0DwNd0imm9sxw8/37OPracQBmDh/l5vv3ARjqJWaXi6RT3LFr/4kwn3X0tePcsWv/gCpSOwx0Sad49vDRjtpVDga6pFOcu3J5R+0qBwNd0iluvOJCli8bOalt+bIRbrziwgFVpHa0DPSIWBMRD0XE4xHxWET8boN1Lo+IlyJib/Hz4d6UK6kfNm8Y5fZr1jO6cjkBjK5czu3XrPeEaMm1M8rlGPD7mfmtiPiHwCMR8UBmPj5nvb/MzF/pfomSBmHzhlEDfMi0PELPzOcy81vF478DngD8lCWpZDrqQ4+IMWAD8HCDxT8bEd+OiK9ExMVNXr8tIqYjYvrQoUMdFytJaq7tC4si4g3Al4APZebLcxZ/Czg/M1+JiKuAKWDd3G1k5gQwATA+Pp4LrlpSZXmF6sK1dYQeEcuohflkZt4/d3lmvpyZrxSPdwLLImJVVyuVVHmzV6jOHD5K8voVqlN7ZgZd2lBoZ5RLAJ8BnsjMP26yzpuL9YiIS4vtvtDNQiVVn1eoLk47XS6XAb8J7IuIvUXbHwBrATLzLuBa4P0RcQw4CmzJTLtUJHXEK1QXp2WgZ+ZfAdFinTuBO7tVlKSl6dyVy5lpEN5eodoerxSVVBpeobo4Tp8rqTRmR7M4ymVhDHRJpeIVqgtnl4skVYSBLkkVYaBLUkUY6JJUEZ4UlbRkVW3eGANd0pI0O2/M7FQDs/PGAEMb6na5SFqSqjhvjIEuaUmq4rwxBrqkJanZ/DDDPG+MgS5pSarivDGeFJW0JFVx3hgDXdKSVbV5Y+xykaSKMNAlqSIMdEmqCANdkirCQJekijDQJakiDHRJqgjHoUvSIpVlGl4DXZIWoUzT8NrlIkmLUKZpeFsGekSsiYiHIuLxiHgsIn63wToREZ+IiAMR8WhEvK035UpSuZRpGt52jtCPAb+fmRcBG4EPRMRFc9Z5F7Cu+NkGfKqrVUpSSZVpGt6WgZ6Zz2Xmt4rHfwc8AcztGNoEfD5rdgMrI+KcrlcrSSVTpml4OzopGhFjwAbg4TmLRoFn6p4fLNqem/P6bdSO4Fm7dm1nlUpSCZVpGt62Az0i3gB8CfhQZr68kDfLzAlgAmB8fDwXsg1JKpuyTMPb1iiXiFhGLcwnM/P+BqvMAGvqnp9XtEmS+qSdUS4BfAZ4IjP/uMlqO4B3F6NdNgIvZeZzTdaVJPVAO10ulwG/CeyLiL1F2x8AawEy8y5gJ3AVcAA4Ary3+6VKkubTMtAz86+AaLFOAh/oVlGSpM55pagkVYSBLkkVYaBLUkUY6JJUEQa6JFWE86FLUh/04yYYBrok9Vi/boJhl4sk9Vi/boJhoEtSj/XrJhgGuiT1WL9ugmGgS1KP9esmGJ4UlaQe69dNMAx0SeqDftwEwy4XSaoIA12SKsJAl6SKMNAlqSIMdEmqCANdkirCQJekijDQJakiDHRJqgivFJWkPun1TS4MdEnqg37c5MIuF0nqg37c5KJloEfE3RHxfER8p8nyyyPipYjYW/x8uGvVSVJF9OMmF+0coX8WuLLFOn+ZmZcUPx9dfFmSVC39uMlFy0DPzK8DL3btHSVpCerHTS661Yf+sxHx7Yj4SkRc3GyliNgWEdMRMX3o0KEuvbUkld/mDaPcfs16RlcuJ4DRlcu5/Zr1XR3lEpnZeqWIMeB/ZOY/abDsLOBHmflKRFwF/Elmrmu1zfHx8Zyenu68YklawiLikcwcb7Rs0UfomflyZr5SPN4JLIuIVYvdriSpM4sO9Ih4c0RE8fjSYpsvLHa7kqTOtLywKCLuAS4HVkXEQeAjwDKAzLwLuBZ4f0QcA44CW7KdfhxJUle1DPTMvK7F8juBO7tWkSRpQbxSVJIqwkCXpIpwci5JmuOWqX3c8/AzHM9kJILr3r6GWzevH3RZLRnoklTnlql9fGH30yeeH8888bzsoW6XiyTVuefhZzpqLxMDXZLqHG8y6rpZe5nY5SJp4Hp9J59OjEQ0DO+R2vWTpeYRuqSBmr2Tz8zhoySv38lnas/MQOq57u1rOmovEwNd0kD1404+nbh183qu37j2xBH5SATXb1xb+hOiYJeLpAHrx518OnXr5vVDEeBzeYQuaaD6cSefpcJAlzRQ/biTz1JhoEsaqH7cyecUk5MwNgannVb7PTnZu/fqI/vQJQ3c5g2j/RumODkJ27bBkSO15089VXsOsHVrf2roEY/QJS0t27e/Huazjhxh5nd+j1um9g2mpi4x0CUtLU8/3bD5nJd/wBd2Pz3UoW6gS1pa1q5t2PzsWbVbIQ/DnC3NGOiSlpbbboMVK05qOnL6mfzRz70bGI45W5ox0CUtLVu3wsQEM2et5kcEB89azU1XfpAdF78DGI45W5pxlIukpWfrVj71D376pHnPZw3DnC3NGOiSlqTZS/uH8c5EzUQOqL9ofHw8p6enB/LekjSsIuKRzBxvtMw+dEmqCANdkirCQJekijDQJakiWgZ6RNwdEc9HxHeaLI+I+EREHIiIRyPibd0vU5LUSjtH6J8Frpxn+buAdcXPNuBTiy9LktSploGemV8HXpxnlU3A57NmN7AyIs7pVoGSpPZ0ow99FKifzeZg0XaKiNgWEdMRMX3o0KEuvLUkaVZfrxTNzAlgAmoXFvXzvSVpsW6Z2lfqK0u7EegzQP3kB+cVbZJUGbdM7Ttp7pfjmSeelyXUu9HlsgN4dzHaZSPwUmY+14XtSlJpNJsnvUzzp7c8Qo+Ie4DLgVURcRD4CLAMIDPvAnYCVwEHgCPAe3tVrCQNSrN50ss0f3rLQM/M61osT+ADXatIkkpoJKJheJdp/nSvFJWkNjSbJ71M86c7H7oktWEY5k93PnRJGiLOhy5JS4CBLkkVYaBLUkUY6JJUEQa6JFWEgS5JFWGgS1JFGOiSVBEGuiRVhJf+S9I8yn5Ti3oGuiQ1MQw3tahnl4skNTEMN7WoZ6BLUhPDcFOLega6JDXR7OYVZbqpRT0DXZKaGIabWtTzpKgkNTEMN7Wo5w0uJGmIeIMLSVoCDHRJqggDXZIqwkCXpIow0CWpItoK9Ii4MiL2R8SBiLipwfL3RMShiNhb/PxW90uVJM2n5Tj0iBgBPgn8EnAQ+GZE7MjMx+esem9mfrAHNUqS2tDOEfqlwIHMfDIzfwh8EdjU27IkSZ1qJ9BHgfqpxQ4WbXP9WkQ8GhH3RUTD62IjYltETEfE9KFDhxZQrobS5CSMjcFpp9V+T04OuiItEbdM7eOtN+9k7KYv89abd3LL1L5Bl9RT3Top+ufAWGb+NPAA8LlGK2XmRGaOZ+b46tWru/TWKrXJSdi2DZ56CjJrv7dtM9TVc7Nzmc/OjDg7l3mVQ72dQJ8B6o+4zyvaTsjMFzLz1eLpp4Gf6U55Gnrbt8ORIye3HTlSa5d6aNjmMu+GdgL9m8C6iLggIs4AtgA76leIiHPqnl4NPNG9EjXUnn66s3apS4ZtLvNuaDnKJTOPRcQHgV3ACHB3Zj4WER8FpjNzB/BvI+Jq4BjwIvCeHtasYbJ2ba2bpVG71EMjEQ3Du6xzmXdDW33ombkzM38yM9+ambcVbR8uwpzMvDkzL87Mf5qZ78jM/9PLojVEbrsNVqw4uW3Filq71EPDNpd5N3ilqHpr61aYmIDzz4eI2u+JiVq71EO3bl7P9RvXnjgiH4ng+o1rSzuXeTc4H7okDRHnQ5ekJcBAl6SKMNAlqSIMdEmqCANdkirCQJekijDQJakiWl76L0mDMrVnhjt27efZw0c5d+VybrziQjZvaDR7t8BAl1RSU3tmuPn+fRx97TgAM4ePcvP9talvDfXG7HKRVEp37Np/IsxnHX3tOHfs2j+gisrPQJdUSs8ePtpRuwx0SSV17srlHbXLQJdUUjdecSHLl42c1LZ82Qg3XnHhgCoqP0+KSiql2ROfjnJpn4EuqbQ2bxg1wDtgl4skVYSBLkkVYaBLUkUY6JJUEQa6JFWEgS5JFWGgS1JFOA5dUlc41e3gtRXoEXEl8CfACPDpzPzYnOVnAp8HfgZ4AfiNzPy/3S1VWhwDp3ec6rYcWna5RMQI8EngXcBFwHURcdGc1d4H/G1m/iPg48AfdrtQaTFmA2fm8FGS1wNnas/MoEurBKe6LYd2+tAvBQ5k5pOZ+UPgi8CmOetsAj5XPL4P+IWIiO6VKS2OgdNbTnVbDu0E+ijwTN3zg0Vbw3Uy8xjwEvCmuRuKiG0RMR0R04cOHVpYxdICGDi95VS35dDXUS6ZOZGZ45k5vnr16n6+tZY4A+dUU3tmuOxjD3LBTV/mso89uKjuJ6e6LYd2An0GWFP3/LyireE6EXE68OPUTo5KpWDgnKzb5xQ2bxjl9mvWM7pyOQGMrlzO7des94Ron7UzyuWbwLqIuIBacG8B/uWcdXYANwDfAK4FHszM7Gah0mI4t/bJ5junsNB94lS3g9cy0DPzWER8ENhFbdji3Zn5WER8FJjOzB3AZ4A/jYgDwIvUQl8qlV4EzrAOhfScQjW1NQ49M3cCO+e0fbju8d8Dv97d0qRyG+ax1+euXM5Mg/BeyucUqsBL/6UFGuahkJ5TqCYv/ZcWqOzdFrdM7eOeh5/heCYjEVz39jXcunk94DmFqjLQpQUqY7fFbJ/+3LqOZ/KF3U8DnBTqBni12OUiLVCZui2m9sxwyX/6n3zo3r0N/8jMuufhZ5ou0/DzCF1aoLJ0W8w9OTuf444mrjQDXVqEbndbLGQYZKOTs82MOMVSpRnoUkksdBhkJydhr3v7mtYraWjZhy6VRKthkM3mXmnnJOxIBNdvXHvihKiqySN0aY5BXf053zDI+Y7eb7ziwoZ96GevWMZHfvViR7IsIQa6VGeQV3/ONwxyvqP3/3XTO4HBn5zV4BnoUp1eTFrVrkZH2rPDIH/v3r0NXzN7VO+YcsGw9aFPTsLYGJx2Wu335OSgK1LFDPLqz/mmoHU+d7VjeI7QJydh2zY4cqT2/Kmnas8Btm4dXF2qhNl+82ajtPsVnM2OtOc7epdmDc8R+vbtr4f5rCNHau3SItTf7KGRMgSnN5BQO4bnCP3ppztrl9o034U5oyU6wWg/uVoZnkBfu7bWzdKoXVqEZv3jASdGkEjDYHi6XG67DVasOLltxYpau7QInnBUVQxPoG/dChMTcP75EFH7PTHhCVEtWplmTZQWY3i6XKAW3ga4uqwssyZKizVcgS71iCccVQXD0+UiSZqXgS5JFWGgS1JFGOiSVBEGuiRVROSAbhobEYeA+ks/VwE/GEgx8ytjXWWsCayrE2WsCayrE4Oq6fzMXN1owcACfa6ImM7M8UHXMVcZ6ypjTWBdnShjTWBdnShjTXa5SFJFGOiSVBFlCvSJQRfQRBnrKmNNYF2dKGNNYF2dKF1NpelDlyQtTpmO0CVJi2CgS1JF9DXQI+LXI+KxiPhRRDQd7hMRV0bE/og4EBE31bVfEBEPF+33RsQZXajpjRHxQER8r/h9doN13hERe+t+/j4iNhfLPhsRf1237JLF1tRuXcV6x+vee0dde9f3Vbt1RcQlEfGN4rN+NCJ+o25Z1/ZXs+9J3fIzi//2A8W+GKtbdnPRvj8irlhoDQus699FxOPFvvmLiDi/blnDz7NPdb0nIg7Vvf9v1S27ofjMvxcRN/Sxpo/X1fPdiDhct6wn+yoi7o6I5yPiO02WR0R8oqj50Yh4W92ynuyntmVm336AfwxcCHwNGG+yzgjwfeAtwBnAt4GLimX/FdhSPL4LeH8Xavoj4Kbi8U3AH7ZY/43Ai8CK4vlngWt7sK/aqgt4pUl71/dVu3UBPwmsKx6fCzwHrOzm/prve1K3zu8AdxWPtwD3Fo8vKtY/E7ig2M5Il/ZPO3W9o+778/7Zuub7PPtU13uAOxu89o3Ak8Xvs4vHZ/ejpjnr/xvg7j7sq58D3gZ8p8nyq4CvULtL4Ubg4V7up05++nqEnplPZOb+FqtdChzIzCcz84fAF4FNERHAO4H7ivU+B2zuQlmbim21u81rga9k5pEuvPd8Oq3rhB7uq7bqyszvZub3isfPAs8DDa9sW4SG35N5ar0P+IVi32wCvpiZr2bmXwMHiu31pa7MfKju+7MbOK9L772ouuZxBfBAZr6YmX8LPABcOYCargPu6cL7ziszv07toK2ZTcDns2Y3sDIizqF3+6ltZexDHwWeqXt+sGh7E3A4M4/NaV+sn8jM54rH/w/4iRbrb+HUL9VtxT+9Ph4RZ3ahpk7q+rGImI6I3bPdQPRuX3VSFwARcSm1o6/v1zV3Y381+540XKfYFy9R2zftvHahOt32+6gd7c1q9Hn2s65fKz6b+yJiTYev7VVNFN1SFwAP1jX3al+10qzuXn6v2tL1OxZFxFeBNzdYtD0z/3u3368d89VU/yQzMyKajuMs/gqvB3bVNd9MLdjOoDYu9T8AH+1jXedn5kxEvAV4MCL2UQuuBevy/vpT4IbM/FHRvOD9VTURcT0wDvx8XfMpn2dmfr/xFrruz4F7MvPViPjX1P51884+vXcrW4D7MvN4Xdsg91UpdT3QM/MXF7mJGWBN3fPzirYXqP3T5vTiaGu2fVE1RcTfRMQ5mflcEUDPz7OpfwH8WWa+Vrft2aPVVyPivwD/vp2aulVXZs4Uv5+MiK8BG4AvscB91a26IuIs4MvU/pDvrtv2gvfXHM2+J43WORgRpwM/Tu171M5rF6qtbUfEL1L7A/nzmfnqbHuTz7MbIdWyrsx8oe7pp6mdL5l97eVzXvu1ftRUZwvwgfqGHu6rVprV3av91LYydrl8E1gXtVEaZ1D7IHdk7azDQ9T6sAFuALpxxL+j2FY72zylD68Itdl+681AwzPjvagrIs6e7bKIiFXAZcDjPdxX7dZ1BvBn1PoZ75uzrFv7q+H3ZJ5arwUeLPbNDmBL1EbBXACsA/73AuvouK6I2AD8Z+DqzHy+rr3h59nHus6pe3o18ETxeBfwy0V9ZwO/zMn/Su1ZTUVdP0XtJOM36tp6ua9a2QG8uxjtshF4qThQ6dV+al8/z8AC/5xav9KrwN8Au4r2c4GddetdBXyX2l/b7XXtb6H2P94B4L8BZ3ahpjcBfwF8D/gq8MaifRz4dN16Y9T+Ap825/UPAvuoBdMXgDd0aV+1rAv4Z8V7f7v4/b5e7qsO6roeeA3YW/dzSbf3V6PvCbXum6uLxz9W/LcfKPbFW+peu7143X7gXV3+nreq66vF93923+xo9Xn2qa7bgceK938I+Km61/6rYj8eAN7br5qK5/8R+Nic1/VsX1E7aHuu+A4fpHae47eB3y6WB/DJouZ91I3Y69V+avfHS/8lqSLK2OUiSVoAA12SKsJAl6SKMNAlqSIMdEmqCANdkirCQJekivj/w7pklrHpOkQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Y6VhJjD8QHJl"},"source":["def get_intrinsic_reward(agent):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    overall_reward = 0\n","    intr_rews = []\n","\n","    for i_episode in range(num_episodes):\n","        cur_intr = []\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_steps = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                cur_intr.append(agent.intrinsic_reward(reward, state, goal, next_state).detach().item())\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","        intr_rews.append(cur_intr)\n","    print(overall_reward / num_episodes)\n","    return intr_rews"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"SBjnn7HWZTyF","executionInfo":{"status":"ok","timestamp":1616946914943,"user_tz":-60,"elapsed":1546,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"2c76b403-2e8a-45e8-eaf0-ea340dfe8979"},"source":["import matplotlib.pyplot as plt\n","\n","episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 4\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_{i}\")\n","episodes = get_intrinsic_reward(agent)\n","\n","eps = np.array([np.array(l) for l in episodes])\n","#eps = np.mean(eps, 0)\n","\n","plt.plot(eps[3])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["96.81999999999951\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzU5bn38c+VjQTIIGtk3xVQQXQEXOuCVq1LbeuGCoiAtuXY5Zxqq4+159j28dSetna1rG7g0qrVugKtPtoqS9g3BUEUEnYMCZB9ruePTDD1JBCYmcz2fb9eeZGZ+WXuaxz5cuf+/ea6zd0REZHUlxHvAkREpGUo8EVE0oQCX0QkTSjwRUTShAJfRCRNZMW7gMPp1KmT9+nTJ95liIgkjSVLlux2986NPZbQgd+nTx8KCwvjXYaISNIws4+bekxLOiIiaUKBLyKSJhT4IiJpQoEvIpImFPgiImkiosA3s2vNbI2ZhcwseJjjLjWzD8zsQzP7fiRjiojIsYl0hr8a+ArwdlMHmFkm8DvgMmAIcKOZDYlwXBEROUoRBb67r3P3D45w2AjgQ3ff5O5VwNPA1ZGMK6mnuKScpxd9gtp1i8ROS3zwqjuwpcHtrcDIpg42s8nAZIBevXrFtjJJCO9t3MOUOUvZc6CKswd0omeH1vEuSSQlHXGGb2bzzWx1I18xmaW7+1R3D7p7sHPnRj8dLCnC3Zn1z4+4ecZCyqtrAdhXXh3nqkRS1xFn+O4+OsIxioCeDW73CN8naayiupZ7XljF80uLuHhIAdcFezLp8UJKKxT4IrHSEks6i4GBZtaXuqC/ARjTAuNKgioqKeeOJ5awqmgf3xl9Av924QDWbisFoLS8Js7ViaSuSC/LvMbMtgJnAq+Y2Rvh+7uZ2asA7l4DTAHeANYBz7r7msjKlmS1YNMervrNP9i8+wDTxwb51uiBZGQY7fKyASjTDF8kZiKa4bv7C8ALjdxfDFze4ParwKuRjCXJzd159N3N/PiVdfTp2JqpY4P079z20OOB3LrAL63QDF8kVhK6PbKkhorqWu59YTXPLd3K6MEF/PL6YeSHA75e29y6/xVLddJWJGYU+BJTxSXl3PHkElZu3ce3Rw/kzgvrlnA+LzPDaNsqSydtRWJIgS8xs2DTHr45eymVNSGmjQ1y8ZCCwx4fyM2iTEs6IjGjwJeYeLZwC/c8v4peHVsz9ZYgA7q0PeLPBPKytaQjEkMKfIm6Zwu3cPdzKzlnQCd+d9Nph07IHkkgN1tLOiIxpPbIElXPLdl6KOynjQ02O+wB8nOzdB2+SAwp8CVq/rKsiP/48wrO6t+RaWOD5GZnHtXPB/I0wxeJJQW+RMVLK4r57rPLGdW3I9PHnnHUYQ86aSsSawp8idgrK7fxnWeWE+zTgRnjg+TlHH3YQ90Mv6yimlBILZJFYkGBLxF5ffU27nx6GcN7Hses8WfQOufYrwPIz80i5HCgSrN8kVhQ4Msxm7tmO1PmLGNYj3Y8OmEEbVpFdtGX2iuIxJYCX47J39bt4JtzlnJS97qwbxth2EPdkg6ogZpIrCjw5ai9+cFOvv7kUgZ3DfD4hBFHdenl4Rya4evSTJGYUODLUXl7/S5uf2IJAwva8sSEkYfaGkdDIE8N1ERiSYEvzfaPDbuZ9Hgh/Tu35cnbRtKudfTCHjjUQVPX4ovEhgJfmuW9jXuY+Phi+nZqw+yJI2nfJifqYwTCLZJ1Lb5IbCjw5YiWfvIptz22mJ7tWzN74kg6xCDsocEMX0s6IjGhwJfDWlO8j/EzF9ElvxWzJ46kY9tWMRsrJyuDvOxMLemIxEike9pea2ZrzCxkZsHDHLfZzFaZ2XIzK4xkTGk5G3ftZ+yMRbRplcWTE0fSJZAb8zHVQE0kdiK9eHo18BXgj8049gJ33x3heNJCtuw9yM3TF2IGsyeOpEf71i0yrhqoicROpJuYrwMw+99b1kny2llawc0zFnKgsoanJ59Jv85H3rwkWtRATSR2WmoN34G5ZrbEzCYf7kAzm2xmhWZWuGvXrhYqT+rtPVDFzTMWsquskkcnjGBIt0CLjq8ZvkjsHHGGb2bzgeMbeehed3+xmeOc4+5FZtYFmGdm77v7240d6O5TgakAwWBQbRNbUFlFNeNmLmLznoM8Ov4MTuvVvsVryM/NZvPuAy0+rkg6OGLgu/voSAdx96LwnzvN7AVgBNBo4Et8lFfVctujhazbVsofbzmdswZ0iksdgdwsNU8TiZGYL+mYWRszy6//HriEupO9kiAqa2q5/cklLP54L7+8/lQuGlwQt1rqe+K765c7kWiL9LLMa8xsK3Am8IqZvRG+v5uZvRo+rAD4h5mtABYBr7j765GMK9FTUxviW08t5+31u3jwK6dw5bBuca0nkJtNda1TUR2Kax0iqSjSq3ReAF5o5P5i4PLw95uAYZGMI7ERCjl3PbeS19ds574rhnD9Gb3iXdJnDdQqqo955ywRaZw+aZum3J0f/XUNzy8t4jujT+C2c/rGuyRA7RVEYinyXSskqbg7G3bu59F3NzNn4SdMOrcvd140IN5lHVLfQE0nbkWiT4GfBmpqQxR+/Cnz1u5g/rodfLznIADjzuzNPZcPTqgPztXveqVr8UWiT4GfovZX1vD2+l3MX7uDv3+wk5KD1eRkZnDWgI5MOrcfowcXcHy72PfGOVoBLemIxIwCP4Vs31fB/HU7mLd2B+9t3ENVbYjjWmdz4YldGD2kgPNO6ByVvWdjSUs6IrGT2H/7pVl2llUwZfYyFm3eC0CvDq255czeXDykgGDv9mRlJs+5eW1kLhI7CvwkV3KwilumL2LLpwf53hdP5OIhBQzs0jah1uWPRqusDHIyM9QiWSQGFPhJbH9lDeNmLeaj3QeYOf4MzhkYn3YI0WRmBPKydNJWJAYU+EmqorqWSY8VsrpoH3+46bSUCPt6+bnZOmkrEgPJs7grh1TXhpgyZynvbdrDz68dyiUnNdbMNHmpgZpIbCjwk0wo5PzHn1Ywf91OHrj6JK4Z3iPeJUVdfQM1EYkuBX4ScXfue3E1Ly4v5q5LT+SWM/vEu6SYCGhJRyQmFPhJwt158PX3mb3wE+74Qn++cX7itEOItrqTtlrSEYm2lAz8/ZWJFxbVtZG1+/39Wxv54//bxM2jenH3pSdGqarEpJO2IrGRcoFfUV3Ll379Dt95Zjk7SiviXQ7uzv99bR2D73udW2ct4oVlW4/6H6TH39vMQ298wJdP7cZ/XXVy0l5j31yB3Cwqa0JU1tTGuxSRlJKSl2VeMbQr097+iLlrtvNvFw1kwtl9ycmKz79t9TPzcwZ0Yv2O/XznmRW0ylrFRYO7cOXQblwwqAu52U33fX9+6VZ++OIaRg8u4KFrh5GRkdphDw0/bVtDq7bqiS8SLSkX+LnZmXzvi4O4LtiTB15ey4Ovvc+zi7dw35VDuODELi1ayxMLPuahNz7gmuHd+Z9r6/aAWbblU15aXswrq7bx6qrttG2VxSVDCrhyWDfOGdiJ7AZtEF5fvZ3v/XklZ/XvyG/HDP+Xx1JZwwZqndq2inM1IqkjosA3s4eAK4EqYCNwq7uXNHLcpcDDQCYw3d0fjGTc5ujdsQ3Tx53Bmx/s5IG/ruXWWYu5aFAX7rtiCH06tYn18Ly4vIgfvria0YO78LOvDT00Mz+9dwdO792B+64YwoJNe/nrimJeW72N55cVcVzrbC47uStXDetGVW2IO59axind2zFtbPCwvwWkmnw1UBOJCYtks2gzuwT4u7vXmNl/A7j73Z87JhNYD1wMbAUWAze6+9ojPX8wGPTCwsJjrq9eVU2Imf/8iN/8bQPVtc6k8/ryzQsG0DonNr/g/P39HUx+fAmn927PYxNGHDGsK2tqeWf9bl5aUcy8tTsor65bux50fD5PTx7Fca1zYlJnolq8eS/XPvIeT9w2gnMHdo53OSJJxcyWuHuwscci3dN2boObC4CvNXLYCODD8N62mNnTwNXAEQM/WnKyMrjjC/25Znh3/vu19/ndmxt5bkkR93xpMFcO7RrVk6CLPtrL159cyuCuAaaPa97MvFVWJqOHFDB6SAEHq2r427qdLPn4U75xQf+0C3touKSjGb5INEVzUXgC8Foj93cHtjS4vTV8X6PMbLKZFZpZ4a5du6JYHhQEcvnF9afy5zvOpGPbHO58ahnXT13A2uLSqDz/6qJ93PboYnq0z+OxCSMO7c96NFrnZHHlsG786KqT6JKfeBuUtISGG5mLSPQcMfDNbL6ZrW7k6+oGx9wL1ACzIy3I3ae6e9Ddg507x+bX+WCfDrw05Rx+es0pbNhRxhW/eYfvP7eSzbsPHPNzbty1n3EzFxHIy+bJiSPp0Cb9ZubRoo3MRWLjiEs67j76cI+b2XjgCuAib/yEQBHQs8HtHuH74iozwxgzsheXn3I8v5q/gTmLPuHZwi18aWg3vv6F/gzpFmj2cxWVlHPL9IWYwZMTR9K1XV4MK099bXIyyTDN8EWiLaIlnfDVN3cBV7n7wSYOWwwMNLO+ZpYD3AC8FMm40XRc6xx+dNVJ/OPuC5h0Xj/efH8nl//6HSY8upjC8A5Sh7N7fyW3TF9IWWUNj00YQd8WuAIo1dX1xM+mTFfpiERVpGv4vwXygXlmttzMHgEws25m9iqAu9cAU4A3gHXAs+6+JsJxo65Lfi4/uGww/7z7Qv794hNYvqWErz3yHtc98h5vfrCTxn55Ka2oZtzMRRTvK2fW+DM4qVu7OFSemtRATST6Ir1Kp9EOXu5eDFze4ParwKuRjNVS2rXO5t8uGsht5/blmcVbmPr2Jm6dtZghXQN844L+XHZyVzIzjIrqWiY+Wsj6HWVMGxsk2KdDvEtPKfnqiS8SdSn3SdtoaZ2Txa1n9+Wmkb35y/IiHvl/G5kyZxl9O63n9vP6MXftDhZ/vJdf3zCc81v4E7zpQDN8kehT4B9BTlYG1wV78tXTevDGmu38/q0P+f7zqwD46TWncOWwbnGuMDUF8rLYvLup00IiciwU+M2UmWFcfkpXLjv5eP7x4W4OVNZy6cmptbVgIgnkZusqHZEoU+AfJTPTx/1bQCBPSzoi0ZYe7Rcl6eTnZnGgqpaaCDeOEZHPKPAlIdX300nE3ctEkpUCXxJS/SYoaqAmEj0KfElIgVw1UBOJNgW+JCQ1UBOJPgW+JKTPWiRrSUckWhT4kpAObYKiJR2RqFHgS0L67KStAl8kWhT4kpDattKSjki0KfAlIWVmGPmtsjTDF4kiBb4kLG2CIhJdCnxJWHU98TXDF4kWBb4kLDVQE4muiLplmtlDwJVAFbARuNXdSxo5bjNQBtQCNe4ejGRcSQ+B3CyKSiriXYZIyoh0hj8PONndhwLrgR8c5tgL3P1Uhb00VyA3mzIt6YhETUSB7+5zw5uUAywAekRekkgdLemIRFc01/AnAK818ZgDc81siZlNPtyTmNlkMys0s8Jdu3ZFsTxJNoHcLMoqawiFPN6liLSYUMgpOVgVk+c+YuCb2XwzW93I19UNjrkXqAFmN/E057j7acBlwDfN7LymxnP3qe4edPdg587aWSqd5edm4w77q3RppqSH2pBz93Mr+eof3o3JXhBHPGnr7qMP97iZjQeuAC5y90anYu5eFP5zp5m9AIwA3j7qaiWt1DdQK6uoOdRbRyRV1dSG+Pc/reDF5cV8e/RA2uRkRn2MiJZ0zOxS4C7gKnc/2MQxbcwsv/574BJgdSTjSnoIqEWypImqmhBT5izjxeXF3HXpiXx79AmYWdTHiXQN/7dAPjDPzJab2SMAZtbNzF4NH1MA/MPMVgCLgFfc/fUIx5U0oAZqkg4qqmu548klvL5mO/ddMYRvnD8gZmNFdB2+uzdambsXA5eHv98EDItkHElP+blqoCaprbyqlslPFPLOht38+Msnc/Oo3jEdL6LAF4klLelIKttfWcNtjy5m0ea9/OxrQ7ku2DPmYyrwJWHVL+now1eSakorqhk/cxErtu7jV9efytWndm+RcRX4krC0pCOpqORgFWNnLmLdtlJ+e+NwLjula4uNrcCXhJWdmUFedqaWdCRl7NlfyU3TF7Jp1wEeufl0Lhpc0KLjK/AloQXy1CJZUsPO0grGTF/I1k8PMn1ckPNOaPkPlirwJaHVNVDTko4kt+KScsZMW8DOskoevXUEo/p1jEsdCnxJaIG8bM3wJalt2XuQG6ctYN/Bap64bQSn9+4Qt1oU+JLQArlZ7N4fm0ZSIrG2efcBbpy2gINVtcyeNJKhPY6Laz3a8UoSWn6uZviSnDbt2s/1U9+jorqWOQkQ9qAZviS4QF6W1vAl6Xy4cz83TltAKOQ8NXkUg44PxLskQIEvCS6QW7cJirvHpJmUSLSt31HGmGkLAOPpyaMYWJAf75IO0ZKOJLRAXjY1Iae8ujbepYgc0bptpdwwdQEZlnhhDwp8SXCHPm1brmUdSWxrivcxZtoCcjIzeHryKAZ0aRvvkv4XBb4ktPoGauqnI4ls1dZ9jJm2kLzsTJ65fRT9Oide2IMCXxLcoZ74CnxJUMu3lDBm+gLatsrimdvPpHfHNvEuqUk6aSsJLaAlHUlgSz/5lHEzFnFcm2yemjSKHu1bx7ukw1LgS0LLz9UMXxJT4ea9jJ+1mI5tc3hq0ii6HZcX75KOSEs6ktDqNzJXx0xJJAs37WHszEV0zm/FM5PPTIqwhygEvpk9YGYrw3vazjWzbk0cN87MNoS/xkU6rqSHQ7te6cNXkiDe3bib8bMW07VdLs9MHsXx7XLjXVKzRWOG/5C7D3X3U4GXgR9+/gAz6wDcD4wERgD3m1n7KIwtKS43O5OcrAwt6UhCmLtmO7fOWkyP9nk8PflMugSSJ+whCoHv7qUNbrYBvJHDvgjMc/e97v4pMA+4NNKxJT3UfdpWM3yJr6cXfcIdTy5hUNcAT08eRef8VvEu6ahF5aStmf0EGAvsAy5o5JDuwJYGt7eG72vsuSYDkwF69eoVjfIkyQVytQmKxI+787s3P+Tnc9dz3gmd+cNNp9GmVXJe79KsGb6ZzTez1Y18XQ3g7ve6e09gNjAlkoLcfaq7B9092Llzy+8II4knP0+boEh81IacH720hp/PXc81w7szY1wwacMemjnDd/fRzXy+2cCr1K3XN1QEnN/gdg/grWY+p6S5QG6WrtKRFldZU8t3n13BKyu3MencvvzgssFkZCR3A79oXKUzsMHNq4H3GznsDeASM2sfPll7Sfg+kSPSrlfS0soqqrl11mJeWbmNey4fxL1fGpL0YQ/RWcN/0MxOBELAx8AdAGYWBO5w94nuvtfMHgAWh3/mv9x9bxTGljRQN8PXko60jJ1lFdw6azEfbC/jF9cN4yun9Yh3SVETceC7+1ebuL8QmNjg9kxgZqTjSfqp28hcM3yJvY/3HOCWGYvYVVbJtHFBLjixS7xLiqrkPfsgaSOQl01lTYiK6lpyszPjXY6kqNVF+xg/axG1IWfOpJEM75V6HxVSawVJePUN1HSljsTKPz/czfV/fI9WWZn86Y6zUjLsQYEvSUAN1CSWXl5ZzPhZi+jRvjXPff2shNy4JFq0pCMJTw3UJFZeXF7Et59Zzhm9OzBtbJB2rbPjXVJMKfAl4X2265WWdCR65q7ZznefXcHIvh2YNX4EeTmpf35ISzqS8LTrlUTbOxt2MWXOMk7p3o7p485Ii7AHBb4kgUMtknUtvkTB4s17mfR4If06t+GxW0fQNolbJRwtBb4kvPz6bQ41w5cIrdq6jwmzFtPtuDyeuG1kyq/Zf54CXxJe65xMMjNMH76SiKzfUcbYmQtp1zqb2RNHJmV740gp8CXhmZnaK0hENu8+wE3TF5KdmcHsiSPp2i45tiSMtvRZvJKkpgZqcqyKSsq5afpCakPOM5NH0btjm3iXFDea4UtSyFeLZDkGO8squHn6QkrLq3l8wggGFuTHu6S40gxfkkJdAzUt6UjzlRysYuyMRWzfV8GTE0dwcvd28S4p7jTDl6QQyNWSjjRfWUU142YuYtPuA0wfF+T03h3iXVJCUOBLUgjk6aStNE95VS23PVbImuJSfj/mNM4e0CneJSUMLelIUsjXDF+aobKmltufXMLizXt5+IbhjB5SEO+SEopm+JIUArnZHKyqpaY2FO9SJEFV14aYMmcZb6/fxYNfOYWrhnWLd0kJJ6LAN7MHzGylmS03s7lm1uh/YTOrDR+z3MxeimRMSU/1HTN14lYaU1Mb4ttPL2fe2h3851Uncf0ZveJdUkKKdIb/kLsPdfdTgZeBHzZxXLm7nxr+uirCMSUNBdQTX5pQG3K+9+eVvLJqG/dePphxZ/WJd0kJK6LAd/fSBjfbAB5ZOSKNO9RPRydupYFQyLnn+VW8sKyI/7jkBCad1y/eJSW0iNfwzewnZrYFuImmZ/i5ZlZoZgvM7MtHeL7J4WMLd+3aFWl5kiLUIlk+z9354UureaZwC3deOIApFw6Md0kJ74iBb2bzzWx1I19XA7j7ve7eE5gNTGniaXq7exAYA/zKzPo3NZ67T3X3oLsHO3fufAwvSVLRZ5ugKPClLuwfeHkdTy74hNvP68d3Lj4h3iUlhSNelunuo5v5XLOBV4H7G3mOovCfm8zsLWA4sLH5ZUq6+2ybQy3ppDt352dvfMDMf37E+LP68P3LBmFm8S4rKUR6lU7D36GuBt5v5Jj2ZtYq/H0n4GxgbSTjSvrRko7Ue/hvG/jDWxsZM7IX9185RGF/FCL94NWDZnYiEAI+Bu4AMLMgcIe7TwQGA380sxB1/8A86O4KfDkqbXOyMNNG5unu9299yK/mb+Brp/fgx1efrLA/ShEFvrt/tYn7C4GJ4e/fBU6JZByRjAyjbassSnUdftqa/s4mfvb6B1w1rBv//dWhZGQo7I+WPmkrSUMN1NLXE+9t5sevrOOyk4/nF9cNI1Nhf0wU+JI0AnnZOmmbhp5Z/An3vbiG0YO78PANw8nKVGwdKzVPk6SRn5ulGX6aOFhVwzsbdjN3zQ6eX7aV807ozO9uOo2cLIV9JBT4kjQCudkUlZTHuwyJkV1llfxt3Q7mrd3BPz7cTWVNiEBuFtcHe3L/lSfRKisz3iUmPQW+JI1AXhbrtmmGnyrcnQ937mdeOOSXbynBHbofl8eNI3pxyZACzujbgWwt4USNAl+Shk7aJr/akFO4eS/zwyG/ec9BAIb2aMd3R5/A6CEFDDo+X5dbxogCX5JGIDeL/ZU1hEKuS/KSTE1tiBeXF/Obv29g856D5GRmcGb/jkw8tx+jBxdwfLvceJeYFhT4kjQCedm4w/6qmkO9dSSx1Yacv64o5td/28Cm3QcY0jXAr28czoWDutC2leKnpem/uCSNQz3xy6sV+AkuFHJeXrWNh+evZ+OuAww6Pp9Hbj6dS4YU6LezOFLgS9L4lwZq7eNcjDQqFHJeW72dh/+2nvU79nNCQVt+f9NpXHrS8Qr6BKDAl6ShXa8SVyjkzF27nV/N38D728sY0KUtv7lxOF86pauCPoEo8CVp5DdY0pHE4O7MW7uDX87fwLptpfTr3IaHbziVK4Z2U/uDBKTAl6Shjcxja+XWEu7680q27ato9s/Uhpz9lTX06diaX14/jKuGdVfQJzAFviQNLenEhrvz2Lub+cmr6+jcthVfPrXbUV0HP7RHO64a1k09bpKAAl+ShjYyj77Simru/vNKXlu9nQsHdeF/rh1G+zY58S5LYkSBL0kjKzOD1jmZmuFHyeqifXxj9lKKSsr5wWWDmHRuP51gTXEKfEkqgdxsbWQeIXfnyQUf88DL6+jYNodnJo8i2KdDvMuSFhC1RTcz+3cz8/C+tY09Ps7MNoS/xkVrXEkvgbwsLelEoKyimilPLeO+F9dw1oCOvHLnuQr7NBKVGb6Z9QQuAT5p4vEOwP1AEHBgiZm95O6fRmN8SR9qoHbsVhft45tzlrL103LuvnQQt5+nJZx0E60Z/i+Bu6gL88Z8EZjn7nvDIT8PuDRKY0sa0SYoR69+Cecrf3iXyuoQT08exdfP76+wT0MRz/DN7GqgyN1XHOZSru7Alga3t4bva+z5JgOTAXr16hVpeZJiAnnZbNp9IN5lJI39lTX84PlV/HVFMeed0JlfXjeMjm1bxbssiZNmBb6ZzQeOb+She4F7qFvOiQp3nwpMBQgGg039xiBpKpCbnbaftF36yaf8/I0PqKiubfbPFJdUsLOsgu998US+/gXN6tNdswLf3Uc3dr+ZnQL0Bepn9z2ApWY2wt23Nzi0CDi/we0ewFvHUK+kuUBeFqUVNbh7Wm2SsWJLCeNmLKJNqywGFrRt9s+d1C3Aw+edysh+HWNYnSSLiJZ03H0V0KX+tpltBoLuvvtzh74B/NTM6nscXgL8IJKxJT3l52ZTG3IOVtXSJk36qa8u2sctMxbSvk0Oz9w+iq7t8uJdkiSpmH0W2syCZjYdwN33Ag8Ai8Nf/xW+T+SopFt7hfe3l3LLjIXk52YzZ9JIhb1EJKpTJHfv0+D7QmBig9szgZnRHE/ST8MGal3bxbmYGPtwZxk3TVtIq6xM5kwaSY/2reNdkiQ5dTuSpBJIkxbJH+0+wJhpC8nIMGZPGknvjm3iXZKkAAW+JJVAXuov6WzZe5Ax0xZQG3LmTBxJ/87NP0krcjjpcdZLUkaqd8wsKinnhqkLKK+u5alJoxhYkB/vkiSFaIYvSaV+SScVG6ht31fBmGkLKK2o5snbRjK4ayDeJUmKUeBLUjk0w0+xXa92ltWF/Z79VTw+YQQnd0/xM9ISFwp8SSq52Zm0yspIqZO2e/ZXctO0hWwvreDRW89geK/2R/4hkWOgwJekk59CHTNLDlZx84xFbPn0IDPGnaFWxRJTOmkrSae+vUKiKTlYxaqifc0+3h0eeuMDNu7az4xxQc7sr/YHElsKfEk6idhA7ZM9B7lh6nsU76s4qp/LzjSm3hLk3IGdY1SZyGcU+JJ0AnnZ7EugwN+y9yA3TlvAwepapo8Nclzr7Gb/7PHtcvUJWmkxCnxJOvm5WWzdezDeZQB1YX/D1AXsr6xhzqSRnNRNV9dI4tJJW0k6ddscxn8Nf+unddoK0scAAAcNSURBVDP7sopqZk9U2EviU+BL0qk7aRvfJZ2iknJunLaA0vJqZk8cpevmJSko8CXpBHKzqaoJHdXOT9FUXFLOjVMXUHKwmiduG8kpPRT2khwU+JJ04tlAbfu+Cm6ctoBPD9R9InZYz+NavAaRY6XAl6QTiFMDtfqw37O/isduG6FPxErSUeBL0olHA7UdpXW9bnaWVvDYhDM4TWEvSUiXZUrSqd/1qqWu1NlZWjez315aweMTRnB6b7U/kOQUlRm+mf27mbmZdWri8VozWx7+eikaY0r6asldr3aWhcN+XwWP3jpCvW4kqUU8wzeznsAlwCeHOazc3U+NdCwRqGueBrE/aburrJIx0xZSXFLXxXJEX4W9JLdoLOn8ErgLeDEKzyVyRA03Mm+ujbv2M27mIopLypv9MyGH3OwMZo0fwch+amwmyS+iwDezq4Eid19hZoc7NNfMCoEa4EF3/8thnnMyMBmgV69ekZQnKSovO5OsDGv2kk5xSTm3TF9IVW2Ib5w/gMP/r/qvLh5SwNAeuvRSUsMRA9/M5gPHN/LQvcA91C3nHElvdy8ys37A381slbtvbOxAd58KTAUIBoPejOeWNGNmBPKa1xN/74EqbpmxkLKKGp6+fZTaH0haO2Lgu/voxu43s1OAvkD97L4HsNTMRrj79s89R1H4z01m9hYwHGg08EWaIz8364jX4e+vrGH8rEVs/bScJ25TrxuRY75Kx91XuXsXd+/j7n2ArcBpnw97M2tvZq3C33cCzgbWRlCzCIHc7MNeh19RXcukxwpZW1zKH24+TSdcRYjRB6/MLGhm08M3BwOFZrYCeJO6NXwFvkTkcLte1dSGuPOpZby3aQ8/v3YYFw4qaOHqRBJT1D54FZ7l139fCEwMf/8ucEq0xhGBuhn+ztL9/+t+d+cHz69i7tod/OdVJ/Hl4d3jUJ1IYlJrBUlKgUY2Mnd3fvrqOv60ZCvfHj2QcWf1iU9xIglKgS9JqbGTtr9/ayPT3vmIcWf25lsXDYxTZSKJS4EvSSmQl015dS3VtSEAZi/8mIfe+IAvn9qN+688iSN8LkQkLal5miSl+hbJZRU1vLtxN//nL6u5cFAXHrp2GBkZCnuRxijwJSnVb4Ly8spiHnh5LcHe7fndmNPIztQvrSJN0d8OSUr1DdR++OIaBnTJZ/q4M8jLyYxzVSKJTYEvSal+SadPx9Y8PmEE7cIzfhFpmpZ0JCkN7XEct57dhwln96Vzfqt4lyOSFBT4kpTycjK5/8qT4l2GSFLRko6ISJpQ4IuIpAkFvohImlDgi4ikCQW+iEiaUOCLiKQJBb6ISJpQ4IuIpAlz93jX0CQz2wV8fIw/3gnYHcVykoFec+pLt9cLes1Hq7e7d27sgYQO/EiYWaG7B+NdR0vSa0596fZ6Qa85mrSkIyKSJhT4IiJpIpUDf2q8C4gDvebUl26vF/SaoyZl1/BFRORfpfIMX0REGlDgi4ikiZQLfDO71Mw+MLMPzez78a6nJZjZZjNbZWbLzaww3vXEgpnNNLOdZra6wX0dzGyemW0I/9k+njVGWxOv+UdmVhR+r5eb2eXxrDHazKynmb1pZmvNbI2ZfSt8f8q+14d5zVF/r1NqDd/MMoH1wMXAVmAxcKO7r41rYTFmZpuBoLun7IdTzOw8YD/wuLufHL7vZ8Bed38w/I97e3e/O551RlMTr/lHwH53/3k8a4sVM+sKdHX3pWaWDywBvgyMJ0Xf68O85uuI8nudajP8EcCH7r7J3auAp4Gr41yTRIG7vw3s/dzdVwOPhb9/jLq/JCmjidec0tx9m7svDX9fBqwDupPC7/VhXnPUpVrgdwe2NLi9lRj9h0swDsw1syVmNjnexbSgAnffFv5+O1AQz2Ja0BQzWxle8kmZpY3PM7M+wHBgIWnyXn/uNUOU3+tUC/x0dY67nwZcBnwzvBSQVrxubTJ11ieb9gegP3AqsA34n/iWExtm1hZ4Dvi2u5c2fCxV3+tGXnPU3+tUC/wioGeD2z3C96U0dy8K/7kTeIG6pa10sCO8/lm/DrozzvXEnLvvcPdadw8B00jB99rMsqkLvtnu/nz47pR+rxt7zbF4r1Mt8BcDA82sr5nlADcAL8W5ppgyszbhEz2YWRvgEmD14X8qZbwEjAt/Pw54MY61tIj60Au7hhR7r83MgBnAOnf/RYOHUva9buo1x+K9TqmrdADCly79CsgEZrr7T+JcUkyZWT/qZvUAWcCcVHzNZvYUcD51bWN3APcDfwGeBXpR10b7OndPmZOcTbzm86n7Fd+BzcDtDda2k56ZnQO8A6wCQuG776FuTTsl3+vDvOYbifJ7nXKBLyIijUu1JR0REWmCAl9EJE0o8EVE0oQCX0QkTSjwRUTShAJfRCRNKPBFRNLE/wewGeS1Si395AAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"cpUcYkH1afDr","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1616946941434,"user_tz":-60,"elapsed":748,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"f596bbb6-50e4-453c-ffee-00126dd2fe38"},"source":["plt.plot(eps[9])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"5uHGvitbixrv"},"source":[""],"execution_count":null,"outputs":[]}]}