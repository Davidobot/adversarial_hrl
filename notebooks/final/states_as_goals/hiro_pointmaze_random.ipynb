{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"hiro_pointmaze_random.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-Y3vLeDo4pG","executionInfo":{"status":"ok","timestamp":1618933832351,"user_tz":-60,"elapsed":54032,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"a67a6513-0320-4826-b345-4518ae73b657"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!cp \"/content/drive/My Drive/Dissertation/envs/point_maze.py\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eaaz1IRfpF1l","executionInfo":{"status":"ok","timestamp":1618933843151,"user_tz":-60,"elapsed":693,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# for inference, not continued training\n","def save_model(model, name):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_maze_random/{name}\" \n","\n","    torch.save({\n","      'meta_controller': {\n","          'critic': model.meta_controller.critic.state_dict(),\n","          'actor': model.meta_controller.actor.state_dict(),\n","      },\n","      'controller': {\n","          'critic': model.controller.critic.state_dict(),\n","          'actor': model.controller.actor.state_dict(),\n","      }\n","    }, path)\n","\n","import copy\n","def load_model(model, name, dir=\"point_maze_random\"):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{dir}/{name}\" \n","    checkpoint = torch.load(path)\n","\n","    model.meta_controller.critic.load_state_dict(checkpoint['meta_controller']['critic'])\n","    model.meta_controller.critic_target = copy.deepcopy(model.meta_controller.critic)\n","    model.meta_controller.actor.load_state_dict(checkpoint['meta_controller']['actor'])\n","    model.meta_controller.actor_target = copy.deepcopy(model.meta_controller.actor)\n","\n","    model.controller.critic.load_state_dict(checkpoint['controller']['critic'])\n","    model.controller.critic_target = copy.deepcopy(model.controller.critic)\n","    model.controller.actor.load_state_dict(checkpoint['controller']['actor'])\n","    model.controller.actor_target = copy.deepcopy(model.controller.actor)\n","\n","    # model.eval() for evaluation instead\n","    model.eval()\n","    model.meta_controller.eval()\n","    model.controller.eval()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1618933848616,"user_tz":-60,"elapsed":5163,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1618933848619,"user_tz":-60,"elapsed":4562,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1618933848621,"user_tz":-60,"elapsed":4071,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["from point_maze import PointMazeEnv \n","env = NormalizedEnv(PointMazeEnv(4))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"DQtcj2j8Erv4","executionInfo":{"status":"ok","timestamp":1618933848623,"user_tz":-60,"elapsed":3173,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def plot_durations(episode_durations, goals_done):\n","    fig, axs = plt.subplots(2, figsize=(10,10))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","\n","    durations_t, durations = list(map(list, zip(*goals_done)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[1].set_xlabel('Episode')\n","    axs[1].set_ylabel('Goals done')\n","    \n","    axs[1].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1618933848626,"user_tz":-60,"elapsed":2845,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1618933848630,"user_tz":-60,"elapsed":2447,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1618933848632,"user_tz":-60,"elapsed":2104,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","  \n","# (state, action) -> (next_state, reward, done)\n","transition_meta = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done', 'state_seq', 'action_seq'))\n","\n","# replay memory D with capacity N\n","class ReplayMemoryMeta(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition_meta(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1618933848634,"user_tz":-60,"elapsed":1389,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["DEPTH = 128\n","\n","class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, DEPTH)\n","        self.fc2 = nn.Linear(DEPTH, DEPTH)\n","        self.head = nn.Linear(DEPTH, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l2 = nn.Linear(DEPTH, DEPTH)\n","        self.l3 = nn.Linear(DEPTH, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l5 = nn.Linear(DEPTH, DEPTH)\n","        self.l6 = nn.Linear(DEPTH, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1618933848636,"user_tz":-60,"elapsed":928,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions, is_meta=False):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        self.is_meta = is_meta\n","\n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000) if not self.is_meta else ReplayMemoryMeta(100000)\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 50000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self, off_policy_correction=None):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","\n","        if not self.is_meta:\n","            batch = transition(*zip(*transitions))\n","            action_batch = torch.cat(batch.action)\n","        else:\n","            batch = transition_meta(*zip(*transitions))\n","\n","            action_batch = torch.cat(batch.action)\n","            state_seq_batch = torch.stack(batch.state_seq)\n","            action_seq_batch = torch.stack(batch.action_seq)\n","\n","            action_batch = off_policy_correction(action_batch.cpu().numpy(), state_seq_batch.cpu().numpy(), action_seq_batch.cpu().numpy())\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            \n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, self.tau / 5)\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup, decay_epsilon):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,1)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u23kJqHhvw8","executionInfo":{"status":"ok","timestamp":1618933849751,"user_tz":-60,"elapsed":1301,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class HIRO(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(HIRO, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        self.goal_dim = [0, 1]\n","        self.goal_dimen = 2\n","      \n","        self.meta_controller = TD3(nb_states, len(self.goal_dim), True).to(device)\n","        self.max_goal_dist = torch.from_numpy(np.array([2.5, 2.5])).to(device)\n","        self.goal_offset = torch.from_numpy(np.array([1., 1.])).to(device)\n","\n","        self.controller = TD3(nb_states + len(self.goal_dim), nb_actions).to(device)\n","        #self.controller.depsilon = 1.0 / 500000\n","\n","    def teach_controller(self):\n","        self.controller.update_policy()\n","    def teach_meta_controller(self):\n","        self.meta_controller.update_policy(self.off_policy_corrections)\n","\n","    def h(self, state, goal, next_state):\n","        #return goal\n","        return state[:,self.goal_dim] + goal - next_state[:,self.goal_dim]\n","    #def intrinsic_reward(self, action, goal):\n","    #    return torch.tensor(1.0 if self.goal_reached(action, goal) else 0.0, device=device) \n","    #def goal_reached(self, action, goal, threshold = 0.1):\n","    #    return torch.abs(action - goal) <= threshold\n","    def intrinsic_reward(self, reward, state, goal, next_state):\n","        #return torch.tensor(2 * reward if self.goal_reached(state, goal, next_state) else reward / 10, device=device) #reward / 2\n","        # just L2 norm\n","        return -torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5)\n","    def goal_reached(self, state, goal, next_state, threshold = 0.1):\n","        return torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5) <= threshold\n","        #return torch.pow(sum(goal.squeeze(0), 2), 0.5) <= threshold\n","\n","    # correct goals to allow for use in experience replay\n","    def off_policy_corrections(self, sgoals, states, actions, candidate_goals=8):\n","        first_s = [s[0] for s in states] # First x\n","        last_s = [s[-1] for s in states] # Last x\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # diff = 1\n","        diff_goal = (np.array(last_s) - np.array(first_s))[:, np.newaxis, :self.goal_dimen]\n","\n","        # Shape: (batch_size, 1, subgoal_dim)\n","        # original = 1\n","        # random = candidate_goals\n","        scale = self.max_goal_dist.cpu().numpy()\n","        original_goal = np.array(sgoals)[:, np.newaxis, :]\n","        random_goals = np.random.normal(loc=diff_goal, scale=.5*scale,\n","                                        size=(BATCH_SIZE, candidate_goals, original_goal.shape[-1]))\n","        random_goals = random_goals.clip(-scale, scale)\n","\n","        # Shape: (batch_size, 10, subgoal_dim)\n","        candidates = np.concatenate([original_goal, diff_goal, random_goals], axis=1)\n","        #states = np.array(states)[:, :-1, :]\n","        actions = np.array(actions)\n","        seq_len = len(states[0])\n","\n","        # For ease\n","        new_batch_sz = seq_len * BATCH_SIZE\n","        action_dim = actions[0][0].shape\n","        obs_dim = states[0][0].shape\n","        ncands = candidates.shape[1]\n","\n","        true_actions = actions.reshape((new_batch_sz,) + action_dim)\n","        observations = states.reshape((new_batch_sz,) + obs_dim)\n","        goal_shape = (new_batch_sz, self.goal_dimen)\n","        # observations = get_obs_tensor(observations, sg_corrections=True)\n","\n","        # batched_candidates = np.tile(candidates, [seq_len, 1, 1])\n","        # batched_candidates = batched_candidates.transpose(1, 0, 2)\n","\n","        policy_actions = np.zeros((ncands, new_batch_sz) + action_dim)\n","\n","        observations = torch.from_numpy(observations).to(device)\n","        for c in range(ncands):\n","            subgoal = candidates[:,c]\n","            candidate = (subgoal + states[:, 0, :self.goal_dimen])[:, None] - states[:, :, :self.goal_dimen]\n","            candidate = candidate.reshape(*goal_shape)\n","            policy_actions[c] = self.controller.actor(torch.cat([observations, torch.from_numpy(candidate).to(device)], 1).float()).detach().cpu().numpy()\n","\n","        difference = (policy_actions - true_actions)\n","        difference = np.where(difference != -np.inf, difference, 0)\n","        difference = difference.reshape((ncands, BATCH_SIZE, seq_len) + action_dim).transpose(1, 0, 2, 3)\n","\n","        logprob = -0.5*np.sum(np.linalg.norm(difference, axis=-1)**2, axis=-1)\n","        max_indices = np.argmax(logprob, axis=-1)\n","\n","        return torch.from_numpy(candidates[np.arange(BATCH_SIZE), max_indices]).to(device).float()\n","\n","    def observe_controller(self, s_t, a_t, s_t1, r_t, done):\n","        self.controller.memory.store(s_t, a_t, s_t1, r_t, done)\n","    def observe_meta_controller(self, s_t, a_t, s_t1, r_t, done, state_seq, action_seq):\n","        self.meta_controller.memory.store(s_t, a_t, s_t1, r_t, done, state_seq, action_seq)\n","\n","    def select_goal(self, s_t, warmup, decay_epsilon):\n","        return self.meta_controller.select_action(s_t, warmup, decay_epsilon) * self.max_goal_dist + self.goal_offset\n","    def select_action(self, s_t, g_t, warmup, decay_epsilon):\n","        sg_t = torch.cat([s_t, g_t], 1).float()\n","        return self.controller.select_action(sg_t, warmup, decay_epsilon)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI"},"source":["import time\n","SAVE_OFFSET = 6\n","def train_model():\n","    global SAVE_OFFSET\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = HIRO(n_observations, n_actions).to(device)\n","    \n","    max_episode_length = 500\n","    observation = None\n","    \n","    warmup = 100\n","    num_episodes = 6000 # M\n","    episode_durations = []\n","    goal_durations = []\n","\n","    steps = 0\n","    c = 10\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        overall_intrinsic = 0\n","        episode_steps = 0\n","        done = False\n","        goals_done = 0\n","\n","        while not done:\n","            # random goal\n","            goal = agent.select_goal(state, True, False)\n","            #goal_durations.append((steps, goal[:,0]))\n","\n","            state_seq, action_seq = None, None\n","            first_goal = goal\n","            goal_done = False\n","            total_extrinsic = 0\n","\n","            while not done and not goal_done:\n","                joint_goal_state = torch.cat([state, goal], axis=1).float()\n","\n","                # agent pick action ...\n","                action = agent.select_action(state, goal, i_episode <= warmup, True)\n","                \n","                # env response with next_observation, reward, terminate_info\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                steps += 1\n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                next_goal = agent.h(state, goal, next_state)\n","                joint_next_state = torch.cat([next_state, next_goal], axis=1).float()\n","                \n","                if max_episode_length and episode_steps >= max_episode_length -1:\n","                    done = True\n","                    \n","                extrinsic_reward = torch.tensor([reward], device=device)\n","                intrinsic_reward = agent.intrinsic_reward(reward, state, goal, next_state).unsqueeze(0)\n","                #intrinsic_reward = agent.intrinsic_reward(action, goal).unsqueeze(0)\n","\n","                overall_reward += reward\n","                total_extrinsic += reward\n","                overall_intrinsic += intrinsic_reward\n","\n","                goal_reached = agent.goal_reached(state, goal, next_state)\n","                #goal_done = agent.goal_reached(action, goal)\n","\n","                # agent observe and update policy\n","                agent.observe_controller(joint_goal_state, action, joint_next_state, intrinsic_reward, done) #goal_done.item())\n","\n","                if state_seq is None:\n","                    state_seq = state\n","                else:\n","                    state_seq = torch.cat([state_seq, state])\n","                if action_seq is None:\n","                    action_seq = action\n","                else:\n","                    action_seq = torch.cat([action_seq, action])\n","\n","                episode_steps += 1\n","\n","                if goal_reached:\n","                    goals_done += 1\n","                \n","                if (episode_steps % c) == 0:\n","                    agent.observe_meta_controller(state_seq[0].unsqueeze(0), goal, next_state, torch.tensor([total_extrinsic], device=device), done,\\\n","                                                  state_seq, action_seq)\n","                    goal_done = True\n","\n","                    #if i_episode > warmup:\n","                    #    agent.teach_meta_controller()\n","\n","                state = next_state\n","                goal = next_goal\n","                \n","                if i_episode > warmup:\n","                    agent.teach_controller()\n","\n","        goal_durations.append((i_episode, overall_intrinsic / episode_steps))\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations, goal_durations)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0:\n","                print(f\"{i_episode}: {np.mean(dur[-100:])}\")\n","            if i_episode >= 300 and i_episode % 100 == 0 and np.mean(dur[-100:]) <= -49.0:\n","                print(f\"Unlucky after {i_episode} eps! Terminating...\")\n","                return None\n","            if np.mean(dur[-100:]) >= 90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"hiro_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","\n","    return None # did not train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj1smUjnRiSJ"},"source":["def plot_fgsm(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    for kk in ['both', 'goal_only', 'action_only']:\n","        x, ys = np.array(list(episode_durations[kk].keys())), np.array(list(episode_durations[kk].values()))\n","        #plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","        plt.xlabel('$\\epsilon$')\n","        plt.ylabel('Average Reward')\n","        \n","        mu = np.mean(ys, axis=1)\n","        plt.plot(x, mu, label=kk)\n","        stds = np.std(ys, axis = 1)\n","        plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\n","    \n","    plt.legend()\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5kgVRwJErwO"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def eval_model(agent, episode_durations, goal_attack, action_attack, same_noise):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for l2norm in np.arange(0.0,0.51,0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","            if goal_attack:\n","                g_state = g_state + state_range * noise\n","                g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","            if action_attack:\n","                if same_noise:\n","                    state = state + state_range * noise\n","                else:\n","                    state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    if goal_attack:\n","                        g_next_state = g_next_state + state_range * noise\n","                        g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                    if action_attack:\n","                        if same_noise:\n","                            next_state = next_state + state_range * noise\n","                        else:\n","                            next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                        next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(l2norm, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-GH33rpv6-Z","executionInfo":{"status":"ok","timestamp":1618933875731,"user_tz":-60,"elapsed":6794,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def fgsm_attack(data, eps, data_grad):\n","    sign_data_grad = data_grad.sign()\n","\n","    perturbed_data = data - eps * sign_data_grad * state_range\n","\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\n","\n","    return clipped_perturbed_data\n","\n","def fgsm_action(state, goal, agent, eps, target, targeted):\n","    #state = torch.tensor(state, requires_grad=True)\n","    state = state.clone().detach().requires_grad_(True)\n","    goal = goal.clone().detach()\n","\n","    sg_t = torch.cat([state, goal], 1).float()\n","\n","    if targeted:\n","        # initial forward pass\n","        action = agent.controller.actor(sg_t)\n","        action = torch.clamp(action, -1., 1.)\n","\n","        loss = F.mse_loss(action, target)\n","    else:\n","        loss = agent.controller.critic.Q1(sg_t, agent.controller.actor(sg_t)).mean()\n","\n","    agent.controller.actor.zero_grad()\n","\n","    # calc loss\n","    loss.backward()\n","    data_grad = state.grad.data\n","    # perturb state\n","    state_p = fgsm_attack(state, eps, data_grad).float()\n","    return state_p\n","\n","def apply_fgsm(agent, episode_durations, targeted):\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0]], device=device, dtype=torch.float)\n","\n","    agent.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for eps in np.arange(0.0, 0.201, 0.02):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            goal = agent.select_goal(og_state, True, False)\n","            state = fgsm_action(og_state, goal, agent, eps, TARGET_ACTION, targeted)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                goal = agent.select_goal(state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    \n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","\n","                    next_og_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    goal_temp = agent.h(state, goal, next_og_state)\n","                    next_state = fgsm_action(next_og_state, goal_temp, agent, eps, TARGET_ACTION, targeted)\n","\n","                    next_goal = agent.h(state, goal, next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(state, goal, next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    goal = next_goal\n","\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrR0kvDhFwRa","executionInfo":{"status":"ok","timestamp":1616784355030,"user_tz":0,"elapsed":18912780,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"20c84bdf-6d56-4b7d-979a-607b02d2a11f"},"source":["noise_hrl = {'both': {}, 'action_only': {}, 'goal_only': {}, 'both_same': {}}\n","for l2norm in np.arange(0,0.51,0.05):\n","    for i in [noise_hrl['both'], noise_hrl['action_only'], noise_hrl['goal_only'], noise_hrl['both_same']]:\n","        i[np.round(l2norm, 2)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    agent = train_model()\n","    #agent = HIRO(n_observations, n_actions).to(device)\n","    #load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_model(agent, noise_hrl['both_same'], True, True, True)\n","        eval_model(agent, noise_hrl['both'], True, True, False)\n","        eval_model(agent, noise_hrl['action_only'], False, True, False)\n","        eval_model(agent, noise_hrl['goal_only'], True, False, False)\n","        print(f\"{i} noise_hrl: {noise_hrl}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"noise_hrl: {noise_hrl}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100: -48.97400000000043\n","200: -29.172000000000402\n","300: -32.65000000000041\n","400: -24.469000000000406\n","500: 14.698999999999712\n","600: 19.41299999999973\n","700: 42.19799999999982\n","800: 77.53099999999996\n","900: 77.72499999999995\n","1000: 77.30199999999996\n","1100: 78.04999999999997\n","1200: 75.72999999999995\n","1300: 78.44199999999996\n","1400: 78.61599999999997\n","1500: 85.02799999999996\n","1600: 79.61999999999995\n","1700: 87.46299999999995\n","1800: 84.975\n","1900: 83.54699999999997\n","2000: 83.97799999999998\n","2100: 84.38299999999998\n","2200: 79.52599999999998\n","2300: 87.49699999999999\n","Solved after 2340 episodes!\n","0 noise_hrl: {'both': {0.0: [90.47199999998625], 0.05: [89.4869999999837], 0.1: [91.21499999998642], 0.15: [90.95299999998502], 0.2: [90.99899999998628], 0.25: [89.98899999998606], 0.3: [82.89599999998005], 0.35: [75.16299999997683], 0.4: [44.124000000006575], 0.45: [29.3830000000148], 0.5: [25.872000000013436]}, 'action_only': {0.0: [90.51499999998822], 0.05: [90.77499999998848], 0.1: [90.9429999999895], 0.15: [91.82999999998647], 0.2: [91.71499999998522], 0.25: [88.26899999998155], 0.3: [82.96999999998104], 0.35: [68.25199999996538], 0.4: [62.2339999999845], 0.45: [45.82000000000585], 0.5: [36.61600000002265]}, 'goal_only': {0.0: [91.56999999998793], 0.05: [88.6179999999853], 0.1: [93.3009999999867], 0.15: [94.09199999998887], 0.2: [94.46599999998952], 0.25: [91.11899999999254], 0.3: [93.6839999999902], 0.35: [93.13399999999162], 0.4: [93.97399999998945], 0.45: [91.99299999998995], 0.5: [87.8099999999837]}, 'both_same': {0.0: [88.91499999998477], 0.05: [92.30599999998712], 0.1: [90.56499999998519], 0.15: [92.28099999998632], 0.2: [90.71899999998492], 0.25: [86.94399999998424], 0.3: [88.8129999999836], 0.35: [79.35699999997657], 0.4: [65.82799999996949], 0.45: [44.69400000000934], 0.5: [39.77100000001431]}}\n","100: -46.39800000000042\n","200: -31.0930000000004\n","300: -38.21300000000043\n","400: -6.989000000000356\n","500: 27.368999999999737\n","600: 47.897999999999826\n","700: 43.49699999999982\n","800: 69.07799999999992\n","900: 75.06899999999995\n","1000: 75.85699999999997\n","1100: 81.12199999999996\n","1200: 81.12799999999997\n","1300: 76.13399999999993\n","1400: 75.04499999999994\n","1500: 78.36299999999997\n","1600: 81.58199999999997\n","1700: 86.81100000000002\n","1800: 88.801\n","Solved after 1897 episodes!\n","1 noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513], 0.05: [89.4869999999837, 93.24799999998795], 0.1: [91.21499999998642, 90.90899999998567], 0.15: [90.95299999998502, 91.00299999998501], 0.2: [90.99899999998628, 89.4699999999805], 0.25: [89.98899999998606, 87.52999999997974], 0.3: [82.89599999998005, 80.61799999997865], 0.35: [75.16299999997683, 70.34799999996771], 0.4: [44.124000000006575, 52.609999999990976], 0.45: [29.3830000000148, 43.51200000000169], 0.5: [25.872000000013436, 21.916000000019608]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534], 0.05: [90.77499999998848, 91.60199999999006], 0.1: [90.9429999999895, 87.92299999998235], 0.15: [91.82999999998647, 90.69699999998711], 0.2: [91.71499999998522, 90.10099999998583], 0.25: [88.26899999998155, 87.14999999998047], 0.3: [82.96999999998104, 83.39299999997124], 0.35: [68.25199999996538, 78.22699999996979], 0.4: [62.2339999999845, 67.57499999996911], 0.45: [45.82000000000585, 57.59299999998575], 0.5: [36.61600000002265, 47.38000000000224]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261], 0.05: [88.6179999999853, 89.00999999998929], 0.1: [93.3009999999867, 92.01499999998596], 0.15: [94.09199999998887, 93.32899999998827], 0.2: [94.46599999998952, 92.8919999999885], 0.25: [91.11899999999254, 92.63499999998864], 0.3: [93.6839999999902, 92.57199999998892], 0.35: [93.13399999999162, 92.94899999998694], 0.4: [93.97399999998945, 92.13899999998692], 0.45: [91.99299999998995, 92.84199999998815], 0.5: [87.8099999999837, 92.43599999998794]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335], 0.05: [92.30599999998712, 90.49499999998585], 0.1: [90.56499999998519, 91.62299999998415], 0.15: [92.28099999998632, 90.62499999998441], 0.2: [90.71899999998492, 89.12899999998388], 0.25: [86.94399999998424, 86.38199999997914], 0.3: [88.8129999999836, 78.29699999997993], 0.35: [79.35699999997657, 60.54799999997876], 0.4: [65.82799999996949, 53.1749999999922], 0.45: [44.69400000000934, 32.6630000000202], 0.5: [39.77100000001431, 25.242000000020642]}}\n","100: -46.72900000000041\n","200: -38.13500000000042\n","300: -38.97800000000043\n","400: -42.95200000000042\n","500: 4.922999999999673\n","600: 29.144999999999758\n","700: 41.4989999999998\n","800: 53.381999999999834\n","900: 57.69999999999985\n","1000: 42.6709999999998\n","1100: 69.99499999999992\n","1200: 77.29799999999994\n","1300: 77.58699999999995\n","1400: 87.90699999999998\n","1500: 87.073\n","1600: 84.85799999999999\n","1700: 83.58499999999998\n","1800: 57.183999999999884\n","1900: 51.67899999999988\n","2000: 83.87499999999999\n","Solved after 2044 episodes!\n","2 noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513, 90.7309999999889], 0.05: [89.4869999999837, 93.24799999998795, 92.62899999998746], 0.1: [91.21499999998642, 90.90899999998567, 92.61499999998635], 0.15: [90.95299999998502, 91.00299999998501, 91.70299999998804], 0.2: [90.99899999998628, 89.4699999999805, 89.41899999998193], 0.25: [89.98899999998606, 87.52999999997974, 80.66399999997658], 0.3: [82.89599999998005, 80.61799999997865, 72.70199999998047], 0.35: [75.16299999997683, 70.34799999996771, 50.234999999996546], 0.4: [44.124000000006575, 52.609999999990976, 29.5280000000186], 0.45: [29.3830000000148, 43.51200000000169, 14.281000000008012], 0.5: [25.872000000013436, 21.916000000019608, -1.44399999999866]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534, 90.90699999998705], 0.05: [90.77499999998848, 91.60199999999006, 91.46199999998693], 0.1: [90.9429999999895, 87.92299999998235, 92.52399999998852], 0.15: [91.82999999998647, 90.69699999998711, 91.3109999999872], 0.2: [91.71499999998522, 90.10099999998583, 90.11499999998324], 0.25: [88.26899999998155, 87.14999999998047, 87.78299999998026], 0.3: [82.96999999998104, 83.39299999997124, 76.377999999976], 0.35: [68.25199999996538, 78.22699999996979, 63.57299999997339], 0.4: [62.2339999999845, 67.57499999996911, 31.85800000002177], 0.45: [45.82000000000585, 57.59299999998575, 35.0630000000193], 0.5: [36.61600000002265, 47.38000000000224, -2.8670000000036793]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261, 88.32499999998407], 0.05: [88.6179999999853, 89.00999999998929, 86.94099999998474], 0.1: [93.3009999999867, 92.01499999998596, 92.03599999998617], 0.15: [94.09199999998887, 93.32899999998827, 90.72399999998566], 0.2: [94.46599999998952, 92.8919999999885, 93.4199999999868], 0.25: [91.11899999999254, 92.63499999998864, 92.71799999998794], 0.3: [93.6839999999902, 92.57199999998892, 92.75399999998722], 0.35: [93.13399999999162, 92.94899999998694, 92.85699999998847], 0.4: [93.97399999998945, 92.13899999998692, 92.85899999998675], 0.45: [91.99299999998995, 92.84199999998815, 92.19799999998747], 0.5: [87.8099999999837, 92.43599999998794, 92.72599999998661]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335, 92.05799999998627], 0.05: [92.30599999998712, 90.49499999998585, 92.81299999998924], 0.1: [90.56499999998519, 91.62299999998415, 92.75099999998571], 0.15: [92.28099999998632, 90.62499999998441, 91.28099999998392], 0.2: [90.71899999998492, 89.12899999998388, 89.55799999998499], 0.25: [86.94399999998424, 86.38199999997914, 85.78899999998062], 0.3: [88.8129999999836, 78.29699999997993, 74.8549999999841], 0.35: [79.35699999997657, 60.54799999997876, 55.30299999998504], 0.4: [65.82799999996949, 53.1749999999922, 17.8190000000091], 0.45: [44.69400000000934, 32.6630000000202, 18.938000000019915], 0.5: [39.77100000001431, 25.242000000020642, 12.218999999997045]}}\n","100: -45.72300000000042\n","200: -39.391000000000425\n","300: -48.95800000000043\n","400: -17.329000000000363\n","500: 18.434999999999707\n","600: 27.698999999999742\n","700: 57.23899999999981\n","800: 69.13699999999989\n","900: 72.88999999999993\n","1000: 78.83399999999997\n","1100: 80.19799999999998\n","1200: 85.382\n","1300: 86.88300000000001\n","1400: 88.498\n","Solved after 1425 episodes!\n","3 noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513, 90.7309999999889, 88.45099999998054], 0.05: [89.4869999999837, 93.24799999998795, 92.62899999998746, 92.02299999998553], 0.1: [91.21499999998642, 90.90899999998567, 92.61499999998635, 90.70199999998697], 0.15: [90.95299999998502, 91.00299999998501, 91.70299999998804, 91.3469999999848], 0.2: [90.99899999998628, 89.4699999999805, 89.41899999998193, 88.43099999998007], 0.25: [89.98899999998606, 87.52999999997974, 80.66399999997658, 81.15699999997197], 0.3: [82.89599999998005, 80.61799999997865, 72.70199999998047, 76.58899999996886], 0.35: [75.16299999997683, 70.34799999996771, 50.234999999996546, 66.67399999997859], 0.4: [44.124000000006575, 52.609999999990976, 29.5280000000186, 53.97299999998187], 0.45: [29.3830000000148, 43.51200000000169, 14.281000000008012, 42.733000000020574], 0.5: [25.872000000013436, 21.916000000019608, -1.44399999999866, 33.39200000002015]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534, 90.90699999998705, 87.16299999997962], 0.05: [90.77499999998848, 91.60199999999006, 91.46199999998693, 92.56599999998772], 0.1: [90.9429999999895, 87.92299999998235, 92.52399999998852, 91.90799999998904], 0.15: [91.82999999998647, 90.69699999998711, 91.3109999999872, 91.84399999998422], 0.2: [91.71499999998522, 90.10099999998583, 90.11499999998324, 89.50599999998418], 0.25: [88.26899999998155, 87.14999999998047, 87.78299999998026, 86.70799999997882], 0.3: [82.96999999998104, 83.39299999997124, 76.377999999976, 82.06599999997408], 0.35: [68.25199999996538, 78.22699999996979, 63.57299999997339, 79.16099999996555], 0.4: [62.2339999999845, 67.57499999996911, 31.85800000002177, 62.27599999997574], 0.45: [45.82000000000585, 57.59299999998575, 35.0630000000193, 42.157000000013596], 0.5: [36.61600000002265, 47.38000000000224, -2.8670000000036793, 35.233000000022955]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261, 88.32499999998407, 91.45699999998727], 0.05: [88.6179999999853, 89.00999999998929, 86.94099999998474, 90.51399999998412], 0.1: [93.3009999999867, 92.01499999998596, 92.03599999998617, 92.60099999998849], 0.15: [94.09199999998887, 93.32899999998827, 90.72399999998566, 89.57999999998505], 0.2: [94.46599999998952, 92.8919999999885, 93.4199999999868, 92.0889999999868], 0.25: [91.11899999999254, 92.63499999998864, 92.71799999998794, 91.91199999998385], 0.3: [93.6839999999902, 92.57199999998892, 92.75399999998722, 91.59899999998689], 0.35: [93.13399999999162, 92.94899999998694, 92.85699999998847, 91.73799999998526], 0.4: [93.97399999998945, 92.13899999998692, 92.85899999998675, 90.233999999989], 0.45: [91.99299999998995, 92.84199999998815, 92.19799999998747, 92.00799999998726], 0.5: [87.8099999999837, 92.43599999998794, 92.72599999998661, 89.25199999998216]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335, 92.05799999998627, 90.5699999999828], 0.05: [92.30599999998712, 90.49499999998585, 92.81299999998924, 91.64599999998914], 0.1: [90.56499999998519, 91.62299999998415, 92.75099999998571, 91.97099999998645], 0.15: [92.28099999998632, 90.62499999998441, 91.28099999998392, 91.22799999998448], 0.2: [90.71899999998492, 89.12899999998388, 89.55799999998499, 88.33499999998281], 0.25: [86.94399999998424, 86.38199999997914, 85.78899999998062, 83.72399999997717], 0.3: [88.8129999999836, 78.29699999997993, 74.8549999999841, 76.50799999997517], 0.35: [79.35699999997657, 60.54799999997876, 55.30299999998504, 51.894999999990496], 0.4: [65.82799999996949, 53.1749999999922, 17.8190000000091, 62.86599999998013], 0.45: [44.69400000000934, 32.6630000000202, 18.938000000019915, 38.57000000002352], 0.5: [39.77100000001431, 25.242000000020642, 12.218999999997045, 32.44100000002214]}}\n","100: -46.67800000000043\n","200: -29.017000000000394\n","300: -36.94500000000042\n","400: -48.90700000000042\n","500: -45.07700000000042\n","600: -12.308000000000366\n","700: 20.422999999999707\n","800: 1.0139999999996543\n","900: 30.534999999999712\n","1000: 48.80199999999974\n","1100: 70.97299999999989\n","1200: 66.69199999999992\n","1300: 75.54099999999998\n","1400: 76.40699999999997\n","1500: 75.01499999999996\n","1600: 82.78999999999998\n","1700: 78.41799999999996\n","1800: 73.48399999999994\n","1900: 81.86999999999996\n","2000: 83.66599999999997\n","Solved after 2075 episodes!\n","4 noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513, 90.7309999999889, 88.45099999998054, 91.15199999998971], 0.05: [89.4869999999837, 93.24799999998795, 92.62899999998746, 92.02299999998553, 94.68599999999101], 0.1: [91.21499999998642, 90.90899999998567, 92.61499999998635, 90.70199999998697, 92.85399999998836], 0.15: [90.95299999998502, 91.00299999998501, 91.70299999998804, 91.3469999999848, 94.13999999999021], 0.2: [90.99899999998628, 89.4699999999805, 89.41899999998193, 88.43099999998007, 93.12299999998895], 0.25: [89.98899999998606, 87.52999999997974, 80.66399999997658, 81.15699999997197, 91.65699999998445], 0.3: [82.89599999998005, 80.61799999997865, 72.70199999998047, 76.58899999996886, 88.20899999998406], 0.35: [75.16299999997683, 70.34799999996771, 50.234999999996546, 66.67399999997859, 79.27799999997332], 0.4: [44.124000000006575, 52.609999999990976, 29.5280000000186, 53.97299999998187, 71.17599999998069], 0.45: [29.3830000000148, 43.51200000000169, 14.281000000008012, 42.733000000020574, 67.73399999997285], 0.5: [25.872000000013436, 21.916000000019608, -1.44399999999866, 33.39200000002015, 52.454999999998975]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534, 90.90699999998705, 87.16299999997962, 93.4349999999874], 0.05: [90.77499999998848, 91.60199999999006, 91.46199999998693, 92.56599999998772, 92.46599999998995], 0.1: [90.9429999999895, 87.92299999998235, 92.52399999998852, 91.90799999998904, 94.70999999999054], 0.15: [91.82999999998647, 90.69699999998711, 91.3109999999872, 91.84399999998422, 93.99099999998944], 0.2: [91.71499999998522, 90.10099999998583, 90.11499999998324, 89.50599999998418, 92.39199999998671], 0.25: [88.26899999998155, 87.14999999998047, 87.78299999998026, 86.70799999997882, 91.10299999998426], 0.3: [82.96999999998104, 83.39299999997124, 76.377999999976, 82.06599999997408, 88.8419999999834], 0.35: [68.25199999996538, 78.22699999996979, 63.57299999997339, 79.16099999996555, 88.58799999998608], 0.4: [62.2339999999845, 67.57499999996911, 31.85800000002177, 62.27599999997574, 75.63899999997427], 0.45: [45.82000000000585, 57.59299999998575, 35.0630000000193, 42.157000000013596, 76.04099999997509], 0.5: [36.61600000002265, 47.38000000000224, -2.8670000000036793, 35.233000000022955, 59.66899999997926]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261, 88.32499999998407, 91.45699999998727, 93.72999999998746], 0.05: [88.6179999999853, 89.00999999998929, 86.94099999998474, 90.51399999998412, 88.60899999998564], 0.1: [93.3009999999867, 92.01499999998596, 92.03599999998617, 92.60099999998849, 92.29099999998736], 0.15: [94.09199999998887, 93.32899999998827, 90.72399999998566, 89.57999999998505, 94.24499999998956], 0.2: [94.46599999998952, 92.8919999999885, 93.4199999999868, 92.0889999999868, 92.74499999998801], 0.25: [91.11899999999254, 92.63499999998864, 92.71799999998794, 91.91199999998385, 94.7019999999912], 0.3: [93.6839999999902, 92.57199999998892, 92.75399999998722, 91.59899999998689, 93.11299999998757], 0.35: [93.13399999999162, 92.94899999998694, 92.85699999998847, 91.73799999998526, 94.5589999999903], 0.4: [93.97399999998945, 92.13899999998692, 92.85899999998675, 90.233999999989, 94.62999999999077], 0.45: [91.99299999998995, 92.84199999998815, 92.19799999998747, 92.00799999998726, 94.24199999999033], 0.5: [87.8099999999837, 92.43599999998794, 92.72599999998661, 89.25199999998216, 94.03399999998847]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335, 92.05799999998627, 90.5699999999828, 91.3279999999879], 0.05: [92.30599999998712, 90.49499999998585, 92.81299999998924, 91.64599999998914, 94.32899999998925], 0.1: [90.56499999998519, 91.62299999998415, 92.75099999998571, 91.97099999998645, 94.26299999998966], 0.15: [92.28099999998632, 90.62499999998441, 91.28099999998392, 91.22799999998448, 93.7409999999889], 0.2: [90.71899999998492, 89.12899999998388, 89.55799999998499, 88.33499999998281, 92.94799999998823], 0.25: [86.94399999998424, 86.38199999997914, 85.78899999998062, 83.72399999997717, 90.56999999998536], 0.3: [88.8129999999836, 78.29699999997993, 74.8549999999841, 76.50799999997517, 90.16799999998089], 0.35: [79.35699999997657, 60.54799999997876, 55.30299999998504, 51.894999999990496, 84.53399999997849], 0.4: [65.82799999996949, 53.1749999999922, 17.8190000000091, 62.86599999998013, 73.82299999997626], 0.45: [44.69400000000934, 32.6630000000202, 18.938000000019915, 38.57000000002352, 60.14099999997083], 0.5: [39.77100000001431, 25.242000000020642, 12.218999999997045, 32.44100000002214, 43.14300000001613]}}\n","100: -43.37100000000042\n","200: -24.88600000000039\n","300: -40.660000000000416\n","400: -35.472000000000406\n","500: -33.093000000000394\n","600: -38.906000000000425\n","700: -38.0100000000004\n","800: -39.670000000000414\n","900: -15.518000000000352\n","1000: -12.948000000000338\n","1100: 20.521999999999736\n","1200: 61.53199999999989\n","1300: 75.53899999999994\n","1400: 62.865999999999914\n","1500: 79.49999999999997\n","1600: 72.95599999999995\n","1700: 55.34099999999984\n","1800: 81.05299999999997\n","1900: 84.37099999999997\n","2000: 81.16599999999997\n","2100: 60.99099999999989\n","2200: 46.88099999999986\n","2300: 80.59899999999998\n","Solved after 2351 episodes!\n","5 noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513, 90.7309999999889, 88.45099999998054, 91.15199999998971, 87.55699999998464], 0.05: [89.4869999999837, 93.24799999998795, 92.62899999998746, 92.02299999998553, 94.68599999999101, 94.34799999998904], 0.1: [91.21499999998642, 90.90899999998567, 92.61499999998635, 90.70199999998697, 92.85399999998836, 92.3249999999885], 0.15: [90.95299999998502, 91.00299999998501, 91.70299999998804, 91.3469999999848, 94.13999999999021, 90.53399999998406], 0.2: [90.99899999998628, 89.4699999999805, 89.41899999998193, 88.43099999998007, 93.12299999998895, 89.51999999998402], 0.25: [89.98899999998606, 87.52999999997974, 80.66399999997658, 81.15699999997197, 91.65699999998445, 69.10599999997565], 0.3: [82.89599999998005, 80.61799999997865, 72.70199999998047, 76.58899999996886, 88.20899999998406, 46.019000000013506], 0.35: [75.16299999997683, 70.34799999996771, 50.234999999996546, 66.67399999997859, 79.27799999997332, -1.342000000003333], 0.4: [44.124000000006575, 52.609999999990976, 29.5280000000186, 53.97299999998187, 71.17599999998069, 7.8789999999931455], 0.45: [29.3830000000148, 43.51200000000169, 14.281000000008012, 42.733000000020574, 67.73399999997285, 0.3659999999955307], 0.5: [25.872000000013436, 21.916000000019608, -1.44399999999866, 33.39200000002015, 52.454999999998975, 8.51499999999646]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534, 90.90699999998705, 87.16299999997962, 93.4349999999874, 88.30399999998608], 0.05: [90.77499999998848, 91.60199999999006, 91.46199999998693, 92.56599999998772, 92.46599999998995, 91.49799999998582], 0.1: [90.9429999999895, 87.92299999998235, 92.52399999998852, 91.90799999998904, 94.70999999999054, 93.73099999998897], 0.15: [91.82999999998647, 90.69699999998711, 91.3109999999872, 91.84399999998422, 93.99099999998944, 92.26899999998724], 0.2: [91.71499999998522, 90.10099999998583, 90.11499999998324, 89.50599999998418, 92.39199999998671, 88.92699999998348], 0.25: [88.26899999998155, 87.14999999998047, 87.78299999998026, 86.70799999997882, 91.10299999998426, 70.83199999997538], 0.3: [82.96999999998104, 83.39299999997124, 76.377999999976, 82.06599999997408, 88.8419999999834, 26.066000000011112], 0.35: [68.25199999996538, 78.22699999996979, 63.57299999997339, 79.16099999996555, 88.58799999998608, -4.701000000003464], 0.4: [62.2339999999845, 67.57499999996911, 31.85800000002177, 62.27599999997574, 75.63899999997427, 7.158999999998852], 0.45: [45.82000000000585, 57.59299999998575, 35.0630000000193, 42.157000000013596, 76.04099999997509, 6.003999999996357], 0.5: [36.61600000002265, 47.38000000000224, -2.8670000000036793, 35.233000000022955, 59.66899999997926, 10.058000000001424]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261, 88.32499999998407, 91.45699999998727, 93.72999999998746, 87.86899999998232], 0.05: [88.6179999999853, 89.00999999998929, 86.94099999998474, 90.51399999998412, 88.60899999998564, 91.53599999998708], 0.1: [93.3009999999867, 92.01499999998596, 92.03599999998617, 92.60099999998849, 92.29099999998736, 91.7959999999865], 0.15: [94.09199999998887, 93.32899999998827, 90.72399999998566, 89.57999999998505, 94.24499999998956, 94.17999999998818], 0.2: [94.46599999998952, 92.8919999999885, 93.4199999999868, 92.0889999999868, 92.74499999998801, 93.73599999998967], 0.25: [91.11899999999254, 92.63499999998864, 92.71799999998794, 91.91199999998385, 94.7019999999912, 93.60099999998731], 0.3: [93.6839999999902, 92.57199999998892, 92.75399999998722, 91.59899999998689, 93.11299999998757, 93.48499999999098], 0.35: [93.13399999999162, 92.94899999998694, 92.85699999998847, 91.73799999998526, 94.5589999999903, 93.78099999998986], 0.4: [93.97399999998945, 92.13899999998692, 92.85899999998675, 90.233999999989, 94.62999999999077, 93.56199999998813], 0.45: [91.99299999998995, 92.84199999998815, 92.19799999998747, 92.00799999998726, 94.24199999999033, 92.39199999998708], 0.5: [87.8099999999837, 92.43599999998794, 92.72599999998661, 89.25199999998216, 94.03399999998847, 92.11199999998833]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335, 92.05799999998627, 90.5699999999828, 91.3279999999879, 90.44499999998813], 0.05: [92.30599999998712, 90.49499999998585, 92.81299999998924, 91.64599999998914, 94.32899999998925, 92.54599999998572], 0.1: [90.56499999998519, 91.62299999998415, 92.75099999998571, 91.97099999998645, 94.26299999998966, 91.73299999998964], 0.15: [92.28099999998632, 90.62499999998441, 91.28099999998392, 91.22799999998448, 93.7409999999889, 92.86399999998842], 0.2: [90.71899999998492, 89.12899999998388, 89.55799999998499, 88.33499999998281, 92.94799999998823, 89.421999999983], 0.25: [86.94399999998424, 86.38199999997914, 85.78899999998062, 83.72399999997717, 90.56999999998536, 71.23699999997693], 0.3: [88.8129999999836, 78.29699999997993, 74.8549999999841, 76.50799999997517, 90.16799999998089, 40.54100000001844], 0.35: [79.35699999997657, 60.54799999997876, 55.30299999998504, 51.894999999990496, 84.53399999997849, 12.257000000007574], 0.4: [65.82799999996949, 53.1749999999922, 17.8190000000091, 62.86599999998013, 73.82299999997626, 14.670000000017659], 0.45: [44.69400000000934, 32.6630000000202, 18.938000000019915, 38.57000000002352, 60.14099999997083, 17.62500000001842], 0.5: [39.77100000001431, 25.242000000020642, 12.218999999997045, 32.44100000002214, 43.14300000001613, 23.417000000014355]}}\n","----\n","noise_hrl: {'both': {0.0: [90.47199999998625, 88.39099999998513, 90.7309999999889, 88.45099999998054, 91.15199999998971, 87.55699999998464], 0.05: [89.4869999999837, 93.24799999998795, 92.62899999998746, 92.02299999998553, 94.68599999999101, 94.34799999998904], 0.1: [91.21499999998642, 90.90899999998567, 92.61499999998635, 90.70199999998697, 92.85399999998836, 92.3249999999885], 0.15: [90.95299999998502, 91.00299999998501, 91.70299999998804, 91.3469999999848, 94.13999999999021, 90.53399999998406], 0.2: [90.99899999998628, 89.4699999999805, 89.41899999998193, 88.43099999998007, 93.12299999998895, 89.51999999998402], 0.25: [89.98899999998606, 87.52999999997974, 80.66399999997658, 81.15699999997197, 91.65699999998445, 69.10599999997565], 0.3: [82.89599999998005, 80.61799999997865, 72.70199999998047, 76.58899999996886, 88.20899999998406, 46.019000000013506], 0.35: [75.16299999997683, 70.34799999996771, 50.234999999996546, 66.67399999997859, 79.27799999997332, -1.342000000003333], 0.4: [44.124000000006575, 52.609999999990976, 29.5280000000186, 53.97299999998187, 71.17599999998069, 7.8789999999931455], 0.45: [29.3830000000148, 43.51200000000169, 14.281000000008012, 42.733000000020574, 67.73399999997285, 0.3659999999955307], 0.5: [25.872000000013436, 21.916000000019608, -1.44399999999866, 33.39200000002015, 52.454999999998975, 8.51499999999646]}, 'action_only': {0.0: [90.51499999998822, 88.96799999998534, 90.90699999998705, 87.16299999997962, 93.4349999999874, 88.30399999998608], 0.05: [90.77499999998848, 91.60199999999006, 91.46199999998693, 92.56599999998772, 92.46599999998995, 91.49799999998582], 0.1: [90.9429999999895, 87.92299999998235, 92.52399999998852, 91.90799999998904, 94.70999999999054, 93.73099999998897], 0.15: [91.82999999998647, 90.69699999998711, 91.3109999999872, 91.84399999998422, 93.99099999998944, 92.26899999998724], 0.2: [91.71499999998522, 90.10099999998583, 90.11499999998324, 89.50599999998418, 92.39199999998671, 88.92699999998348], 0.25: [88.26899999998155, 87.14999999998047, 87.78299999998026, 86.70799999997882, 91.10299999998426, 70.83199999997538], 0.3: [82.96999999998104, 83.39299999997124, 76.377999999976, 82.06599999997408, 88.8419999999834, 26.066000000011112], 0.35: [68.25199999996538, 78.22699999996979, 63.57299999997339, 79.16099999996555, 88.58799999998608, -4.701000000003464], 0.4: [62.2339999999845, 67.57499999996911, 31.85800000002177, 62.27599999997574, 75.63899999997427, 7.158999999998852], 0.45: [45.82000000000585, 57.59299999998575, 35.0630000000193, 42.157000000013596, 76.04099999997509, 6.003999999996357], 0.5: [36.61600000002265, 47.38000000000224, -2.8670000000036793, 35.233000000022955, 59.66899999997926, 10.058000000001424]}, 'goal_only': {0.0: [91.56999999998793, 87.00399999998261, 88.32499999998407, 91.45699999998727, 93.72999999998746, 87.86899999998232], 0.05: [88.6179999999853, 89.00999999998929, 86.94099999998474, 90.51399999998412, 88.60899999998564, 91.53599999998708], 0.1: [93.3009999999867, 92.01499999998596, 92.03599999998617, 92.60099999998849, 92.29099999998736, 91.7959999999865], 0.15: [94.09199999998887, 93.32899999998827, 90.72399999998566, 89.57999999998505, 94.24499999998956, 94.17999999998818], 0.2: [94.46599999998952, 92.8919999999885, 93.4199999999868, 92.0889999999868, 92.74499999998801, 93.73599999998967], 0.25: [91.11899999999254, 92.63499999998864, 92.71799999998794, 91.91199999998385, 94.7019999999912, 93.60099999998731], 0.3: [93.6839999999902, 92.57199999998892, 92.75399999998722, 91.59899999998689, 93.11299999998757, 93.48499999999098], 0.35: [93.13399999999162, 92.94899999998694, 92.85699999998847, 91.73799999998526, 94.5589999999903, 93.78099999998986], 0.4: [93.97399999998945, 92.13899999998692, 92.85899999998675, 90.233999999989, 94.62999999999077, 93.56199999998813], 0.45: [91.99299999998995, 92.84199999998815, 92.19799999998747, 92.00799999998726, 94.24199999999033, 92.39199999998708], 0.5: [87.8099999999837, 92.43599999998794, 92.72599999998661, 89.25199999998216, 94.03399999998847, 92.11199999998833]}, 'both_same': {0.0: [88.91499999998477, 89.50999999998335, 92.05799999998627, 90.5699999999828, 91.3279999999879, 90.44499999998813], 0.05: [92.30599999998712, 90.49499999998585, 92.81299999998924, 91.64599999998914, 94.32899999998925, 92.54599999998572], 0.1: [90.56499999998519, 91.62299999998415, 92.75099999998571, 91.97099999998645, 94.26299999998966, 91.73299999998964], 0.15: [92.28099999998632, 90.62499999998441, 91.28099999998392, 91.22799999998448, 93.7409999999889, 92.86399999998842], 0.2: [90.71899999998492, 89.12899999998388, 89.55799999998499, 88.33499999998281, 92.94799999998823, 89.421999999983], 0.25: [86.94399999998424, 86.38199999997914, 85.78899999998062, 83.72399999997717, 90.56999999998536, 71.23699999997693], 0.3: [88.8129999999836, 78.29699999997993, 74.8549999999841, 76.50799999997517, 90.16799999998089, 40.54100000001844], 0.35: [79.35699999997657, 60.54799999997876, 55.30299999998504, 51.894999999990496, 84.53399999997849, 12.257000000007574], 0.4: [65.82799999996949, 53.1749999999922, 17.8190000000091, 62.86599999998013, 73.82299999997626, 14.670000000017659], 0.45: [44.69400000000934, 32.6630000000202, 18.938000000019915, 38.57000000002352, 60.14099999997083, 17.62500000001842], 0.5: [39.77100000001431, 25.242000000020642, 12.218999999997045, 32.44100000002214, 43.14300000001613, 23.417000000014355]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GhC6f7N6sJoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618941242781,"user_tz":-60,"elapsed":7364432,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"7b52a613-dcc6-4a36-b626-991f3cb32f08"},"source":["targeted = {'goal': {}, 'action': {}}\n","untargeted = {'goal': {}, 'action': {}}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    for x in ['goal', 'action']:\n","        targeted[x][eps] = []\n","        untargeted[x][eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        apply_fgsm(agent, untargeted['action'], False)   \n","        print(f\"{i} fgsm (ut): {untargeted}\")\n","\n","        apply_fgsm(agent, targeted['action'], True)   \n","        print(f\"{i} fgsm (t): {targeted}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"fgsm (ut): {untargeted}\")\n","print(f\"fgsm (t): {targeted}\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287], 0.02: [90.92399999999213], 0.04: [89.7319999999854], 0.06: [89.37099999998456], 0.08: [87.73099999998068], 0.1: [80.78999999997882], 0.12: [69.93799999997549], 0.14: [50.24699999998062], 0.16: [5.063999999995682], 0.18: [-17.25299999998021], 0.2: [-38.44499999997118]}}\n","0 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691], 0.02: [84.279999999984], 0.04: [76.47699999998052], 0.06: [57.613999999994974], 0.08: [40.40900000001749], 0.1: [19.70200000000977], 0.12: [22.290000000010266], 0.14: [1.887000000001302], 0.16: [-16.67199999998326], 0.18: [-26.216999999973414], 0.2: [-19.215999999981573]}}\n","1 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521], 0.02: [90.92399999999213, 91.03299999998605], 0.04: [89.7319999999854, 91.50699999998328], 0.06: [89.37099999998456, 88.72099999998544], 0.08: [87.73099999998068, 90.98499999998667], 0.1: [80.78999999997882, 81.29099999997374], 0.12: [69.93799999997549, 80.28099999997814], 0.14: [50.24699999998062, 68.13199999997856], 0.16: [5.063999999995682, 58.833999999982694], 0.18: [-17.25299999998021, 45.43400000001079], 0.2: [-38.44499999997118, 21.708000000008028]}}\n","1 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418], 0.02: [84.279999999984, 84.6059999999839], 0.04: [76.47699999998052, 79.1319999999893], 0.06: [57.613999999994974, 56.24999999997841], 0.08: [40.40900000001749, 54.187999999983546], 0.1: [19.70200000000977, 12.744000000013283], 0.12: [22.290000000010266, -17.083999999989125], 0.14: [1.887000000001302, -34.31799999996792], 0.16: [-16.67199999998326, -44.701999999984565], 0.18: [-26.216999999973414, -46.622999999993844], 0.2: [-19.215999999981573, -48.95600000000188]}}\n","2 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521, 88.37899999998503], 0.02: [90.92399999999213, 91.03299999998605, 93.4259999999886], 0.04: [89.7319999999854, 91.50699999998328, 93.60399999998853], 0.06: [89.37099999998456, 88.72099999998544, 91.484999999985], 0.08: [87.73099999998068, 90.98499999998667, 88.74299999998189], 0.1: [80.78999999997882, 81.29099999997374, 83.69399999997599], 0.12: [69.93799999997549, 80.28099999997814, 69.53999999997886], 0.14: [50.24699999998062, 68.13199999997856, 65.6579999999838], 0.16: [5.063999999995682, 58.833999999982694, 34.348000000021486], 0.18: [-17.25299999998021, 45.43400000001079, 14.801000000007566], 0.2: [-38.44499999997118, 21.708000000008028, -11.01699999998469]}}\n","2 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418, 89.54499999998605], 0.02: [84.279999999984, 84.6059999999839, 88.13799999998776], 0.04: [76.47699999998052, 79.1319999999893, 77.56999999998088], 0.06: [57.613999999994974, 56.24999999997841, 63.44599999997978], 0.08: [40.40900000001749, 54.187999999983546, 46.23000000000261], 0.1: [19.70200000000977, 12.744000000013283, 4.486999999995527], 0.12: [22.290000000010266, -17.083999999989125, -6.596000000003991], 0.14: [1.887000000001302, -34.31799999996792, -14.236999999995232], 0.16: [-16.67199999998326, -44.701999999984565, -20.595999999980112], 0.18: [-26.216999999973414, -46.622999999993844, -29.387999999971495], 0.2: [-19.215999999981573, -48.95600000000188, -38.59499999997069]}}\n","3 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521, 88.37899999998503, 88.92399999998435], 0.02: [90.92399999999213, 91.03299999998605, 93.4259999999886, 88.95699999998355], 0.04: [89.7319999999854, 91.50699999998328, 93.60399999998853, 90.91599999998641], 0.06: [89.37099999998456, 88.72099999998544, 91.484999999985, 89.7229999999819], 0.08: [87.73099999998068, 90.98499999998667, 88.74299999998189, 85.64099999997956], 0.1: [80.78999999997882, 81.29099999997374, 83.69399999997599, 82.92099999997752], 0.12: [69.93799999997549, 80.28099999997814, 69.53999999997886, 71.17099999997656], 0.14: [50.24699999998062, 68.13199999997856, 65.6579999999838, 62.12499999997119], 0.16: [5.063999999995682, 58.833999999982694, 34.348000000021486, 41.19600000002268], 0.18: [-17.25299999998021, 45.43400000001079, 14.801000000007566, 25.839000000022892], 0.2: [-38.44499999997118, 21.708000000008028, -11.01699999998469, -0.3989999999993097]}}\n","3 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418, 89.54499999998605, 90.93599999998474], 0.02: [84.279999999984, 84.6059999999839, 88.13799999998776, 89.33499999998484], 0.04: [76.47699999998052, 79.1319999999893, 77.56999999998088, 87.57199999998045], 0.06: [57.613999999994974, 56.24999999997841, 63.44599999997978, 72.81999999997704], 0.08: [40.40900000001749, 54.187999999983546, 46.23000000000261, 53.822999999990685], 0.1: [19.70200000000977, 12.744000000013283, 4.486999999995527, 2.388999999998871], 0.12: [22.290000000010266, -17.083999999989125, -6.596000000003991, -19.73599999998384], 0.14: [1.887000000001302, -34.31799999996792, -14.236999999995232, -35.58899999997033], 0.16: [-16.67199999998326, -44.701999999984565, -20.595999999980112, -40.85599999996743], 0.18: [-26.216999999973414, -46.622999999993844, -29.387999999971495, -48.747000000001115], 0.2: [-19.215999999981573, -48.95600000000188, -38.59499999997069, -42.370999999979055]}}\n","4 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521, 88.37899999998503, 88.92399999998435, 92.02099999998686], 0.02: [90.92399999999213, 91.03299999998605, 93.4259999999886, 88.95699999998355, 95.05499999999171], 0.04: [89.7319999999854, 91.50699999998328, 93.60399999998853, 90.91599999998641, 95.01399999999167], 0.06: [89.37099999998456, 88.72099999998544, 91.484999999985, 89.7229999999819, 93.55699999999142], 0.08: [87.73099999998068, 90.98499999998667, 88.74299999998189, 85.64099999997956, 90.41199999998663], 0.1: [80.78999999997882, 81.29099999997374, 83.69399999997599, 82.92099999997752, 84.23899999997887], 0.12: [69.93799999997549, 80.28099999997814, 69.53999999997886, 71.17099999997656, 75.14399999997572], 0.14: [50.24699999998062, 68.13199999997856, 65.6579999999838, 62.12499999997119, 66.79599999997377], 0.16: [5.063999999995682, 58.833999999982694, 34.348000000021486, 41.19600000002268, 35.30900000001889], 0.18: [-17.25299999998021, 45.43400000001079, 14.801000000007566, 25.839000000022892, 34.059000000022635], 0.2: [-38.44499999997118, 21.708000000008028, -11.01699999998469, -0.3989999999993097, 11.34699999999628]}}\n","4 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418, 89.54499999998605, 90.93599999998474, 90.02399999998914], 0.02: [84.279999999984, 84.6059999999839, 88.13799999998776, 89.33499999998484, 92.27899999998752], 0.04: [76.47699999998052, 79.1319999999893, 77.56999999998088, 87.57199999998045, 84.61799999997952], 0.06: [57.613999999994974, 56.24999999997841, 63.44599999997978, 72.81999999997704, 65.17699999998538], 0.08: [40.40900000001749, 54.187999999983546, 46.23000000000261, 53.822999999990685, 40.66200000002305], 0.1: [19.70200000000977, 12.744000000013283, 4.486999999995527, 2.388999999998871, 15.38499999999999], 0.12: [22.290000000010266, -17.083999999989125, -6.596000000003991, -19.73599999998384, -5.479000000004586], 0.14: [1.887000000001302, -34.31799999996792, -14.236999999995232, -35.58899999997033, -10.696999999995223], 0.16: [-16.67199999998326, -44.701999999984565, -20.595999999980112, -40.85599999996743, -31.176999999976807], 0.18: [-26.216999999973414, -46.622999999993844, -29.387999999971495, -48.747000000001115, -37.6759999999721], 0.2: [-19.215999999981573, -48.95600000000188, -38.59499999997069, -42.370999999979055, -45.26999999998688]}}\n","5 fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521, 88.37899999998503, 88.92399999998435, 92.02099999998686, 89.33499999998736], 0.02: [90.92399999999213, 91.03299999998605, 93.4259999999886, 88.95699999998355, 95.05499999999171, 91.81199999998783], 0.04: [89.7319999999854, 91.50699999998328, 93.60399999998853, 90.91599999998641, 95.01399999999167, 91.76299999998601], 0.06: [89.37099999998456, 88.72099999998544, 91.484999999985, 89.7229999999819, 93.55699999999142, 90.11699999998348], 0.08: [87.73099999998068, 90.98499999998667, 88.74299999998189, 85.64099999997956, 90.41199999998663, 86.69599999998148], 0.1: [80.78999999997882, 81.29099999997374, 83.69399999997599, 82.92099999997752, 84.23899999997887, 68.914999999983], 0.12: [69.93799999997549, 80.28099999997814, 69.53999999997886, 71.17099999997656, 75.14399999997572, 38.00600000001808], 0.14: [50.24699999998062, 68.13199999997856, 65.6579999999838, 62.12499999997119, 66.79599999997377, -1.1800000000023914], 0.16: [5.063999999995682, 58.833999999982694, 34.348000000021486, 41.19600000002268, 35.30900000001889, -26.66799999997652], 0.18: [-17.25299999998021, 45.43400000001079, 14.801000000007566, 25.839000000022892, 34.059000000022635, -37.37699999996809], 0.2: [-38.44499999997118, 21.708000000008028, -11.01699999998469, -0.3989999999993097, 11.34699999999628, -44.61699999998788]}}\n","5 fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418, 89.54499999998605, 90.93599999998474, 90.02399999998914, 90.33699999998363], 0.02: [84.279999999984, 84.6059999999839, 88.13799999998776, 89.33499999998484, 92.27899999998752, 91.95499999998566], 0.04: [76.47699999998052, 79.1319999999893, 77.56999999998088, 87.57199999998045, 84.61799999997952, 84.90699999997989], 0.06: [57.613999999994974, 56.24999999997841, 63.44599999997978, 72.81999999997704, 65.17699999998538, 76.3049999999765], 0.08: [40.40900000001749, 54.187999999983546, 46.23000000000261, 53.822999999990685, 40.66200000002305, 61.985999999985005], 0.1: [19.70200000000977, 12.744000000013283, 4.486999999995527, 2.388999999998871, 15.38499999999999, 40.9240000000194], 0.12: [22.290000000010266, -17.083999999989125, -6.596000000003991, -19.73599999998384, -5.479000000004586, -3.2220000000031517], 0.14: [1.887000000001302, -34.31799999996792, -14.236999999995232, -35.58899999997033, -10.696999999995223, -12.229000000002966], 0.16: [-16.67199999998326, -44.701999999984565, -20.595999999980112, -40.85599999996743, -31.176999999976807, -20.463999999974533], 0.18: [-26.216999999973414, -46.622999999993844, -29.387999999971495, -48.747000000001115, -37.6759999999721, -36.40099999997183], 0.2: [-19.215999999981573, -48.95600000000188, -38.59499999997069, -42.370999999979055, -45.26999999998688, -42.06299999997248]}}\n","----\n","fgsm (ut): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [90.53799999998287, 85.20699999998521, 88.37899999998503, 88.92399999998435, 92.02099999998686, 89.33499999998736], 0.02: [90.92399999999213, 91.03299999998605, 93.4259999999886, 88.95699999998355, 95.05499999999171, 91.81199999998783], 0.04: [89.7319999999854, 91.50699999998328, 93.60399999998853, 90.91599999998641, 95.01399999999167, 91.76299999998601], 0.06: [89.37099999998456, 88.72099999998544, 91.484999999985, 89.7229999999819, 93.55699999999142, 90.11699999998348], 0.08: [87.73099999998068, 90.98499999998667, 88.74299999998189, 85.64099999997956, 90.41199999998663, 86.69599999998148], 0.1: [80.78999999997882, 81.29099999997374, 83.69399999997599, 82.92099999997752, 84.23899999997887, 68.914999999983], 0.12: [69.93799999997549, 80.28099999997814, 69.53999999997886, 71.17099999997656, 75.14399999997572, 38.00600000001808], 0.14: [50.24699999998062, 68.13199999997856, 65.6579999999838, 62.12499999997119, 66.79599999997377, -1.1800000000023914], 0.16: [5.063999999995682, 58.833999999982694, 34.348000000021486, 41.19600000002268, 35.30900000001889, -26.66799999997652], 0.18: [-17.25299999998021, 45.43400000001079, 14.801000000007566, 25.839000000022892, 34.059000000022635, -37.37699999996809], 0.2: [-38.44499999997118, 21.708000000008028, -11.01699999998469, -0.3989999999993097, 11.34699999999628, -44.61699999998788]}}\n","fgsm (t): {'goal': {0.0: [], 0.02: [], 0.04: [], 0.06: [], 0.08: [], 0.1: [], 0.12: [], 0.14: [], 0.16: [], 0.18: [], 0.2: []}, 'action': {0.0: [87.55699999998691, 88.04199999998418, 89.54499999998605, 90.93599999998474, 90.02399999998914, 90.33699999998363], 0.02: [84.279999999984, 84.6059999999839, 88.13799999998776, 89.33499999998484, 92.27899999998752, 91.95499999998566], 0.04: [76.47699999998052, 79.1319999999893, 77.56999999998088, 87.57199999998045, 84.61799999997952, 84.90699999997989], 0.06: [57.613999999994974, 56.24999999997841, 63.44599999997978, 72.81999999997704, 65.17699999998538, 76.3049999999765], 0.08: [40.40900000001749, 54.187999999983546, 46.23000000000261, 53.822999999990685, 40.66200000002305, 61.985999999985005], 0.1: [19.70200000000977, 12.744000000013283, 4.486999999995527, 2.388999999998871, 15.38499999999999, 40.9240000000194], 0.12: [22.290000000010266, -17.083999999989125, -6.596000000003991, -19.73599999998384, -5.479000000004586, -3.2220000000031517], 0.14: [1.887000000001302, -34.31799999996792, -14.236999999995232, -35.58899999997033, -10.696999999995223, -12.229000000002966], 0.16: [-16.67199999998326, -44.701999999984565, -20.595999999980112, -40.85599999996743, -31.176999999976807, -20.463999999974533], 0.18: [-26.216999999973414, -46.622999999993844, -29.387999999971495, -48.747000000001115, -37.6759999999721, -36.40099999997183], 0.2: [-19.215999999981573, -48.95600000000188, -38.59499999997069, -42.370999999979055, -45.26999999998688, -42.06299999997248]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8pnki1eCngGQ"},"source":["def eval_scale(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for scale in np.arange(1.0,7.01,0.5):\n","        env = NormalizedEnv(PointMazeEnv(scale))\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(scale, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmUPiWlPqUts","executionInfo":{"status":"ok","timestamp":1616788935216,"user_tz":0,"elapsed":691558,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"bf84e199-3f1f-4656-bc18-004245d9fb68"},"source":["episodes = {}\n","for scale in np.arange(1.0,7.01,0.5):\n","    episodes[np.round(scale, 2)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_scale(agent, episodes)\n","        print(f\"{i} scale: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"scale: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 scale: {1.0: [78.75799999998466], 1.5: [89.74099999998862], 2.0: [86.62299999998672], 2.5: [93.10599999998769], 3.0: [93.0859999999875], 3.5: [91.81299999998505], 4.0: [88.148999999985], 4.5: [85.85799999998679], 5.0: [85.80599999998648], 5.5: [87.48499999997877], 6.0: [86.87399999998206], 6.5: [81.57099999997848], 7.0: [84.72599999997956]}\n","1 scale: {1.0: [78.75799999998466, 51.987999999993434], 1.5: [89.74099999998862, 60.50399999998389], 2.0: [86.62299999998672, 78.52799999998525], 2.5: [93.10599999998769, 85.2079999999852], 3.0: [93.0859999999875, 91.79599999998871], 3.5: [91.81299999998505, 88.90399999998013], 4.0: [88.148999999985, 89.82699999998295], 4.5: [85.85799999998679, 91.81699999998554], 5.0: [85.80599999998648, 87.79699999997958], 5.5: [87.48499999997877, 86.16899999998098], 6.0: [86.87399999998206, 86.98299999998004], 6.5: [81.57099999997848, 86.14699999997943], 7.0: [84.72599999997956, 84.87899999998122]}\n","2 scale: {1.0: [78.75799999998466, 51.987999999993434, 60.42599999999493], 1.5: [89.74099999998862, 60.50399999998389, 79.45299999998349], 2.0: [86.62299999998672, 78.52799999998525, 87.84899999998325], 2.5: [93.10599999998769, 85.2079999999852, 87.52099999998504], 3.0: [93.0859999999875, 91.79599999998871, 87.15699999998347], 3.5: [91.81299999998505, 88.90399999998013, 88.47899999999015], 4.0: [88.148999999985, 89.82699999998295, 91.28699999998635], 4.5: [85.85799999998679, 91.81699999998554, 89.73899999998748], 5.0: [85.80599999998648, 87.79699999997958, 91.344999999989], 5.5: [87.48499999997877, 86.16899999998098, 89.79299999998656], 6.0: [86.87399999998206, 86.98299999998004, 86.91599999998114], 6.5: [81.57099999997848, 86.14699999997943, 88.843999999982], 7.0: [84.72599999997956, 84.87899999998122, 86.32299999998452]}\n","3 scale: {1.0: [78.75799999998466, 51.987999999993434, 60.42599999999493, 73.74099999997844], 1.5: [89.74099999998862, 60.50399999998389, 79.45299999998349, 89.97799999998252], 2.0: [86.62299999998672, 78.52799999998525, 87.84899999998325, 92.56099999998753], 2.5: [93.10599999998769, 85.2079999999852, 87.52099999998504, 92.45799999998715], 3.0: [93.0859999999875, 91.79599999998871, 87.15699999998347, 91.73699999998546], 3.5: [91.81299999998505, 88.90399999998013, 88.47899999999015, 89.63199999998032], 4.0: [88.148999999985, 89.82699999998295, 91.28699999998635, 88.358999999982], 4.5: [85.85799999998679, 91.81699999998554, 89.73899999998748, 90.18799999998231], 5.0: [85.80599999998648, 87.79699999997958, 91.344999999989, 89.72899999998408], 5.5: [87.48499999997877, 86.16899999998098, 89.79299999998656, 87.91799999998068], 6.0: [86.87399999998206, 86.98299999998004, 86.91599999998114, 89.35199999998238], 6.5: [81.57099999997848, 86.14699999997943, 88.843999999982, 84.37799999998192], 7.0: [84.72599999997956, 84.87899999998122, 86.32299999998452, 86.66699999997991]}\n","4 scale: {1.0: [78.75799999998466, 51.987999999993434, 60.42599999999493, 73.74099999997844, 71.27499999997755], 1.5: [89.74099999998862, 60.50399999998389, 79.45299999998349, 89.97799999998252, 92.51799999999197], 2.0: [86.62299999998672, 78.52799999998525, 87.84899999998325, 92.56099999998753, 92.86099999998888], 2.5: [93.10599999998769, 85.2079999999852, 87.52099999998504, 92.45799999998715, 92.25099999998673], 3.0: [93.0859999999875, 91.79599999998871, 87.15699999998347, 91.73699999998546, 93.07299999998557], 3.5: [91.81299999998505, 88.90399999998013, 88.47899999999015, 89.63199999998032, 92.43199999998804], 4.0: [88.148999999985, 89.82699999998295, 91.28699999998635, 88.358999999982, 91.810999999987], 4.5: [85.85799999998679, 91.81699999998554, 89.73899999998748, 90.18799999998231, 91.83099999998618], 5.0: [85.80599999998648, 87.79699999997958, 91.344999999989, 89.72899999998408, 91.6169999999865], 5.5: [87.48499999997877, 86.16899999998098, 89.79299999998656, 87.91799999998068, 89.44399999998176], 6.0: [86.87399999998206, 86.98299999998004, 86.91599999998114, 89.35199999998238, 90.76199999998451], 6.5: [81.57099999997848, 86.14699999997943, 88.843999999982, 84.37799999998192, 87.08999999998092], 7.0: [84.72599999997956, 84.87899999998122, 86.32299999998452, 86.66699999997991, 86.80299999998152]}\n","5 scale: {1.0: [78.75799999998466, 51.987999999993434, 60.42599999999493, 73.74099999997844, 71.27499999997755, 72.19199999998395], 1.5: [89.74099999998862, 60.50399999998389, 79.45299999998349, 89.97799999998252, 92.51799999999197, 88.97299999998562], 2.0: [86.62299999998672, 78.52799999998525, 87.84899999998325, 92.56099999998753, 92.86099999998888, 87.64899999998075], 2.5: [93.10599999998769, 85.2079999999852, 87.52099999998504, 92.45799999998715, 92.25099999998673, 89.18499999998836], 3.0: [93.0859999999875, 91.79599999998871, 87.15699999998347, 91.73699999998546, 93.07299999998557, 89.57299999998654], 3.5: [91.81299999998505, 88.90399999998013, 88.47899999999015, 89.63199999998032, 92.43199999998804, 84.93599999998187], 4.0: [88.148999999985, 89.82699999998295, 91.28699999998635, 88.358999999982, 91.810999999987, 84.72999999998476], 4.5: [85.85799999998679, 91.81699999998554, 89.73899999998748, 90.18799999998231, 91.83099999998618, 87.11999999998645], 5.0: [85.80599999998648, 87.79699999997958, 91.344999999989, 89.72899999998408, 91.6169999999865, 88.6999999999873], 5.5: [87.48499999997877, 86.16899999998098, 89.79299999998656, 87.91799999998068, 89.44399999998176, 85.97599999998413], 6.0: [86.87399999998206, 86.98299999998004, 86.91599999998114, 89.35199999998238, 90.76199999998451, 86.52599999998094], 6.5: [81.57099999997848, 86.14699999997943, 88.843999999982, 84.37799999998192, 87.08999999998092, 84.1119999999792], 7.0: [84.72599999997956, 84.87899999998122, 86.32299999998452, 86.66699999997991, 86.80299999998152, 86.16599999998098]}\n","----\n","scale: {1.0: [78.75799999998466, 51.987999999993434, 60.42599999999493, 73.74099999997844, 71.27499999997755, 72.19199999998395], 1.5: [89.74099999998862, 60.50399999998389, 79.45299999998349, 89.97799999998252, 92.51799999999197, 88.97299999998562], 2.0: [86.62299999998672, 78.52799999998525, 87.84899999998325, 92.56099999998753, 92.86099999998888, 87.64899999998075], 2.5: [93.10599999998769, 85.2079999999852, 87.52099999998504, 92.45799999998715, 92.25099999998673, 89.18499999998836], 3.0: [93.0859999999875, 91.79599999998871, 87.15699999998347, 91.73699999998546, 93.07299999998557, 89.57299999998654], 3.5: [91.81299999998505, 88.90399999998013, 88.47899999999015, 89.63199999998032, 92.43199999998804, 84.93599999998187], 4.0: [88.148999999985, 89.82699999998295, 91.28699999998635, 88.358999999982, 91.810999999987, 84.72999999998476], 4.5: [85.85799999998679, 91.81699999998554, 89.73899999998748, 90.18799999998231, 91.83099999998618, 87.11999999998645], 5.0: [85.80599999998648, 87.79699999997958, 91.344999999989, 89.72899999998408, 91.6169999999865, 88.6999999999873], 5.5: [87.48499999997877, 86.16899999998098, 89.79299999998656, 87.91799999998068, 89.44399999998176, 85.97599999998413], 6.0: [86.87399999998206, 86.98299999998004, 86.91599999998114, 89.35199999998238, 90.76199999998451, 86.52599999998094], 6.5: [81.57099999997848, 86.14699999997943, 88.843999999982, 84.37799999998192, 87.08999999998092, 84.1119999999792], 7.0: [84.72599999997956, 84.87899999998122, 86.32299999998452, 86.66699999997991, 86.80299999998152, 86.16599999998098]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gd2_86AIqOt4"},"source":["def eval_starting_position(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    c = 10\n","\n","    for extra_range in np.arange(0.0, 0.401, 0.05):\n","        \n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            extra = np.random.uniform(-0.1 - extra_range, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = np.random.uniform(0.1, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = extra * (2*np.random.randint(0,2,size=env.starting_point.shape)-1)\n","            env.unwrapped.state = np.array(env.starting_point + extra, dtype=np.float32)\n","            env.unwrapped.state[2] = env.state[2] % (2 * math.pi)\n","            observation = env.normalised_state()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, True, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                    \n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    #goal_done = agent.goal_reached(action, goal)\n","                    goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    if (episode_steps % c) == 0:\n","                        goal_done = True\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[np.round(extra_range, 3)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJjpZcCLqjua","executionInfo":{"status":"ok","timestamp":1616952046175,"user_tz":-60,"elapsed":404922,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"f94067e8-b6e5-476c-86a5-a185d01b5bc3"},"source":["episodes = {}\n","for extra_range in np.arange(0.0, 0.401, 0.05):\n","    episodes[np.round(extra_range, 3)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","env = NormalizedEnv(PointMazeEnv(4))\n","i = 0\n","while i < 6:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_starting_position(agent, episodes)\n","        print(f\"{i} range: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","print(f\"range: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 range: {0.0: [87.05699999998791], 0.05: [86.49299999998384], 0.1: [90.6799999999892], 0.15: [89.1949999999878], 0.2: [86.18899999998126], 0.25: [91.13599999998965], 0.3: [86.67599999998603], 0.35: [91.48799999998477], 0.4: [92.51599999998852]}\n","1 range: {0.0: [87.05699999998791, 91.25199999998551], 0.05: [86.49299999998384, 88.11799999998264], 0.1: [90.6799999999892, 89.6079999999862], 0.15: [89.1949999999878, 92.24599999998654], 0.2: [86.18899999998126, 87.60699999997975], 0.25: [91.13599999998965, 86.10099999998863], 0.3: [86.67599999998603, 90.41699999998096], 0.35: [91.48799999998477, 88.61199999998503], 0.4: [92.51599999998852, 91.3649999999879]}\n","2 range: {0.0: [87.05699999998791, 91.25199999998551, 92.40499999998755], 0.05: [86.49299999998384, 88.11799999998264, 87.24499999998294], 0.1: [90.6799999999892, 89.6079999999862, 92.38199999998497], 0.15: [89.1949999999878, 92.24599999998654, 85.02599999998205], 0.2: [86.18899999998126, 87.60699999997975, 90.4699999999843], 0.25: [91.13599999998965, 86.10099999998863, 90.91699999998426], 0.3: [86.67599999998603, 90.41699999998096, 91.77499999998423], 0.35: [91.48799999998477, 88.61199999998503, 91.22199999998772], 0.4: [92.51599999998852, 91.3649999999879, 93.16399999998757]}\n","3 range: {0.0: [87.05699999998791, 91.25199999998551, 92.40499999998755, 88.00999999998199], 0.05: [86.49299999998384, 88.11799999998264, 87.24499999998294, 89.28799999998256], 0.1: [90.6799999999892, 89.6079999999862, 92.38199999998497, 89.84099999998365], 0.15: [89.1949999999878, 92.24599999998654, 85.02599999998205, 89.36499999998524], 0.2: [86.18899999998126, 87.60699999997975, 90.4699999999843, 90.93199999998461], 0.25: [91.13599999998965, 86.10099999998863, 90.91699999998426, 90.17999999998464], 0.3: [86.67599999998603, 90.41699999998096, 91.77499999998423, 92.41699999998679], 0.35: [91.48799999998477, 88.61199999998503, 91.22199999998772, 90.57799999998417], 0.4: [92.51599999998852, 91.3649999999879, 93.16399999998757, 86.49499999997789]}\n","4 range: {0.0: [87.05699999998791, 91.25199999998551, 92.40499999998755, 88.00999999998199, 90.12499999998306], 0.05: [86.49299999998384, 88.11799999998264, 87.24499999998294, 89.28799999998256, 90.7309999999892], 0.1: [90.6799999999892, 89.6079999999862, 92.38199999998497, 89.84099999998365, 91.29799999998895], 0.15: [89.1949999999878, 92.24599999998654, 85.02599999998205, 89.36499999998524, 90.88899999998986], 0.2: [86.18899999998126, 87.60699999997975, 90.4699999999843, 90.93199999998461, 88.83199999998648], 0.25: [91.13599999998965, 86.10099999998863, 90.91699999998426, 90.17999999998464, 90.63099999998558], 0.3: [86.67599999998603, 90.41699999998096, 91.77499999998423, 92.41699999998679, 92.78599999998829], 0.35: [91.48799999998477, 88.61199999998503, 91.22199999998772, 90.57799999998417, 87.93799999998619], 0.4: [92.51599999998852, 91.3649999999879, 93.16399999998757, 86.49499999997789, 90.2829999999836]}\n","5 range: {0.0: [87.05699999998791, 91.25199999998551, 92.40499999998755, 88.00999999998199, 90.12499999998306, 87.73699999998702], 0.05: [86.49299999998384, 88.11799999998264, 87.24499999998294, 89.28799999998256, 90.7309999999892, 87.80499999998543], 0.1: [90.6799999999892, 89.6079999999862, 92.38199999998497, 89.84099999998365, 91.29799999998895, 85.47599999997855], 0.15: [89.1949999999878, 92.24599999998654, 85.02599999998205, 89.36499999998524, 90.88899999998986, 89.20299999998716], 0.2: [86.18899999998126, 87.60699999997975, 90.4699999999843, 90.93199999998461, 88.83199999998648, 82.4259999999855], 0.25: [91.13599999998965, 86.10099999998863, 90.91699999998426, 90.17999999998464, 90.63099999998558, 88.85499999998694], 0.3: [86.67599999998603, 90.41699999998096, 91.77499999998423, 92.41699999998679, 92.78599999998829, 87.58399999998491], 0.35: [91.48799999998477, 88.61199999998503, 91.22199999998772, 90.57799999998417, 87.93799999998619, 90.68399999998559], 0.4: [92.51599999998852, 91.3649999999879, 93.16399999998757, 86.49499999997789, 90.2829999999836, 90.77899999998083]}\n","----\n","range: {0.0: [87.05699999998791, 91.25199999998551, 92.40499999998755, 88.00999999998199, 90.12499999998306, 87.73699999998702], 0.05: [86.49299999998384, 88.11799999998264, 87.24499999998294, 89.28799999998256, 90.7309999999892, 87.80499999998543], 0.1: [90.6799999999892, 89.6079999999862, 92.38199999998497, 89.84099999998365, 91.29799999998895, 85.47599999997855], 0.15: [89.1949999999878, 92.24599999998654, 85.02599999998205, 89.36499999998524, 90.88899999998986, 89.20299999998716], 0.2: [86.18899999998126, 87.60699999997975, 90.4699999999843, 90.93199999998461, 88.83199999998648, 82.4259999999855], 0.25: [91.13599999998965, 86.10099999998863, 90.91699999998426, 90.17999999998464, 90.63099999998558, 88.85499999998694], 0.3: [86.67599999998603, 90.41699999998096, 91.77499999998423, 92.41699999998679, 92.78599999998829, 87.58399999998491], 0.35: [91.48799999998477, 88.61199999998503, 91.22199999998772, 90.57799999998417, 87.93799999998619, 90.68399999998559], 0.4: [92.51599999998852, 91.3649999999879, 93.16399999998757, 86.49499999997789, 90.2829999999836, 90.77899999998083]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BhvsIWF-qrHj"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def save_trajectories(agent, episode_durations, dirty):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    for i_episode in range(num_episodes):\n","        path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","\n","        if dirty:\n","            g_state = g_state + state_range * noise\n","            g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","        if dirty:\n","            state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","            state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","        episode_steps = 0\n","        overall_reward = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","            path[\"manager\"].append((episode_steps, g_state_.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                path[\"worker\"].append((episode_steps, torch.cat([state_, goal], 1).detach().cpu().squeeze(0).numpy(), action.detach().cpu().squeeze(0).numpy()))\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                noise = torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                if dirty:\n","                    g_next_state = g_next_state + state_range * noise\n","                    g_next_state = torch.max(torch.min(g_next_state, state_max), state_min).float()\n","                if dirty:\n","                    next_state = next_state + state_range * torch.FloatTensor(next_state.shape).uniform_(-l2norm, l2norm).to(device)\n","                    next_state = torch.max(torch.min(next_state, state_max), state_min).float()\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","\n","        path[\"overall_reward\"] = overall_reward\n","        episode_durations[-1].append(path)\n","\n","def save_random_manager(agent, episode_durations):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_points = 10000\n","\n","    c = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    path = {\"overall_reward\": 0, \"manager\": [], \"worker\": []}\n","\n","    for _ in range(num_points):\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        noise = torch.FloatTensor(state.shape).uniform_(0.0, 1.0).to(device)\n","\n","        g_state = state_min + state_range * noise\n","        g_state = torch.max(torch.min(g_state, state_max), state_min).float()\n","\n","        goal = agent.select_goal(g_state, False, False)\n","        path[\"manager\"].append((0, g_state.detach().cpu().squeeze(0).numpy(), goal.detach().cpu().squeeze(0).numpy()))\n","\n","    episode_durations[-1].append(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWeLBDKTP3Ao","executionInfo":{"status":"ok","timestamp":1616493270550,"user_tz":0,"elapsed":38321,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FzBpJhrUOXgzWW4qa9Nf-REhQJ53qmzZVKDvGOA=s64","userId":"08578009112219899929"}},"outputId":"0107b42c-f0dc-4328-af79-819acc958d8a"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 7:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_freeze_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        #save_trajectories(agent, episodes, False)\n","        save_random_manager(agent, episodes)\n","        #print(f\"{i} paths: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","#print(f\"paths: {episodes}\")\n","\n","episodes.pop(1)\n","torch.save(episodes, \"PointMaze_Freeze_manager.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HiiVeensmOuB"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_0\")\n","\n","save_trajectories(agent, episodes, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"lN-lHL7jmRe_","executionInfo":{"status":"ok","timestamp":1616947849418,"user_tz":-60,"elapsed":866,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"01c8f56b-4cbf-4883-9eb9-9d55435ae411"},"source":["i = 0\n","\n","x = [t[1][0] for t in episodes[0][i]['worker']]\n","y = [t[1][1] for t in episodes[0][i]['worker']]\n","\n","x2 = [t[2][0] for t in episodes[0][i]['manager']]\n","y2 = [t[2][1] for t in episodes[0][i]['manager']]\n","\n","plt.scatter(x, y)\n","plt.scatter(x2, y2, c='r')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Y6VhJjD8QHJl"},"source":["def get_intrinsic_reward(agent):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 500\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 10\n","\n","    c = 10\n","\n","    overall_reward = 0\n","    intr_rews = []\n","\n","    for i_episode in range(num_episodes):\n","        cur_intr = []\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_steps = 0\n","        done = False\n","        while not done:\n","            # select a goal\n","            goal = agent.select_goal(g_state, True, False)\n","\n","            goal_done = False\n","            while not done and not goal_done:\n","                action = agent.select_action(state, goal, False, False)\n","                observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","                \n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                next_goal = agent.h(g_state, goal, g_next_state)\n","                                  \n","                overall_reward += reward\n","\n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                episode_steps += 1\n","\n","                #goal_done = agent.goal_reached(action, goal)\n","                cur_intr.append(agent.intrinsic_reward(reward, state, goal, next_state).detach().item())\n","                goal_reached = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                if (episode_steps % c) == 0:\n","                    goal_done = True\n","\n","                state = next_state\n","                g_state = g_next_state\n","                goal = next_goal\n","        intr_rews.append(cur_intr)\n","    print(overall_reward / num_episodes)\n","    return intr_rews"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"SBjnn7HWZTyF","executionInfo":{"status":"ok","timestamp":1616946549902,"user_tz":-60,"elapsed":3103,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"9555ecc8-08f9-4883-ff80-13439c7544f4"},"source":["import matplotlib.pyplot as plt\n","\n","episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 4\n","agent = HIRO(n_observations, n_actions).to(device)\n","load_model(agent, f\"hiro_{i}\")\n","episodes = get_intrinsic_reward(agent)\n","\n","eps = np.array([np.array(l) for l in episodes])\n","#eps = np.mean(eps, 0)\n","\n","plt.plot(eps[1])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["92.47999999999897\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"cpUcYkH1afDr","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1616946584132,"user_tz":-60,"elapsed":1179,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"fd3dc38e-ca55-44ec-fcaa-eaa432d87a4b"},"source":["plt.plot(eps[9])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRc1Z0n8O+v9kVVsi1rs7zICwSMN2xhsGMINIQYQ7CD7UAmmYQs7SSd9PR0p08aOn3S6dCZdELPdPec7hAgC1kIiRe2gAGbAMMSjC0Z7wt4V8mSJVvWvlbVnT+qSq4ISZZc9d67Ve/7OUfHqlKl7i8P6+dbv3fv74pSCkRElP8cVgdARETmYMInIrIJJnwiIptgwicisgkmfCIim3BZHcBIJk6cqCorK60Og4goZ9TU1JxVShUP9TOtE35lZSWqq6utDoOIKGeIyMnhfsaSDhGRTTDhExHZBBM+EZFNMOETEdkEEz4RkU0w4RMR2QQTPhGRTWi9Dt8IDa092FBdi/5Y3OpQTDW1KIg1iyZbHQYRWchWCf+VQ2fwjfW7cb6rHyJWR2Oe1JEHt88th9/jtDYYIrKMLRJ+XzSOH754CD958ziuLA9j41eXYmZxgdVhmebX207iH57eh7aefiZ8IhvL+4R/6lwX/vKJndgdacVnl0zD36+4Ej63vZJeyJf4z9ze04/SsM/iaIjIKnmd8J/bcxr3b9oLEeDHn1mI5XPKrQ7JEmGfGwDQ1hO1OBIislJeJvye/hj+6fcH8MT2U7h66jj833uuxpQJAavDssyFGT4TPpGd5V3Cb+nqw90Pb8PhM+34ykdm4hu3Xg63096rT0PJGX57T7/FkRCRlfIu4Rf63aiqHI/7V1yBGz9UYnU4WuAMn4iAPEz4IoLvfWKu1WFoJeznDJ+IuNPWFoIeJxwCtHVzhk9kZ0z4NiAiKPC6OMMnsjkmfJsI+dys4RPZHBO+TYR8Lq7DJ7I5JnybCPvcLOkQ2RwTvk2EfC6WdIhsjgnfJsJ+N9p7OcMnsrOMEr6IrBWR/SISF5GqEV63XEQOi8gREbkvkzHp0nCGT0SZzvD3AbgLwOvDvUBEnAD+C8BtAGYD+JSIzM5wXBqjVMJXqeb4RGQ7GSV8pdRBpdThi7xsMYAjSqljSqk+AL8FsDKTcWnsQj43YnGFrr6Y1aEQkUXMqOFXAKhNexxJPkcmYj8dGsm7p87ju78/gK4+/v3IZxftpSMiLwMoG+JH31JKPZPtgERkHYB1ADB16tRsv71tpXfMLCvkISj0p7773AG8e6oFeyIt+Om916Aw2X+J8stFZ/hKqVuUUnOG+Bptsq8DMCXt8eTkc8ON94hSqkopVVVcXDzKIehiUjN8br6iwXbVtuDdUy1YflUZdkda8KlHtuFsR6/VYZEBzCjp7ABwmYhMFxEPgHsAPGvCuJQmnHbMIVG6x946jgKvC//6yfl49LNVOHa2A598+G3Ut3ZbHRplWabLMj8hIhEASwA8LyIvJZ+fJCKbAUApFQXwdQAvATgIYL1San9mYdNYhQdKOpzh0wWNbT14fm891lZNRoHXhRs/VIJffuFaNLX1Ys1Db+PE2U6rQ6QsynSVzlNKqclKKa9SqlQp9bHk86eVUivSXrdZKXW5UmqmUup7mQZNYxdiwqchPP7OKUTjCp9bUjnw3OLpE/DEuuvQ3R/D2offxqGGNusCpKziTlubuFDDZ0mHEnqjMTz+zinc9KESVE4M/snP5lQUYv2Xr4NDgLsf3oZdtS0WRUnZxIRvEwGPE06HsIZPAzbvrcfZjl7cu7RyyJ/PKglh41eWotDvxqcf3YaHXjuKN95v4g3dHJZ3RxzS0C4cgsKSDgFKKfz8rROYVVKA6y+bOOzrpkwIYMNXlmDdL6vxgxcPDTxfHPLiirIQZpeHcWV5GPOnjMP0QZ8SSD9M+DbCfjqUsvNUC/ZEWvHAqjkQkRFfWxr24ZmvL0NzZx8O1bfhQH0bDta342B9G37+1gn0xeIAgD984yOYWVxgRvh0iZjwbSTEnviU9NgfTyDkc+Guq0e/6X1C0IOlsyZi6awLnwj6Y3H8fvdp/M363Whs62XC1xxr+DYS5qlXBKChtQcv7K3H3VVTEPRmNudzOx2YkUzy3f38u6U7Jnwb4bm2BACPv3MSMaXw2bSlmJkIepwAgM5eNubTHRO+jYR9LpZ0bK6nP4bfvHMKN19RiqlFgay8ZyD5KYGN1/THhG8jIZ8Lbd1M+Hb2+92nca6zD1/4cGXW3jPg5gw/VzDh20jI50ZHLw9BsSulFB774wlcXlqAJTOLsva+AW8i4Xf3M+HrjgnfRkI+F+IK6OQhKLZUffI89p9uw71Lp190KeZYeJwOuByCzl6WdHTHhG8j6T3xyX4ee+sECv1urLp6UlbfV0QQ8Dh5mloOYMK3kbCfp17ZVUNrD17c34B7rpmCgCf7228CHhdv2uYAJnwb4QzfvjbtjCAWV/jUYmNOkQt4nSwV5gAmfBvhqVf2pJTCxpoIFk+f8IGumNkS9LjQxRq+9pjwbSTMg8xtqfrkeRw/24m1iyYbNoafNfycwIRvI6mSDtfi28uG6loEPU6smFtu2BhBJvycwIRvIyHO8G2nszeK5/fU4/Z55Rn3zRlJwOtCJ2/aao8J30b8bh6CYjeb99ajsy+GtVVTDB0n4HaimzN87THh24iIsCe+zWyoiWD6xCCqpo03dJyg18WNVzmACd9mwuyJbxsnz3Vi+/FmrFk0Oas7a4eS2njFth16Y8K3Gc7w7WNjTQQOAVYvNG51TkrQ60I0rgZOvyI9MeHbDBO+PcTiibX3119WjLJCn+Hj+ZMdM1nH1xsTvs2EfG60saST9946chb1rT1YW2X87B4AgsmOmdxtqzcmfJvhDN8eNtREMC7gxkdnl5oyXqo/D3fb6o0J32bCnOHnvdaufry0vwEr50+C1+U0ZcxA8phDbr7SGxO+zYR8LnT0RhGPczVFvnp2dx36onHD196nS83wuflKb0z4NhP2uaEUfzHz2YaaCK4oC+GqSWHTxkzV8Lt4zKHWmPBthu0V8tvhhnbsibTik1VTDF97n26gpMNjDrXGhG8zF3riM+Hnow3VtXA7BauurjB1XN60zQ1M+DZzYYbPG7f5pj8Wx1Pv1uHmK0oxIegxdezgQA2fM3ydMeHbDEs6+euVQ40419ln2tr7dP5USYczfK1llPBFZK2I7BeRuIhUjfC6EyKyV0R2iUh1JmNSZgZ64nOGn3c2VEdQHPLiI5cXmz62x+WA2yms4Wsu0wbZ+wDcBeDhUbz2JqXU2QzHowyFecxhXmpq78Wrhxvxpeunw+W05oN7gMccai+jhK+UOgjA1NUAlJmwnweZ56On361DLK4MPcbwYoIeHmSuO7OmAgrAFhGpEZF1Jo1JQ/AmP3qzhp8/lFLYUFOLBVPGYVZJyLI4/B4egqK7i87wReRlAGVD/OhbSqlnRjnOMqVUnYiUANgqIoeUUq8PM946AOsAYOrUqaN8exqtxCEo7ImfT/ZEWvHemQ587xNzLI0jyGMOtXfRhK+UuiXTQZRSdck/G0XkKQCLAQyZ8JVSjwB4BACqqqq4/98AbKCWXzbWROB1OfDx+ZMsjSPgcXKnreYML+mISFBEQqnvAdyKxM1esggTfv7o6Y/hmV11WD6nDOHkCiyrBDwudPXz75XOMl2W+QkRiQBYAuB5EXkp+fwkEdmcfFkpgDdFZDeA7QCeV0q9mMm4lJmQlyWdfLH1wBm09USxdpF5jdKGwxm+/jJdpfMUgKeGeP40gBXJ748BmJ/JOJRdIZ8LJ891WR0GZcGGmggqxvmxdGaR1aEg6GENX3fcaWtDvGmbH+pbu/HG+01YvbACDof1S6P9yYPMSV9M+DYU9rOGnw+e3FkHpYDVFq69Txf0JhK+UlxroatMd9pSDgr53OjoSxyCYuXM8Jlddfjhi4fRF4tbFsNwJhZ4semrSwa6QOpGKYUN1bVYPH0CphUFrQ4HQOKmbSyu0BuNw+c256QtGhs9/zaTocI+F5QCOvqilq3s2HbsHP52w258qCyEuRXjLIlhOHUt3Xj9vSacPNeFK8vNO0RkLGpOnseJc1342k2zrA5lQDDtmEMmfD0x4dtQesdMKxL+saYOfPlXNZg6IYDHv3QdCv3WLiccbMeJZrz+XhMa23txZbnV0QxtQ3UEAY8TK+bqE+BAT/y+qOntmWl0WMO3oQuHoJh/4/Z8Zx+++ItqOB2Cn9+7WLtkDwAlIS+AREMyHXX1RfHcntO4fW45gl595mwBLw8y150+f1vINFb1xO+LxvHlX9egrqUbT/z5tZhaFDB1/NGaWKB3wn9hbwM6+2KmHlI+GgOHoLBjprY4w7ehgZ743ebN8JVSuP/Jvdh+vBkPrpmHRdMmmDb2WAW9LgQ9TjS291gdypA21NSisiiAayrHWx3Kn0gdgsIGavpiwrehsAUz/B+9dhSbdkbw17dcjpULzD1v9VKUhH1azvBPnevCtmPNWLNosnZtyXnMof6Y8G3I7Br+c3tO48GXDmPVgkn4Hzfrs6pkJMUFXi0T/sadEYgAdy3UY+19ugs1fJZ0dMWEb0MhE0+92nnqPP5m/W5UTRuPf1k9T7tZ6XCKQ/ol/HhcYVNNBMtmTcSkcX6rw/mAgIc3bXXHhG9DPrcTHqfD8JJOV18U635Zg7KwDw//90U5tTZbx4S/7dg51LV0Y40mO2sHC/CmrfaY8G0q0SLZ2JLOC3sbcLajFz9YPQ9FyZUvuaI45EV7b1SrG5AbayII+Vz42FVDnUdkPc7w9ceEb1Nm9MRPrSa5boa+K3KGU6zZWvyO3ihe2NeAO+ZN0vaTktvpgMfpYMLXGBO+TYV8brQZOMM/ea4T2441Y23VlJyp26cb2HzVocfSzBf21qO7P4Y1i/Re4RTwOnnTVmNM+DZl9Ax/Y00EDgHuWqh3ghqObjP8TTsjmD4xiIVT9Vp7P1jQ40InD0HRFhO+TYUN7IkfiytsrInghsuLUV6o32qS0dAp4dc2J9be33V1hfaflgIezvB1xoRvU0bO8N88chb1rT34pGZb/8eiKOiFQ4BGDRL+kzvrEmvvNV2dky7AQ1C0xoRvU4lTr4xJ+OurazE+4MbNV5YY8v5mcDoERRpsvlJK4cl3I1gyowgVGq69HyzgcXGGrzEmfJsK+Vzo6I0iFs/u6UTnO/uwdf8ZrLq6Al6XnqtJRkuH3bbVJ8/j5LkurNZwZ+1Qgl4na/gaY8K3qdRu244sb5J5Zlcd+mJxrF2Uu+WclOKQ1/KSzqaaRN/75XP0XHs/mN/jQnc/E76umPBtKmxQP5311RHMrSjE7El6nhQ1FiUW77bt7ovh+T31uG2OXn3vRxL0OLnTVmNM+DY10E+nO3u/nPvqWnGgvg1rq3Kj/HAxxSEvznb0Ip7lstdobTnQgPbeqLatFIaSqOFzhq8rJnybCvuzP8PfUF0Lj8uBO+dPytp7Wqk45EU0rnC+q8+S8TfWRFAxzo9rp+fOTuXUskylrPlHkkbGhG9T2T71qqc/hqd3ncbHrirDuEB+nGdaEvIBAJo6zC/rNLT24K0jZ7F6YQUcDr3X3qcLeJ2IK6A3Grc6FBoCE75NDfTE783ODH/rgTNo7e7HJ/OknANYu/nqqXfrEFd69r0fCY851BsTvk1le4a/vroWFeP8WDpzYlbeTwephN/YZm7CV0ph084IqqaNR+XEoKljZ4odM/XGhG9T2Uz4p1u68eaRs1i9aDKcOVR+uJgLDdTMTfi7I6040tiRUzdrU1I98Znw9cSEb1NelxMelyMrHTM31USgFLA2BxPUSIJeFwIep+klnU01EXhdDqyYV27quNmQOuawk7tttcSEb2PhLPTTiccVNtREsHRmEaZMCGQpMn2YvfmqNxrDs7sTN79TeyVySaqG38XdtlpiwrexsM+Ntu7MZvjvHG/GqeaunG6UNpLE5ivzeuK/crARrd39WJ2jn5Yu1PA5w9cRE76NZaNj5k/fPI6QV99j9zJl9tm2m3ZGUBr2Ytms3Lz5zZu2esso4YvIgyJySET2iMhTIjJumNctF5HDInJERO7LZEzKnlCGPfFf2t+Alw+ewVdvmgm/J7cbpQ2nuMC8kk5jew9ePdyEVVdX5OzN71QLCNbw9ZTpDH8rgDlKqXkA3gNw/+AXiIgTwH8BuA3AbACfEpHZGY5LWZDJDL+9px/ffmYfriwP48+vn5HlyPRREvahvSeKHhMagj39bh1icZXT5bHUP/w6Hf5OF2SU8JVSW5RSqYyxDcBQhcfFAI4opY4ppfoA/BbAykzGpezIJOH/8MXDaGzvxb/cNRduZ/5WBosLzNl8pZTC+uoIFk0bj5nFBYaOZaRA8oB1tkjWUzZ/U78A4IUhnq8AUJv2OJJ8bkgisk5EqkWkuqmpKYvh0WCXWtKpOdmMX79zEvcurcT8KUNW8fLGwOYrgxP+rtoWHGnsyPmlrS6nA16XgzdtNXXRhC8iL4vIviG+Vqa95lsAogAezzQgpdQjSqkqpVRVcXFxpm9HIwj5XOjsi43pEJTeaAz3bdqLSYV+/O2tHzIwOj2Y1V5hfXUEfrcTt+fg2vvBeMyhvi7aZFspdctIPxeRewHcAeBmNXSLvDoA6UXJycnnyGKpfjodPVEUBka35vvHrx3D+40d+Pm91+RMj/ZMmLHbtrsvhud2n8Ztc8sG/pvksoDHxZu2msp0lc5yAN8EcKdSqmuYl+0AcJmITBcRD4B7ADybybiUHeFUT/xRlnWONHbgv149go/Pn4Sbrsjd82rHYkLQAxGgqc24tfgv7q9He280p2/Wpgt6ndx4palMa/j/CSAEYKuI7BKRHwOAiEwSkc0AkLyp+3UALwE4CGC9Ump/huNSFqRmk6NJ+PG4wt8/uRd+jxPfvsM+i6xcTgeKgl5DZ/jrd0QwrSiQU33vR8IZvr4y+kyulJo1zPOnAaxIe7wZwOZMxqLsC4+hgdpvd9Ri+4lm/HD1vIG6tl0YufmqtrkLbx87h2989HKI5Oba+8ECHieXZWoqf9fT0UUN9MS/SMJvbOvB9184iCUzivLm+MKxMLKfzoaaCESQs60UhpKY4TPh64gJ38YutEgeuaTznd/vR280jv9119y8mYWOhVGHmcfjCptqIlg2ayImjfNn/f2tEvQ6uSxTU0z4NjaanvjvHDuHzXsb8Fc3X4bpOXYYR7YYdZj5H4+eQ11Ld97crE3hskx9MeHb2IWSzvAz/N9V1yLkdeGLy6abFZZ2igu86I8ptGTYWXSw9dW1CPtc+Ojs0qy+r9UCHhe6eMShlpjwbczjcsDndgw7w+/ojeKFvQ24Y/4k+Nz52RxtNErC2d981drVjxf3N2DV1RV5d22DHie6+mMYelsOWYkJ3+ZCPvewyzI3761Hd38MaxYN2wnDFozop/PsntPoi8axdlF+lXMAwO9xQSmgpz9udSg0CBO+zYV8LrQNM8PfWBPB9IlBLJw63uSo9HKhn072Nl9trK7FFWUhzKkIZ+09dRHkMYfaYsK3uUQDtQ/+Yp4614Xtx5uxZtFkW67MSVcS9gHI3gz/UEMbdkdasbZqSl5e2wCPOdQWE77NJc61/WBJZ9POxPrwT1xt73IOkKhJ+93ZO8x8Q3UEbqdg1YJJWXk/3aROveIMXz9M+DY3VE/8eFxh084IPjwzv9aHXyoRydrmq75oHE+/W4dbrixFUUF+7ljmMYf6YsK3uZD3gz3x3znejMj5bqzJo92fmcrW5qtXDjXiXGdfXu9YTnVR5eYr/TDh21zY/8EZ/qadERTk8cHkl6I4lJ0Gahuqa1ES8uKGy/L3rIeBkg5r+Nphwre5kM+Nrr4YorHEErrO3ig2763HHfPK8/Zg8ktRHPKiMcMWyWfaevDq4UasXjQZrjw+FjJ107a7nzN83eTv3zoalcHtFV7Y14CuvhjLOYOUhLxoy/Aw8401EcQV8q6VwmBBzvC1xYRvc4M7Zm6sqUVlUQCLptl77f1gqbX4Zy+xrKOUwobqWiyePiHvexIFWMPXFhO+zYXSTr2qbe7CtmPNWL2Qa+8Hy/Qw83eON+PEuS7cneezewDwu7lKR1f5fygpjSi9pPOHg40QAe5iOecDSkKZbb5avyPRhG7F3Nw/pPxinA6Bz+1gwtcQZ/g2F0475nDjzlosnVmECq69/4DUDP9SEn5bTz8276vHxxdMss2N8KDHhU52zNQOE77NpWb4rxxsRG1zN1Yv5Ox+KAOHmV9Cwn9212n09MdtUc5J8fOYQy0x4dtcaob/9K46BD1OLJ/DtfdDcTsdmBDwXFINf32yUdq8yYUGRKanIA8y1xJr+DZXkJzh90bjWFk1eWANNX3QpRxmfrC+DXsirfj2HbNtdSM84NX/1Ku9kVY8vavOkrF9bge+8pGZA6vkzMLfbptzOx3wu53Jvvf2KTlcikvZbfu7HbXwOB22a0Knew3/fGcfPv/YdrR298PrMve+SlwpdPXFMLu8ELfPM/cmPhM+IeRzoTjkxTWVXHs/kuKQF0cbO0b9+t5oDE/vqsNHryrF+KDHwMj04/c4L3nPghm+t/kgWrr68ezXl2H2JHPPJGjt6sf8725BfWu3qeMCTPgE4EvXT8fUCUFblRwuRUnIh6aOXiilRnWttuw/g5auflvdrE0JanyQ+Zvvn8XGmgi+dtNM05M9kOhf5XM7cCbDVh2XggmfsO6GmVaHkBOKQ4nDzFu7+zEucPEZ+/rqWlSM82PZrIkmRKeXgNel5U7brr4o7n9qD2ZMDOIv/+wyS2IQEZQX+lHfan7C5yodolEay27byPkuvHnkLNYsmgyHw36fnAJuPWf4/7b1PdQ2d+P7d8219PD40rDXkhk+Ez7RKJWMYfPVxpoIAOR13/uRJGb4McTjyupQBuyJtOCnbx7Hf7t2Kq6dUWRpLJzhE2lutLtt43GFDdURLJs1EZPHB8wITTupjpndGXQXzab+WBzf3LgHxSEv7rvtCqvDQWnYhzNtPab/g8iETzRKF0o6I8/M3jp6FnUt3XnfBnkkuh1z+Mjrx3CooR0PrJwzsNnQSuWFPvTHFJq7+kwdlwmfaJRC3sTqiovN8H+3oxbjAm7celWpSZHpJ7WBT4cbt8eaOvAff3gfK+aW4VZNTnErDSea8TWYXNZhwicapdRh5iMl/Ma2HmzZfwarFlSYvqFHJ0GvHoegxOMK9z25Fz6XA9+58ypLY0lXXsiET6S94gLvsKt0lEokFxHgc0srzQ1MM35Njjn87Y5abD/ejH+4ffZAi2sdlCUTfr3JK3UySvgi8qCIHBKRPSLylIiMG+Z1J0Rkr4jsEpHqTMYkslJJyDfsDP+J7bV45VAj7r/tirw/1epidDjmsLG9B9/ffBBLZxZpt1pqYoEXTofgTI7N8LcCmKOUmgfgPQD3j/Dam5RSC5RSVRmOSWSZ4frpnDjbiQeeO4DrL5uIzy6pND8wzehQw//1tlPo6IvigVVztNtF7nQISkNe05dmZpTwlVJblFKp/6LbAOj1zyhRlhWHvGjp6kdv9MLMNRqL46/X74LH5cCDa+bbcqPVYFbX8PuicTyx/RRuvLwYM4sLLInhYkoLfaZvvspmDf8LAF4Y5mcKwBYRqRGRdSO9iYisE5FqEaluamrKYnhEmSsZOMz8wnK6h147indPteCfV80ZqM3aXepkry6L1uFvOdCApvZerT9tlRf6TG+gdtGELyIvi8i+Ib5Wpr3mWwCiAB4f5m2WKaUWArgNwNdE5IbhxlNKPaKUqlJKVRUXF4/x/w6RsQZvvtoTacF//OF93Dl/Ej4+f5KVoWklmCrpWNQi+Zdvn8SUCX7ccLm+OaQ07DN9lc5Fm6cppW4Z6ecici+AOwDcrJQactuYUqou+WejiDwFYDGA18ccLZHFBjZftfWguy+Gv/7dLkws8OKBlXMsjkwv/mSfmk4LNl4damjD9uPNuP+2K+DUuLxWXuhDZ18M7T39ph2EkukqneUAvgngTqVU1zCvCYpIKPU9gFsB7MtkXCKrpJb2NXX04gcvHsLRpk7869r5KAxYv3tTJw6HJA7WseCm7a+3nYTH5dB+p7MVm68yreH/J4AQgK3JJZc/BgARmSQim5OvKQXwpojsBrAdwPNKqRczHJfIEkUFibbIz+w6jcf+eAKf/3Alll1mv/bHoxH0Ok2f4bf39OOpnXX4+LxJ2h86U17oBwA0mHjjNqN++EqpWcM8fxrAiuT3xwDMz2QcIl24nQ5MCHqw/XgzZpUU4O+WW9+IS1cBj8v0Gv6TO+vQ2RfDZ5dMM3XcS1GWnOGbuTSTO22Jxqgk5IXLIfj3uxdY2lNddwGTT71SSuFX205i/uRCzJ8y5B5QrZSEE/eDzNx8xROviMboqzcmTgibU1FocSR6Mzvhv33sHI40duDBNfNMGzMTPrcTE4IeU9srMOETjdHKBRVWh5ATgl4XOkws6fzq7ZMYF3Dn1PLYsrDP1Bk+SzpEZIiAx4kuk3baNrT2YMuBM7i7akpOldkSm6+Y8IkoxwU8LnSZ1C3zN9tPIa4UPn2t/jdr05UW+kxdpcOET0SGMGuGn943Z2pRbh0pWR72obmzDz0mtaBgwiciQwS9LnSasPEqF/rmDKc02XupsW3kU9SyhQmfiAzhdzvR0x9HzOCDunOhb85wBk6+Mqmsw4RPRIZItUjuNrBckeqb85lrp2ndN2c4FzZfmdM1kwmfiAwRMKFjZq70zRlOqp22WX3xmfCJyBCBVE98gzZfNXf2YVNNHe6cr3/fnOGEfG4EPU7TlmYy4RORIVIzfKNu3D721nF098fw5RtmGPL+Zikz8eQrJnwiMkSqhm/EDL+jN4rH/ngCt84uxWWloay/v5nKTNx8xYRPRIYwsqTzm3dOoq0nir+4aciGvTmlLOw3rb0CEz4RGcKom7a90Rh+8sZxLJ1ZhAU50BXzYsoKvTjT3mv48lWACZ+IDBIcqOFnd4a/qaYOje29+FoezO4BoKzQj1hc4WyH8ZuvmPCJyBCBgRp+9mb40VgcD79+FPMnF2LpzKKsva+Vyk086pAJn4gMYUQNf/O+Bjw3rjwAAAoKSURBVJw814Wv3jgLIrm30WooqbX4Zty4ZcInIkP4XE6IZK+Gr5TCj149glklBbh1dmlW3lMHZm6+YsInIkM4HIKAO3sHmb96uBGHGtrxlY/MhCMH2ygMZ0LAA7dTOMMnotzm97iyVtL50atHUTHOj5ULcudEq9FwOASlYXM2XzHhE5Fhgl5nVm7abj/ejOqT57HuhhlwO/MvbZWFfaY0UMu/K0dE2gh4XOjMwiEoP3rtCIqCnpxtknYxifYKXJZJRDks4HGiO8NjDvefbsVrh5vwhWXT4ffkznm1Y5Ga4Stl7OYrJnwiMkzA48x4hv/Qa0dR4HXhM9fl1nm1Y1FW6ENPfxyt3f2GjsOET0SGCXpcGdXw3z/Tjs176/GZ66ah0O/OYmR6KTPp5CuXoe9ORLYW8DovaZVOQ2sPfvz/juI3208h4HHhC8sqsx+cRsrTNl9dURY2bBwmfCIyTMAztoTf0NqDh147gid21CIeV1i9cDK+dtMslIR8BkZpvbJCPwAY3jWTCZ+IDBP0uNA5ip229a3deOi1o/jt9lrElcKaRYlEP2VCwIQorVcS8kLE+PYKTPhEZJiAx4XeaByxuBrykPF4XOH7LxzEL/54EnGlsLZqMv7iRvsk+hS304GJBV7DN18x4RORYS40UIsi5PvgTdfX3mvEo28cx6oFk/CNWz9ku0SfLrE0kwmfiHJUIO2Yw6ES/qOvH0d5oQ8Prp2flztox6Ks0Ifa5i5Dx8j4CovIAyKyR0R2icgWERmy0YWIfE5E3k9+fS7TcYlIfwOHoAxRx99X14q3j53D5z9caftkD5gzw8/GVX5QKTVPKbUAwHMAvj34BSIyAcA/ArgWwGIA/ygi47MwNhFpzD9CT/yfvHEMQY8T9yyeanZYWior9KG1ux/dBpwBnJJxwldKtaU9DAIYam/wxwBsVUo1K6XOA9gKYHmmYxOR3lIz/MEJv761G8/tqcfd10xFeIhSjx2VhY3ffJWVz1Ei8j0RqQXwaQwxwwdQAaA27XEk+dxQ77VORKpFpLqpqSkb4RGRRVI1/M5Bu20fe+sE4krh8x+utCAqPV3YfGVc18xRJXwReVlE9g3xtRIAlFLfUkpNAfA4gK9nEpBS6hGlVJVSqqq4uDiTtyIii6VW6aSXKTp6o/jN9lO4bW65rVflDFZqwslXo1qlo5S6ZZTv9ziAzUjU69PVAbgx7fFkAK+N8j2JKEcNddN2/Y5atPdE8efXz7AqLC2lSjpG3rjNxiqdy9IergRwaIiXvQTgVhEZn7xZe2vyOSLKY4MPMo/G4vjZW8dxTeV4LJgyzsrQtBP0uhD2uQxtr5CNGv6/JMs7e5BI5H8FACJSJSI/AQClVDOABwDsSH59N/kcEeWxoDc5w0/W8F/afwaR89344jLO7odSVmjs0syMN14ppVYP83w1gC+lPf4ZgJ9lOh4R5Q6vywGRRA1fKYVH3ziGaUUBfHR2qdWhaams0G9oDZ+7HYjIMCKSbKAWQ83J89hV24IvLps+ZF8dAsrCXr1r+EREI0m0SI7i0TeOodDvxppFk60OSVtlhX40dfSiPxY35P2Z8InIUAGPEwcb2rHlwBl85rqpCHjYwms4ZWEflAKa2o050JwJn4gMFfC4sLu2BS6H4LNLKq0OR2vpJ18ZgQmfiAwVTO62vXN+BUrD+X1yVaZS18eoG7dM+ERkKH+yhPOl66dbHIn+jJ7hs5hGRIb6yOXFmDrBjyvLjTucO1+MC7jhcTkMm+Ez4RORob64jDP70RIRlBu4+YolHSIijZSFfYa1V2DCJyLSSFmhD/VtxrRIZkmHiEgj180ogs/lNOS9mfCJiDTyqcVT8SmDjn1kSYeIyCaY8ImIbIIJn4jIJpjwiYhsggmfiMgmmPCJiGyCCZ+IyCaY8ImIbEKUUlbHMCwRaQJw8hL/5xMBnM1iONnCuMaGcY0N4xqbfIxrmlKqeKgfaJ3wMyEi1UqpKqvjGIxxjQ3jGhvGNTZ2i4slHSIim2DCJyKyiXxO+I9YHcAwGNfYMK6xYVxjY6u48raGT0REfyqfZ/hERJSGCZ+IyCbyLuGLyHIROSwiR0TkPqvjSRGREyKyV0R2iUi1xbH8TEQaRWRf2nMTRGSriLyf/HO8JnF9R0Tqktdtl4isMDmmKSLyqogcEJH9IvJXyectvV4jxGXp9UrG4BOR7SKyOxnbPyWfny4i7yR/N38nIh5N4npMRI6nXbMFZsaVjMEpIu+KyHPJx8ZcK6VU3nwBcAI4CmAGAA+A3QBmWx1XMrYTACZaHUcylhsALASwL+25HwK4L/n9fQB+oElc3wHwtxZeq3IAC5PfhwC8B2C21ddrhLgsvV7JeARAQfJ7N4B3AFwHYD2Ae5LP/xjAVzWJ6zEAayy+Zn8D4DcAnks+NuRa5dsMfzGAI0qpY0qpPgC/BbDS4pi0o5R6HUDzoKdXAvhF8vtfAFhlalAYNi5LKaXqlVI7k9+3AzgIoAIWX68R4rKcSuhIPnQnvxSAPwOwMfm8FddsuLgsJSKTAdwO4CfJxwKDrlW+JfwKALVpjyPQ5JcAib9YW0SkRkTWWR3MEEqVUvXJ7xsAlFoZzCBfF5E9yZKP6aWmFBGpBHA1EjNDba7XoLgADa5XskSxC0AjgK1IfPJuUUpFky+x5HdzcFxKqdQ1+17ymv2biHhNDuvfAXwTQDz5uAgGXat8S/g6W6aUWgjgNgBfE5EbrA5oOCrxOdLymU/SQwBmAlgAoB7A/7YiCBEpALAJwP9USrWl/8zK6zVEXFpcL6VUTCm1AMBkJD55X2FFHIMNjktE5gC4H4n4rgEwAcDfmRWPiNwBoFEpVWPGePmW8OsATEl7PDn5nOWUUnXJPxsBPIXEL4FOzohIOQAk/2y0OB4AgFLqTPKXNA7gUVhw3UTEjURSfVwp9WTyacuv11Bx6XC90imlWgC8CmAJgHEi4kr+yNLfzbS4lifLY0op1Qvg5zD3mn0YwJ0icgKJEvSfAfgPGHSt8i3h7wBwWfIOtwfAPQCetTgmiEhQREKp7wHcCmDfyP8r0z0L4HPJ7z8H4BkLYxmQSqpJn4DJ1y1ZT/0pgINKqf+T9iNLr9dwcVl9vZIxFIvIuOT3fgAfReIew6sA1iRfZsU1GyquQ2n/cAsStXLTrplS6n6l1GSlVCUS+eoVpdSnYdS1svLOtBFfAFYgsWLhKIBvWR1PMqYZSKwY2g1gv9VxAXgCiY/7/UjUB7+IRN3wDwDeB/AygAmaxPUrAHsB7EEiyZabHNMyJMo1ewDsSn6tsPp6jRCXpdcrGds8AO8mY9gH4NvJ52cA2A7gCIANALyaxPVK8prtA/BrJFfyWHDdbsSFVTqGXCu2ViAisol8K+kQEdEwmPCJiGyCCZ+IyCaY8ImIbIIJn4jIJpjwiYhsggmfiMgm/j9M2tCb1pfbiAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"cRU_1X7VhDVh"},"source":[""],"execution_count":null,"outputs":[]}]}