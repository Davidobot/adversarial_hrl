{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"td3_pointfall.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"id":"QM04UTO98Nf2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618902854732,"user_tz":-60,"elapsed":15472,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"df0ab1fb-bad3-4e09-fdd3-91be09013919"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!cp \"/content/drive/My Drive/Dissertation/envs/point_fall.py\" ."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4bwBIEXm8gt7","executionInfo":{"status":"ok","timestamp":1618903012393,"user_tz":-60,"elapsed":1085,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# for inference, not continued training\n","def save_model(model, name):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_fall/{name}\" \n","\n","    torch.save({\n","      'controller': {\n","          'critic': model.critic.state_dict(),\n","          'actor': model.actor.state_dict(),\n","      }\n","    }, path)\n","\n","import copy\n","def load_model(model, name):\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/point_fall/{name}\" \n","    checkpoint = torch.load(path)\n","\n","    model.critic.load_state_dict(checkpoint['controller']['critic'])\n","    model.critic_target = copy.deepcopy(model.critic)\n","    \n","    model.actor.load_state_dict(checkpoint['controller']['actor'])\n","    model.actor_target = copy.deepcopy(model.actor)\n","\n","    model.eval()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1618902858409,"user_tz":-60,"elapsed":6628,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1618902858411,"user_tz":-60,"elapsed":6352,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1618902858415,"user_tz":-60,"elapsed":5654,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["from point_fall import PointFallEnv \n","env = NormalizedEnv(PointFallEnv(4))"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"DQtcj2j8Erv4","executionInfo":{"status":"ok","timestamp":1618902858420,"user_tz":-60,"elapsed":5178,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def plot_durations(episode_durations, actions):\n","    fig, axs = plt.subplots(2, figsize=(10,10))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","\n","    durations_t, durations = list(map(list, zip(*actions)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    axs[1].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1618902858425,"user_tz":-60,"elapsed":4984,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1618902858428,"user_tz":-60,"elapsed":4828,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1618902858432,"user_tz":-60,"elapsed":4653,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1618902858437,"user_tz":-60,"elapsed":1908,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, 128)\n","        self.fc2 = nn.Linear(128, 128)\n","        self.head = nn.Linear(128, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, 128)\n","        self.l2 = nn.Linear(128, 128)\n","        self.l3 = nn.Linear(128, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, 128)\n","        self.l5 = nn.Linear(128, 128)\n","        self.l6 = nn.Linear(128, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1618902859111,"user_tz":-60,"elapsed":2225,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000)\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 10000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            \n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, self.tau)\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup, decay_epsilon):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,1)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI","executionInfo":{"status":"ok","timestamp":1618902859114,"user_tz":-60,"elapsed":1552,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["import time\n","SAVE_OFFSET = 6\n","\n","def train_model():\n","    global SAVE_OFFSET\n","\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = TD3(n_observations, n_actions).to(device)\n","    \n","    max_episode_length = 500\n","    \n","    agent.is_training = True\n","    episode_reward = 0.\n","    observation = None\n","    \n","    warmup = 200\n","    num_episodes = 4000 # M\n","    episode_durations = []\n","    actions = [(0,0)]\n","\n","    steps = 0\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        episode_steps = 0\n","        done = False\n","        while not done:        \n","            # agent pick action ...\n","            action = agent.select_action(state, i_episode <= warmup, True)\n","\n","            # env response with next_observation, reward, terminate_info\n","            action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","            observation, reward, done, info = env.step(action_i)\n","            steps += 1\n","\n","            #actions.append((steps, action_i[0]))\n","                \n","            if max_episode_length and episode_steps >= max_episode_length - 1:\n","                done = True\n","            episode_steps += 1 \n","                \n","            extrinsic_reward = torch.tensor([reward], device=device)\n","            \n","            overall_reward += reward\n","            \n","            next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            # agent observe and update policy\n","            agent.observe(state, action, next_state, extrinsic_reward, done)           \n","            state = next_state\n","            \n","            if i_episode > warmup:\n","                agent.update_policy()\n","\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations, actions)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0:\n","                print(f\"{i_episode}: {np.mean(dur[-100:])}\")\n","            if i_episode >= 400 and i_episode % 100 == 0 and np.mean(dur[-100:]) <= -49.0:\n","                print(f\"Unlucky after {i_episode} eps! Terminating...\")\n","                return None\n","            if np.mean(dur[-100:]) >= 90:\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"td3_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","    return None"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrKiOTksSvYo"},"source":["i = 0\n","while i < 17:\n","    agent = train_model()\n","    \n","    if agent is not None:\n","        print(i)\n","        i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewRAF108B9Ia"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def eval_model(agent, episode_durations):\n","    agent.eval()\n","    agent.is_training = False\n","\n","    max_episode_length = 500\n","    num_episodes = 100\n","\n","    for noise in np.arange(0,0.51,0.05):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","            # unsqueeze adds batch dimension\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                state = state + state_range * torch.FloatTensor(state.shape).uniform_(-noise, noise).to(device)\n","                state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","                action = agent.select_action(state, False, False)\n","                action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","                observation, reward, done, info = env.step(action_i) \n","                \n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                \n","                episode_steps += 1 \n","\n","                overall_reward += reward\n","\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_durations[np.round(noise, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgdtuIjSK-Aa","executionInfo":{"status":"ok","timestamp":1618902869516,"user_tz":-60,"elapsed":6875,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}}},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def fgsm_attack(data, eps, data_grad):\n","    sign_data_grad = data_grad.sign()\n","\n","    perturbed_data = data - eps * sign_data_grad * state_range\n","\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\n","\n","    return clipped_perturbed_data\n","\n","def fgsm_action(state, agent, eps, target, targeted):\n","    state = state.clone().detach().requires_grad_(True)\n","\n","    if targeted:\n","        # initial forward pass\n","        action = agent.actor(state)\n","        action = torch.clamp(action, -1., 1.)\n","\n","        loss = F.mse_loss(action, target)\n","    else:\n","        loss = agent.critic.Q1(state, agent.actor(state)).mean()\n","\n","    agent.actor.zero_grad()\n","    agent.critic.zero_grad()\n","\n","    # calc loss\n","    loss.backward()\n","    data_grad = state.grad.data\n","    # perturb state\n","    state_p = fgsm_attack(state, eps, data_grad).float()\n","    return agent.select_action(state_p, False, False)\n","\n","def apply_fgsm(agent, episode_durations, targeted):\n","    TARGET_ACTION = torch.tensor([[0.0, 0.0]], device=device, dtype=torch.float)\n","\n","    agent.eval()\n","\n","    max_episode_length = 500\n","    agent.is_training = False\n","\n","    num_episodes = 100\n","\n","    for eps in np.arange(0.0, 0.201, 0.02):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","            # unsqueeze adds batch dimension\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                action = fgsm_action(state, agent, eps, TARGET_ACTION, targeted)\n","                action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","                observation, reward, done, info = env.step(action_i)\n","                \n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                \n","                episode_steps += 1 \n","\n","                overall_reward += reward\n","\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wfh59tBCA--"},"source":["def plot_norms(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\n","    \n","    plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","    plt.xlabel('L2 Norm')\n","    plt.ylabel('Average Reward')\n","    \n","    mu = np.mean(ys, axis=1)\n","    plt.plot(x, mu)\n","    stds = np.std(ys, axis = 1)\n","    plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jazaVnJNErwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618914365767,"user_tz":-60,"elapsed":11336857,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"242a800b-c27d-4d54-f080-c627596df45e"},"source":["episodes = {}\n","for l2norm in np.arange(0,0.51,0.05):\n","    episodes[np.round(l2norm, 2)] = []\n","\n","fgsm_t = {}\n","fgsm_ut = {}\n","for eps in np.arange(0.0, 0.201, 0.02):\n","    fgsm_t[eps] = []\n","    fgsm_ut[eps] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","\"\"\"\n","i = 0\n","while i < 11:\n","    #agent = train_model()\n","    agent = TD3(n_observations, n_actions).to(device)\n","    load_model(agent, f\"td3_{i}\")\n","\n","    if agent is not None:\n","        eval_model(agent, episodes)\n","        print(f\"{i} noise: {episodes}\")\n","        i += 1\n","\n","print(\"---\")\n","print(f\"noise: {episodes}\")\n","\"\"\"\n","\n","for i in [0, 1, 2, 3, 4]:\n","    #agent = train_model()\n","    agent = TD3(n_observations, n_actions).to(device)\n","    load_model(agent, f\"td3_{i}\")\n","\n","    if agent is not None:\n","        apply_fgsm(agent, fgsm_t, True)\n","        apply_fgsm(agent, fgsm_ut, False)\n","        print(f\"{i} fgsm (t): {fgsm_t}\")\n","        print(f\"{i} fgsm (ut): {fgsm_ut}\")\n","        i += 1\n","\n","print(\"---\")\n","print(f\"fgsm (t): {fgsm_t}\")\n","print(f\"fgsm (ut): {fgsm_ut}\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["0 fgsm (t): {0.0: [97.80999999999597], 0.02: [-41.63899999997277], 0.04: [-17.889999999986298], 0.06: [-17.354999999987832], 0.08: [-35.579999999974106], 0.1: [-42.07299999997629], 0.12: [-44.86999999998728], 0.14: [-47.228999999994684], 0.16: [-48.62800000000068], 0.18: [-48.97400000000308], 0.2: [-48.68700000000204]}\n","0 fgsm (ut): {0.0: [97.56799999999632], 0.02: [54.48399999998769], 0.04: [-14.542999999999903], 0.06: [2.544999999997841], 0.08: [3.281999999994613], 0.1: [-20.574999999984144], 0.12: [-31.809999999971534], 0.14: [-38.66899999997551], 0.16: [-45.171999999987094], 0.18: [-50.00000000000659], 0.2: [-47.69399999999638]}\n","1 fgsm (t): {0.0: [97.80999999999597, 95.60599999999312], 0.02: [-41.63899999997277, -46.795999999996745], 0.04: [-17.889999999986298, -34.43199999997088], 0.06: [-17.354999999987832, -36.16599999996913], 0.08: [-35.579999999974106, 9.039999999998228], 0.1: [-42.07299999997629, -0.01799999999945533], 0.12: [-44.86999999998728, -22.303999999976803], 0.14: [-47.228999999994684, -34.16899999997636], 0.16: [-48.62800000000068, -35.36999999997106], 0.18: [-48.97400000000308, -34.483999999974365], 0.2: [-48.68700000000204, -39.939999999970325]}\n","1 fgsm (ut): {0.0: [97.56799999999632, 96.12699999999285], 0.02: [54.48399999998769, -50.00000000000659], 0.04: [-14.542999999999903, -34.288999999973285], 0.06: [2.544999999997841, -41.71199999998082], 0.08: [3.281999999994613, -47.29399999999947], 0.1: [-20.574999999984144, -43.32699999998117], 0.12: [-31.809999999971534, -40.5569999999677], 0.14: [-38.66899999997551, -37.04499999997367], 0.16: [-45.171999999987094, -43.434999999984235], 0.18: [-50.00000000000659, -42.163999999973754], 0.2: [-47.69399999999638, -36.695999999973616]}\n","2 fgsm (t): {0.0: [97.80999999999597, 95.60599999999312, 96.29599999999607], 0.02: [-41.63899999997277, -46.795999999996745, 25.883000000016406], 0.04: [-17.889999999986298, -34.43199999997088, -50.00000000000659], 0.06: [-17.354999999987832, -36.16599999996913, -50.00000000000659], 0.08: [-35.579999999974106, 9.039999999998228, -48.70600000000097], 0.1: [-42.07299999997629, -0.01799999999945533, -50.00000000000659], 0.12: [-44.86999999998728, -22.303999999976803, -50.00000000000659], 0.14: [-47.228999999994684, -34.16899999997636, -50.00000000000659], 0.16: [-48.62800000000068, -35.36999999997106, -48.69100000000091], 0.18: [-48.97400000000308, -34.483999999974365, -46.56499999999704], 0.2: [-48.68700000000204, -39.939999999970325, -46.073999999989574]}\n","2 fgsm (ut): {0.0: [97.56799999999632, 96.12699999999285, 97.7649999999959], 0.02: [54.48399999998769, -50.00000000000659, 91.97399999999088], 0.04: [-14.542999999999903, -34.288999999973285, -18.64199999998474], 0.06: [2.544999999997841, -41.71199999998082, -44.233999999982736], 0.08: [3.281999999994613, -47.29399999999947, -42.952999999977536], 0.1: [-20.574999999984144, -43.32699999998117, -43.2729999999786], 0.12: [-31.809999999971534, -40.5569999999677, -44.30099999998311], 0.14: [-38.66899999997551, -37.04499999997367, -47.17099999999447], 0.16: [-45.171999999987094, -43.434999999984235, -47.541000000000366], 0.18: [-50.00000000000659, -42.163999999973754, -47.178999999995504], 0.2: [-47.69399999999638, -36.695999999973616, -46.5089999999957]}\n","3 fgsm (t): {0.0: [97.80999999999597, 95.60599999999312, 96.29599999999607, 97.94299999999623], 0.02: [-41.63899999997277, -46.795999999996745, 25.883000000016406, 40.34400000001263], 0.04: [-17.889999999986298, -34.43199999997088, -50.00000000000659, -37.394999999971034], 0.06: [-17.354999999987832, -36.16599999996913, -50.00000000000659, -43.10899999998151], 0.08: [-35.579999999974106, 9.039999999998228, -48.70600000000097, -45.8129999999909], 0.1: [-42.07299999997629, -0.01799999999945533, -50.00000000000659, -45.909999999997446], 0.12: [-44.86999999998728, -22.303999999976803, -50.00000000000659, -48.90400000000254], 0.14: [-47.228999999994684, -34.16899999997636, -50.00000000000659, -48.75000000000568], 0.16: [-48.62800000000068, -35.36999999997106, -48.69100000000091, -47.41499999999536], 0.18: [-48.97400000000308, -34.483999999974365, -46.56499999999704, -46.73199999999311], 0.2: [-48.68700000000204, -39.939999999970325, -46.073999999989574, -47.2619999999955]}\n","3 fgsm (ut): {0.0: [97.56799999999632, 96.12699999999285, 97.7649999999959, 97.93499999999618], 0.02: [54.48399999998769, -50.00000000000659, 91.97399999999088, 93.41899999999781], 0.04: [-14.542999999999903, -34.288999999973285, -18.64199999998474, 48.374999999981185], 0.06: [2.544999999997841, -41.71199999998082, -44.233999999982736, -23.481999999980484], 0.08: [3.281999999994613, -47.29399999999947, -42.952999999977536, -30.90599999998028], 0.1: [-20.574999999984144, -43.32699999998117, -43.2729999999786, -22.47999999998028], 0.12: [-31.809999999971534, -40.5569999999677, -44.30099999998311, -36.44999999997213], 0.14: [-38.66899999997551, -37.04499999997367, -47.17099999999447, -44.36499999998252], 0.16: [-45.171999999987094, -43.434999999984235, -47.541000000000366, -46.63399999999161], 0.18: [-50.00000000000659, -42.163999999973754, -47.178999999995504, -50.00000000000659], 0.2: [-47.69399999999638, -36.695999999973616, -46.5089999999957, -44.65399999998259]}\n","4 fgsm (t): {0.0: [97.80999999999597, 95.60599999999312, 96.29599999999607, 97.94299999999623, 95.17499999999453], 0.02: [-41.63899999997277, -46.795999999996745, 25.883000000016406, 40.34400000001263, -33.765999999972784], 0.04: [-17.889999999986298, -34.43199999997088, -50.00000000000659, -37.394999999971034, -19.338999999975716], 0.06: [-17.354999999987832, -36.16599999996913, -50.00000000000659, -43.10899999998151, -23.558999999984366], 0.08: [-35.579999999974106, 9.039999999998228, -48.70600000000097, -45.8129999999909, -30.451999999968706], 0.1: [-42.07299999997629, -0.01799999999945533, -50.00000000000659, -45.909999999997446, -36.374999999973554], 0.12: [-44.86999999998728, -22.303999999976803, -50.00000000000659, -48.90400000000254, -29.534999999982578], 0.14: [-47.228999999994684, -34.16899999997636, -50.00000000000659, -48.75000000000568, -27.039999999981752], 0.16: [-48.62800000000068, -35.36999999997106, -48.69100000000091, -47.41499999999536, -43.3349999999787], 0.18: [-48.97400000000308, -34.483999999974365, -46.56499999999704, -46.73199999999311, -48.56400000000045], 0.2: [-48.68700000000204, -39.939999999970325, -46.073999999989574, -47.2619999999955, -46.27799999999145]}\n","4 fgsm (ut): {0.0: [97.56799999999632, 96.12699999999285, 97.7649999999959, 97.93499999999618, 95.17699999999228], 0.02: [54.48399999998769, -50.00000000000659, 91.97399999999088, 93.41899999999781, -3.747000000003803], 0.04: [-14.542999999999903, -34.288999999973285, -18.64199999998474, 48.374999999981185, -46.04999999999216], 0.06: [2.544999999997841, -41.71199999998082, -44.233999999982736, -23.481999999980484, -50.00000000000659], 0.08: [3.281999999994613, -47.29399999999947, -42.952999999977536, -30.90599999998028, -47.32399999999579], 0.1: [-20.574999999984144, -43.32699999998117, -43.2729999999786, -22.47999999998028, -50.00000000000659], 0.12: [-31.809999999971534, -40.5569999999677, -44.30099999998311, -36.44999999997213, -50.00000000000659], 0.14: [-38.66899999997551, -37.04499999997367, -47.17099999999447, -44.36499999998252, -50.00000000000659], 0.16: [-45.171999999987094, -43.434999999984235, -47.541000000000366, -46.63399999999161, -50.00000000000659], 0.18: [-50.00000000000659, -42.163999999973754, -47.178999999995504, -50.00000000000659, -50.00000000000659], 0.2: [-47.69399999999638, -36.695999999973616, -46.5089999999957, -44.65399999998259, -48.58800000000054]}\n","---\n","fgsm (t): {0.0: [97.80999999999597, 95.60599999999312, 96.29599999999607, 97.94299999999623, 95.17499999999453], 0.02: [-41.63899999997277, -46.795999999996745, 25.883000000016406, 40.34400000001263, -33.765999999972784], 0.04: [-17.889999999986298, -34.43199999997088, -50.00000000000659, -37.394999999971034, -19.338999999975716], 0.06: [-17.354999999987832, -36.16599999996913, -50.00000000000659, -43.10899999998151, -23.558999999984366], 0.08: [-35.579999999974106, 9.039999999998228, -48.70600000000097, -45.8129999999909, -30.451999999968706], 0.1: [-42.07299999997629, -0.01799999999945533, -50.00000000000659, -45.909999999997446, -36.374999999973554], 0.12: [-44.86999999998728, -22.303999999976803, -50.00000000000659, -48.90400000000254, -29.534999999982578], 0.14: [-47.228999999994684, -34.16899999997636, -50.00000000000659, -48.75000000000568, -27.039999999981752], 0.16: [-48.62800000000068, -35.36999999997106, -48.69100000000091, -47.41499999999536, -43.3349999999787], 0.18: [-48.97400000000308, -34.483999999974365, -46.56499999999704, -46.73199999999311, -48.56400000000045], 0.2: [-48.68700000000204, -39.939999999970325, -46.073999999989574, -47.2619999999955, -46.27799999999145]}\n","fgsm (ut): {0.0: [97.56799999999632, 96.12699999999285, 97.7649999999959, 97.93499999999618, 95.17699999999228], 0.02: [54.48399999998769, -50.00000000000659, 91.97399999999088, 93.41899999999781, -3.747000000003803], 0.04: [-14.542999999999903, -34.288999999973285, -18.64199999998474, 48.374999999981185, -46.04999999999216], 0.06: [2.544999999997841, -41.71199999998082, -44.233999999982736, -23.481999999980484, -50.00000000000659], 0.08: [3.281999999994613, -47.29399999999947, -42.952999999977536, -30.90599999998028, -47.32399999999579], 0.1: [-20.574999999984144, -43.32699999998117, -43.2729999999786, -22.47999999998028, -50.00000000000659], 0.12: [-31.809999999971534, -40.5569999999677, -44.30099999998311, -36.44999999997213, -50.00000000000659], 0.14: [-38.66899999997551, -37.04499999997367, -47.17099999999447, -44.36499999998252, -50.00000000000659], 0.16: [-45.171999999987094, -43.434999999984235, -47.541000000000366, -46.63399999999161, -50.00000000000659], 0.18: [-50.00000000000659, -42.163999999973754, -47.178999999995504, -50.00000000000659, -50.00000000000659], 0.2: [-47.69399999999638, -36.695999999973616, -46.5089999999957, -44.65399999998259, -48.58800000000054]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zhjx5F9-XS8p","executionInfo":{"status":"ok","timestamp":1612195918801,"user_tz":-60,"elapsed":1211,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"04334c2a-a026-4df8-be21-7864e610849d"},"source":["print(\"noise: {0.0: [97.81499999999596, 95.79099999999157, 96.29499999999415, 97.93399999999622, 89.30499999998712, 97.84699999999604, 74.62099999997754, 95.85599999999204, 96.18399999999309, 97.01099999999464, 96.47899999999447], 0.05: [39.19600000001345, 11.098999999999204, 40.6430000000141, 76.87199999998931, -38.2709999999691, 22.212000000009603, -5.862000000002688, 48.65999999999616, 60.307999999991196, 51.18599999999777, 29.395000000016207], 0.1: [39.44700000001104, 19.49400000000553, 7.407999999998801, 5.172999999996604, -29.545999999980477, -0.7610000000016894, 15.351000000007309, 54.35499999999417, 44.139000000016075, 5.32299999999485, -11.879000000005778], 0.15: [34.88800000001661, 10.176000000005898, -4.807000000003346, 1.80099999999872, -37.58199999997086, -7.636999999988667, 10.978999999999944, 49.05499999999026, 19.37700000001689, 9.861999999997536, -25.572999999975647], 0.2: [15.112000000010319, 1.2659999999980365, -11.567999999999508, 1.0520000000000012, -38.732999999969586, -17.227999999990075, -2.1740000000002775, 35.37600000001522, 11.374000000009316, -15.644999999990025, -44.16399999998171], 0.25: [-3.8680000000034487, 11.804000000015783, -14.883999999984407, 9.46299999999308, -39.18599999997031, -23.24799999998533, -4.704000000004297, 48.1570000000026, 4.500999999992392, -4.468000000003668, -48.53400000000148], 0.3: [-31.383999999974453, -1.502000000002005, -28.093999999980177, 15.916000000008475, -43.60099999997876, -34.167999999971215, -0.6040000000000825, 25.675000000019203, -23.599999999983996, -16.84399999998561, -45.650999999992585], 0.35: [-39.02299999996841, 7.255999999997249, -14.482999999988003, -3.4680000000078066, -45.07599999999413, -22.656999999984663, -9.733999999996666, 29.077000000016533, -23.853999999984406, -16.208999999992002, -47.14599999999438], 0.4: [-25.800999999977197, 0.5730000000010412, -22.76899999998588, 3.8259999999933054, -44.070999999980465, -25.158999999975304, 6.500999999997405, 1.9169999999969856, -35.369999999973274, -20.191999999981523, -50.00000000000659], 0.45: [-34.308999999973565, 2.224999999999611, -11.166999999994822, -6.007000000003689, -41.651999999972986, -29.768999999973133, -2.7340000000000577, -0.8810000000035015, -26.87399999997508, -14.243999999991024, -45.655999999988914], 0.5: [-31.747999999974258, 0.0439999999931584, -17.907999999982874, -5.305000000004871, -44.36099999998351, -31.96599999997717, -13.580999999999328, 3.650999999998195, -33.08199999996927, -19.990999999988492, -47.15799999999897]}\")\n","print(\"fgsm (t): {0.0: [95.57199999999243, 96.19799999999323, 94.81699999999242, 97.9369999999962, 96.64399999999395, 97.85999999999605, 77.05699999997755, 95.92999999999223, 96.2319999999931, 97.01499999999461, 97.96599999999627], 0.02: [35.51200000001988, 90.58899999998599, 73.89699999999209, 97.86099999999605, 22.522000000013207, -20.712999999990046, -26.80899999997856, 77.60999999998342, 80.30499999998672, 31.939000000019064, 89.75199999998918], 0.04: [26.968000000013845, 65.82299999997052, 1.3969999999971012, 97.82599999999601, -11.029000000002043, -30.563999999977636, -40.824999999974466, 46.20999999999979, -14.923999999991544, 15.293000000012748, 78.39199999999352], 0.06: [58.230999999987546, 9.583000000000402, -12.918999999990211, 92.02999999999116, -24.49799999997799, -27.016999999972967, -13.35099999999957, 55.218999999998566, -39.74599999996958, -9.693999999991156, 74.25999999997873], 0.08: [23.172000000012527, 24.187000000015917, -21.81999999998329, 67.29799999999072, -33.33399999997277, 16.935000000008753, -17.590999999976752, 68.79399999997432, -41.49399999997805, 29.113000000009084, 77.17699999999063], 0.1: [53.25399999999027, -0.2180000000023696, -12.198999999996294, -2.6900000000004285, -23.889999999981434, 5.224999999996488, -16.77999999998918, 49.12600000000882, -44.240999999981995, -15.395999999989506, 91.66699999998907], 0.12: [8.550999999994978, 4.264999999995929, -16.995999999992122, 2.5499999999963503, -31.487999999974814, 1.6220000000001022, -23.45399999997804, 7.224999999995686, -47.94599999999843, -33.16599999996982, 17.830000000009445], 0.14: [-30.374999999974666, -9.393999999993381, 15.905000000014029, 8.213999999998551, -29.69999999997737, 6.232999999995797, -17.91199999998686, -24.67299999997783, -47.961999999999215, -33.98299999996913, -48.90400000000169], 0.16: [-29.086999999976868, -17.957999999990374, 37.8360000000115, -2.723000000001943, -30.860999999973792, 3.4049999999957494, -20.460999999987468, -27.45899999997346, -45.63099999998819, -47.39000000000087, -50.00000000000659], 0.18: [-45.469999999988744, -26.167999999978083, 43.729000000003595, 5.205999999996762, -27.704999999978522, -11.222000000003717, -15.169999999980416, -29.884999999981346, -46.85599999999242, -44.8159999999875, -50.00000000000659], 0.2: [-40.65899999996761, -18.59899999998767, 8.997999999994933, -22.16799999998375, -22.78599999998103, -3.604999999999342, -25.204999999973253, -32.1539999999753, -43.005999999975685, -38.074999999970984, -50.00000000000659]}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["noise: {0.0: [97.81499999999596, 95.79099999999157, 96.29499999999415, 97.93399999999622, 89.30499999998712, 97.84699999999604, 74.62099999997754, 95.85599999999204, 96.18399999999309, 97.01099999999464, 96.47899999999447], 0.05: [39.19600000001345, 11.098999999999204, 40.6430000000141, 76.87199999998931, -38.2709999999691, 22.212000000009603, -5.862000000002688, 48.65999999999616, 60.307999999991196, 51.18599999999777, 29.395000000016207], 0.1: [39.44700000001104, 19.49400000000553, 7.407999999998801, 5.172999999996604, -29.545999999980477, -0.7610000000016894, 15.351000000007309, 54.35499999999417, 44.139000000016075, 5.32299999999485, -11.879000000005778], 0.15: [34.88800000001661, 10.176000000005898, -4.807000000003346, 1.80099999999872, -37.58199999997086, -7.636999999988667, 10.978999999999944, 49.05499999999026, 19.37700000001689, 9.861999999997536, -25.572999999975647], 0.2: [15.112000000010319, 1.2659999999980365, -11.567999999999508, 1.0520000000000012, -38.732999999969586, -17.227999999990075, -2.1740000000002775, 35.37600000001522, 11.374000000009316, -15.644999999990025, -44.16399999998171], 0.25: [-3.8680000000034487, 11.804000000015783, -14.883999999984407, 9.46299999999308, -39.18599999997031, -23.24799999998533, -4.704000000004297, 48.1570000000026, 4.500999999992392, -4.468000000003668, -48.53400000000148], 0.3: [-31.383999999974453, -1.502000000002005, -28.093999999980177, 15.916000000008475, -43.60099999997876, -34.167999999971215, -0.6040000000000825, 25.675000000019203, -23.599999999983996, -16.84399999998561, -45.650999999992585], 0.35: [-39.02299999996841, 7.255999999997249, -14.482999999988003, -3.4680000000078066, -45.07599999999413, -22.656999999984663, -9.733999999996666, 29.077000000016533, -23.853999999984406, -16.208999999992002, -47.14599999999438], 0.4: [-25.800999999977197, 0.5730000000010412, -22.76899999998588, 3.8259999999933054, -44.070999999980465, -25.158999999975304, 6.500999999997405, 1.9169999999969856, -35.369999999973274, -20.191999999981523, -50.00000000000659], 0.45: [-34.308999999973565, 2.224999999999611, -11.166999999994822, -6.007000000003689, -41.651999999972986, -29.768999999973133, -2.7340000000000577, -0.8810000000035015, -26.87399999997508, -14.243999999991024, -45.655999999988914], 0.5: [-31.747999999974258, 0.0439999999931584, -17.907999999982874, -5.305000000004871, -44.36099999998351, -31.96599999997717, -13.580999999999328, 3.650999999998195, -33.08199999996927, -19.990999999988492, -47.15799999999897]}\n","fgsm (t): {0.0: [95.57199999999243, 96.19799999999323, 94.81699999999242, 97.9369999999962, 96.64399999999395, 97.85999999999605, 77.05699999997755, 95.92999999999223, 96.2319999999931, 97.01499999999461, 97.96599999999627], 0.02: [35.51200000001988, 90.58899999998599, 73.89699999999209, 97.86099999999605, 22.522000000013207, -20.712999999990046, -26.80899999997856, 77.60999999998342, 80.30499999998672, 31.939000000019064, 89.75199999998918], 0.04: [26.968000000013845, 65.82299999997052, 1.3969999999971012, 97.82599999999601, -11.029000000002043, -30.563999999977636, -40.824999999974466, 46.20999999999979, -14.923999999991544, 15.293000000012748, 78.39199999999352], 0.06: [58.230999999987546, 9.583000000000402, -12.918999999990211, 92.02999999999116, -24.49799999997799, -27.016999999972967, -13.35099999999957, 55.218999999998566, -39.74599999996958, -9.693999999991156, 74.25999999997873], 0.08: [23.172000000012527, 24.187000000015917, -21.81999999998329, 67.29799999999072, -33.33399999997277, 16.935000000008753, -17.590999999976752, 68.79399999997432, -41.49399999997805, 29.113000000009084, 77.17699999999063], 0.1: [53.25399999999027, -0.2180000000023696, -12.198999999996294, -2.6900000000004285, -23.889999999981434, 5.224999999996488, -16.77999999998918, 49.12600000000882, -44.240999999981995, -15.395999999989506, 91.66699999998907], 0.12: [8.550999999994978, 4.264999999995929, -16.995999999992122, 2.5499999999963503, -31.487999999974814, 1.6220000000001022, -23.45399999997804, 7.224999999995686, -47.94599999999843, -33.16599999996982, 17.830000000009445], 0.14: [-30.374999999974666, -9.393999999993381, 15.905000000014029, 8.213999999998551, -29.69999999997737, 6.232999999995797, -17.91199999998686, -24.67299999997783, -47.961999999999215, -33.98299999996913, -48.90400000000169], 0.16: [-29.086999999976868, -17.957999999990374, 37.8360000000115, -2.723000000001943, -30.860999999973792, 3.4049999999957494, -20.460999999987468, -27.45899999997346, -45.63099999998819, -47.39000000000087, -50.00000000000659], 0.18: [-45.469999999988744, -26.167999999978083, 43.729000000003595, 5.205999999996762, -27.704999999978522, -11.222000000003717, -15.169999999980416, -29.884999999981346, -46.85599999999242, -44.8159999999875, -50.00000000000659], 0.2: [-40.65899999996761, -18.59899999998767, 8.997999999994933, -22.16799999998375, -22.78599999998103, -3.604999999999342, -25.204999999973253, -32.1539999999753, -43.005999999975685, -38.074999999970984, -50.00000000000659]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6Sxio8iR3qqp"},"source":["def eval_scale(agent, episode_durations):\n","    agent.eval()\n","    agent.is_training = False\n","\n","    max_episode_length = 500\n","    num_episodes = 100\n","\n","    for scale in np.arange(1.0,7.01,0.5):\n","        env = NormalizedEnv(PointFallEnv(scale))\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","            # unsqueeze adds batch dimension\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","\n","                action = agent.select_action(state, False, False)\n","                action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","                observation, reward, done, info = env.step(action_i) \n","                \n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                \n","                episode_steps += 1 \n","\n","                overall_reward += reward\n","\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_durations[np.round(scale, 2)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yv_Kd5pYO0-5","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"error","timestamp":1611482604774,"user_tz":-60,"elapsed":1395924,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"6819c871-fd10-406b-9bf6-9791be660d67"},"source":["episodes = {}\n","for scale in np.arange(1.0,7.01,0.5):\n","    episodes[np.round(scale, 2)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 11:\n","    agent = TD3(n_observations, n_actions).to(device)\n","    load_model(agent, f\"td3_{i}\")\n","\n","    if agent is not None:\n","        eval_scale(agent, episodes)\n","        print(f\"{i} scale: {episodes}\")\n","        i += 1\n","\n","print(\"---\")\n","print(f\"scale: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 scale: {1.0: [-35.835999999973694], 1.5: [-35.9149999999692], 2.0: [-37.89399999997111], 2.5: [33.00800000001212], 3.0: [55.47699999998554], 3.5: [98.00299999999628], 4.0: [97.819999999996], 4.5: [97.67999999999573], 5.0: [17.665000000001974], 5.5: [57.4319999999789], 6.0: [74.99299999997442], 6.5: [1.3509999999953681], 7.0: [-38.95499999996939]}\n","1 scale: {1.0: [-35.835999999973694, 97.7049999999989], 1.5: [-35.9149999999692, -35.61599999997276], 2.0: [-37.89399999997111, -15.921999999994489], 2.5: [33.00800000001212, 69.35199999998638], 3.0: [55.47699999998554, 89.27799999999148], 3.5: [98.00299999999628, 94.66999999999138], 4.0: [97.819999999996, 96.22099999999323], 4.5: [97.67999999999573, 96.37099999999342], 5.0: [17.665000000001974, 96.03299999999261], 5.5: [57.4319999999789, 80.88099999998138], 6.0: [74.99299999997442, 73.57499999998119], 6.5: [1.3509999999953681, 45.81000000000228], 7.0: [-38.95499999996939, 9.903000000005465]}\n","2 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935]}\n","3 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366]}\n","4 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274]}\n","5 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775]}\n","6 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888, -39.23599999996845], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285, -42.51099999998298], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223, 62.281999999983384], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365, 98.39399999999712], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405, 98.41199999999708], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463, 98.22299999999669], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604, 78.64999999999029], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052, -47.46199999999658], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244, -47.40699999999761], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423, -50.00000000000659], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094, -50.00000000000659], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744, -50.00000000000659], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775, -50.00000000000659]}\n","7 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888, -39.23599999996845, -50.00000000000659], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285, -42.51099999998298, -41.87399999997416], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223, 62.281999999983384, 82.3069999999896], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365, 98.39399999999712, 96.21799999999308], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405, 98.41199999999708, 96.51499999999383], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463, 98.22299999999669, 95.97199999999256], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604, 78.64999999999029, 95.89099999999272], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052, -47.46199999999658, 96.67699999999377], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244, -47.40699999999761, 96.09999999999287], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423, -50.00000000000659, 94.08699999999027], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094, -50.00000000000659, 88.85099999999098], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744, -50.00000000000659, 58.0219999999787], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775, -50.00000000000659, 28.847000000014464]}\n","8 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888, -39.23599999996845, -50.00000000000659, -33.93999999997553], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285, -42.51099999998298, -41.87399999997416, -9.411000000007345], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223, 62.281999999983384, 82.3069999999896, -2.1750000000002556], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365, 98.39399999999712, 96.21799999999308, 17.39599999999722], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405, 98.41199999999708, 96.51499999999383, 17.42300000000654], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463, 98.22299999999669, 95.97199999999256, 96.19599999999315], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604, 78.64999999999029, 95.89099999999272, 96.25599999999336], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052, -47.46199999999658, 96.67699999999377, 96.2399999999932], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244, -47.40699999999761, 96.09999999999287, 96.55599999999392], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423, -50.00000000000659, 94.08699999999027, 96.75999999999416], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094, -50.00000000000659, 88.85099999999098, 96.48499999999365], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744, -50.00000000000659, 58.0219999999787, 96.36499999999346], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775, -50.00000000000659, 28.847000000014464, 96.19199999999313]}\n","9 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888, -39.23599999996845, -50.00000000000659, -33.93999999997553, -50.00000000000659], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285, -42.51099999998298, -41.87399999997416, -9.411000000007345, -48.742000000002236], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223, 62.281999999983384, 82.3069999999896, -2.1750000000002556, 92.22199999999215], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365, 98.39399999999712, 96.21799999999308, 17.39599999999722, 95.66699999999324], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405, 98.41199999999708, 96.51499999999383, 17.42300000000654, 97.69499999999576], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463, 98.22299999999669, 95.97199999999256, 96.19599999999315, 84.22799999998226], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604, 78.64999999999029, 95.89099999999272, 96.25599999999336, 97.01299999999463], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052, -47.46199999999658, 96.67699999999377, 96.2399999999932, 96.8049999999943], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244, -47.40699999999761, 96.09999999999287, 96.55599999999392, 96.39599999999349], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423, -50.00000000000659, 94.08699999999027, 96.75999999999416, 94.6769999999932], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094, -50.00000000000659, 88.85099999999098, 96.48499999999365, 94.99999999999044], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744, -50.00000000000659, 58.0219999999787, 96.36499999999346, 63.111999999974074], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775, -50.00000000000659, 28.847000000014464, 96.19199999999313, 60.31099999998715]}\n","10 scale: {1.0: [-35.835999999973694, 97.7049999999989, -39.581999999971316, 61.07199999999098, -48.783000000001245, 10.656999999995888, -39.23599999996845, -50.00000000000659, -33.93999999997553, -50.00000000000659, -50.00000000000659], 1.5: [-35.9149999999692, -35.61599999997276, -45.56299999998772, 35.904000000014065, -45.18199999998983, 48.598000000001285, -42.51099999998298, -41.87399999997416, -9.411000000007345, -48.742000000002236, -12.967999999998751], 2.0: [-37.89399999997111, -15.921999999994489, 66.70599999998662, 94.17899999999412, -32.67999999997552, 82.37899999999223, 62.281999999983384, 82.3069999999896, -2.1750000000002556, 92.22199999999215, 88.07099999998803], 2.5: [33.00800000001212, 69.35199999998638, 25.534000000004966, 98.68899999999756, 26.383000000004778, 94.52499999999365, 98.39399999999712, 96.21799999999308, 17.39599999999722, 95.66699999999324, 15.411000000005913], 3.0: [55.47699999998554, 89.27799999999148, 25.59500000001191, 98.57099999999735, 84.55699999999045, 92.07499999999405, 98.41199999999708, 96.51499999999383, 17.42300000000654, 97.69499999999576, 80.3069999999848], 3.5: [98.00299999999628, 94.66999999999138, 86.16399999999568, 98.24699999999677, 93.69399999999054, 96.54199999999463, 98.22299999999669, 95.97199999999256, 96.19599999999315, 84.22799999998226, 80.45299999998537], 4.0: [97.819999999996, 96.22099999999323, 97.78099999999591, 97.94499999999621, 90.76499999998946, 97.85599999999604, 78.64999999999029, 95.89099999999272, 96.25599999999336, 97.01299999999463, 97.89799999999619], 4.5: [97.67999999999573, 96.37099999999342, 93.10899999999266, 97.69899999999576, 93.47999999999156, 95.08599999999052, -47.46199999999658, 96.67699999999377, 96.2399999999932, 96.8049999999943, 97.81199999999599], 5.0: [17.665000000001974, 96.03299999999261, 96.67599999999345, 97.37699999999522, 94.79699999999461, 89.87799999998244, -47.40699999999761, 96.09999999999287, 96.55599999999392, 96.39599999999349, 91.16499999998139], 5.5: [57.4319999999789, 80.88099999998138, 97.1559999999949, 97.08699999999479, 93.24499999998983, 82.97799999997423, -50.00000000000659, 94.08699999999027, 96.75999999999416, 94.6769999999932, 87.22399999998342], 6.0: [74.99299999997442, 73.57499999998119, 96.5539999999934, 96.8929999999944, 81.52399999998069, 60.622999999991094, -50.00000000000659, 88.85099999999098, 96.48499999999365, 94.99999999999044, 85.33799999998806], 6.5: [1.3509999999953681, 45.81000000000228, 87.13899999998596, 95.23099999999236, 41.496000000021716, 68.1019999999744, -50.00000000000659, 58.0219999999787, 96.36499999999346, 63.111999999974074, 86.50899999998704], 7.0: [-38.95499999996939, 9.903000000005465, 55.593999999979935, 96.51099999999366, -8.080000000007274, 67.5729999999775, -50.00000000000659, 28.847000000014464, 96.19199999999313, 60.31099999998715, 87.70399999999523]}\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-cd80ce66ded6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTD3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"td3_{i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-130d4f9b1475>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/drive/My Drive/Dissertation/saved_models/point_fall/{name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'controller'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'critic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Dissertation/saved_models/point_fall/td3_11'"]}]},{"cell_type":"code","metadata":{"id":"CzPo4An7w9cM"},"source":["def eval_starting_position(agent, episode_durations):\n","    agent.eval()\n","    agent.is_training = False\n","\n","    max_episode_length = 500\n","    num_episodes = 100\n","\n","    for extra_range in np.arange(0.0, 0.401, 0.05):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            extra = np.random.uniform(-0.1 - extra_range, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = np.random.uniform(0.1, 0.1 + extra_range, env.starting_point.shape)\n","            #extra = extra * (2*np.random.randint(0,2,size=env.starting_point.shape)-1)\n","            env.unwrapped.state = np.array(env.starting_point + extra, dtype=np.float32)\n","            env.unwrapped.state[2] += math.pi / 2. # start facing up\n","            env.unwrapped.state[2] = env.state[2] % (2 * math.pi)\n","            observation = env.normalised_state()\n","\n","            # unsqueeze adds batch dimension\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","\n","                action = agent.select_action(state, False, False)\n","                action_i = action.detach().cpu().squeeze(0).numpy()\n","\n","                observation, reward, done, info = env.step(action_i) \n","                \n","                if max_episode_length and episode_steps >= max_episode_length - 1:\n","                    done = True\n","                \n","                episode_steps += 1 \n","\n","                overall_reward += reward\n","\n","                state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_durations[np.round(extra_range, 3)].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jzp0i3LDVLZ-","executionInfo":{"status":"ok","timestamp":1612549412282,"user_tz":-60,"elapsed":980605,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"c9055d0c-e322-4808-c87a-ffaca03f40ae"},"source":["episodes = {}\n","for extra_range in np.arange(0.0, 0.401, 0.05):\n","    episodes[np.round(extra_range, 3)] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 11:\n","    agent = TD3(n_observations, n_actions).to(device)\n","    load_model(agent, f\"td3_{i}\")\n","\n","    if agent is not None:\n","        eval_starting_position(agent, episodes)\n","        print(f\"{i} extra_range: {episodes}\")\n","        i += 1\n","\n","print(\"---\")\n","print(f\"extra_range: {episodes}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 extra_range: {0.0: [96.13399999999586], 0.05: [97.84299999999601], 0.1: [96.36099999999662], 0.15: [88.99399999998981], 0.2: [79.92499999998046], 0.25: [76.99499999998858], 0.3: [69.98099999998173], 0.35: [63.36599999999035], 0.4: [58.85999999999196]}\n","1 extra_range: {0.0: [96.13399999999586, 96.26499999999332], 0.05: [97.84299999999601, 93.20899999999355], 0.1: [96.36099999999662, 69.93699999998559], 0.15: [88.99399999998981, 58.15099999998757], 0.2: [79.92499999998046, 51.99899999999083], 0.25: [76.99499999998858, 34.228000000016856], 0.3: [69.98099999998173, 47.098000000009854], 0.35: [63.36599999999035, 19.86500000000292], 0.4: [58.85999999999196, 10.691000000010465]}\n","2 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517]}\n","3 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327]}\n","4 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512]}\n","5 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765]}\n","6 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743]}\n","7 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568, 96.051999999993], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755, 95.98599999999287], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042, 95.89599999999221], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798, 93.09399999999208], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444, 89.83299999999372], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819, 87.51099999998985], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171, 70.77899999998104], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545, 56.28199999998931], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743, 71.16499999997833]}\n","8 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568, 96.051999999993, 96.21799999999328], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755, 95.98599999999287, 96.20699999999324], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042, 95.89599999999221, 96.29599999999328], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798, 93.09399999999208, 96.29299999999321], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444, 89.83299999999372, 96.3159999999931], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819, 87.51099999998985, 96.31999999999334], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171, 70.77899999998104, 92.03299999999086], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545, 56.28199999998931, 90.58799999999064], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743, 71.16499999997833, 81.78499999999494]}\n","9 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568, 96.051999999993, 96.21799999999328, 97.00999999999463], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755, 95.98599999999287, 96.20699999999324, 97.02499999999462], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042, 95.89599999999221, 96.29599999999328, 96.99599999999452], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798, 93.09399999999208, 96.29299999999321, 97.00299999999453], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444, 89.83299999999372, 96.3159999999931, 95.54199999999517], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819, 87.51099999998985, 96.31999999999334, 82.3049999999869], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171, 70.77899999998104, 92.03299999999086, 77.88799999998596], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545, 56.28199999998931, 90.58799999999064, 73.08699999998946], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743, 71.16499999997833, 81.78499999999494, 52.54100000000377]}\n","10 extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568, 96.051999999993, 96.21799999999328, 97.00999999999463, 97.9719999999963], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755, 95.98599999999287, 96.20699999999324, 97.02499999999462, 96.49099999999629], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042, 95.89599999999221, 96.29599999999328, 96.99599999999452, 96.47199999999701], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798, 93.09399999999208, 96.29299999999321, 97.00299999999453, 97.6719999999952], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444, 89.83299999999372, 96.3159999999931, 95.54199999999517, 91.7799999999883], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819, 87.51099999998985, 96.31999999999334, 82.3049999999869, 83.1229999999833], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171, 70.77899999998104, 92.03299999999086, 77.88799999998596, 63.893999999982185], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545, 56.28199999998931, 90.58799999999064, 73.08699999998946, 65.07599999998692], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743, 71.16499999997833, 81.78499999999494, 52.54100000000377, 62.13599999998003]}\n","---\n","extra_range: {0.0: [96.13399999999586, 96.26499999999332, 96.30299999999419, 97.93099999999619, 92.25099999999115, 97.85399999999605, 85.00399999998568, 96.051999999993, 96.21799999999328, 97.00999999999463, 97.9719999999963], 0.05: [97.84299999999601, 93.20899999999355, 84.45099999999358, 97.93999999999618, 89.29399999998998, 94.87399999999718, 54.87299999999755, 95.98599999999287, 96.20699999999324, 97.02499999999462, 96.49099999999629], 0.1: [96.36099999999662, 69.93699999998559, 71.15099999999032, 97.94199999999624, 84.90299999998679, 82.64999999999534, 56.03699999998042, 95.89599999999221, 96.29599999999328, 96.99599999999452, 96.47199999999701], 0.15: [88.99399999998981, 58.15099999998757, 57.8159999999806, 97.74199999999642, 80.4909999999976, 69.43099999999421, 22.450000000015798, 93.09399999999208, 96.29299999999321, 97.00299999999453, 97.6719999999952], 0.2: [79.92499999998046, 51.99899999999083, 44.51700000001421, 96.24899999999614, 79.01399999998846, 59.58099999998413, 8.61999999999444, 89.83299999999372, 96.3159999999931, 95.54199999999517, 91.7799999999883], 0.25: [76.99499999998858, 34.228000000016856, 37.10500000001619, 87.46499999998792, 71.67899999998063, 47.066000000003186, 12.923000000000819, 87.51099999998985, 96.31999999999334, 82.3049999999869, 83.1229999999833], 0.3: [69.98099999998173, 47.098000000009854, 7.320999999997223, 83.06999999999417, 73.15499999998991, 31.815000000010784, -1.56900000000171, 70.77899999998104, 92.03299999999086, 77.88799999998596, 63.893999999982185], 0.35: [63.36599999999035, 19.86500000000292, 6.12299999999899, 80.09799999998638, 65.81699999998777, 29.84600000000832, 1.173999999997545, 56.28199999998931, 90.58799999999064, 73.08699999998946, 65.07599999998692], 0.4: [58.85999999999196, 10.691000000010465, 6.108999999995517, 68.23399999998327, 71.67799999999512, 16.36900000000765, -15.890999999988743, 71.16499999997833, 81.78499999999494, 52.54100000000377, 62.13599999998003]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x0RfEsXYVO03"},"source":["state_max = torch.from_numpy(env.observation_space.high).to(device).float()\n","state_min = torch.from_numpy(env.observation_space.low).to(device).float()\n","state_mid = (state_max + state_min) / 2.\n","state_range = (state_max - state_min)\n","def save_trajectories(agent, episode_durations, dirty):\n","    agent.eval()\n","\n","    max_episode_length = 500\n","    agent.is_training = False\n","\n","    num_episodes = 10\n","\n","    l2norm = 0.3\n","    episode_durations.append([])\n","    \n","    for i_episode in range(num_episodes):\n","        path = {\"overall_reward\": 0, \"worker\": []}\n","\n","        observation = env.reset()\n","\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        episode_steps = 0\n","        overall_reward = 0\n","        done = False\n","        while not done:\n","            if dirty:\n","                state = state + state_range * torch.FloatTensor(state.shape).uniform_(-l2norm, l2norm).to(device)\n","                state = torch.max(torch.min(state, state_max), state_min).float()\n","\n","            action = agent.select_action(state, False, False)\n","            action_i = action.detach().cpu().squeeze(0).numpy()\n","            path[\"worker\"].append((episode_steps, state_.detach().cpu().squeeze(0).numpy(), action.detach().cpu().squeeze(0).numpy()))\n","\n","            observation, reward, done, info = env.step(action_i) \n","            \n","            if max_episode_length and episode_steps >= max_episode_length - 1:\n","                done = True\n","            \n","            episode_steps += 1 \n","\n","            overall_reward += reward\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            state_ = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","        path[\"overall_reward\"] = overall_reward\n","        episode_durations[-1].append(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeNRw8D6X0_O","executionInfo":{"status":"ok","timestamp":1612800175329,"user_tz":-60,"elapsed":37360,"user":{"displayName":"D.G. Khachaturov","photoUrl":"","userId":"02831277067458900124"}},"outputId":"bee75e32-0c8c-488d-fc3b-761471520bee"},"source":["episodes = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 11:\n","    #agent = train_model()\n","    agent = TD3(n_observations, n_actions).to(device)\n","    load_model(agent, f\"td3_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        save_trajectories(agent, episodes, True)\n","        #print(f\"{i} paths: {episodes}\")\n","        i += 1\n","\n","print(\"----\")\n","#print(f\"paths: {episodes}\")\n","\n","episodes.pop(6)\n","\n","torch.save(episodes, \"td3_PointFall_dirty_eps.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2miwVcOkYAeo"},"source":[""],"execution_count":null,"outputs":[]}]}