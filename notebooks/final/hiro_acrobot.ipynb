{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Copy of HIRO_acrobot.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-Y3vLeDo4pG","executionInfo":{"status":"ok","timestamp":1609575461370,"user_tz":-60,"elapsed":31963,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"a6299b71-894d-4dd1-ad41-3257d8cb4a72"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive/')\r\n","\r\n","#!cp \"/content/drive/My Drive/Dissertation/preprocessing.py\" .\r\n","#!cp -r \"/content/drive/My Drive/Dissertation/gym_maze\" .\r\n","!cp \"/content/drive/My Drive/Dissertation/envs/continuous_arcobot.py\" ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eaaz1IRfpF1l","executionInfo":{"status":"ok","timestamp":1609575490206,"user_tz":-60,"elapsed":1083,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["# for inference, not continued training\r\n","def save_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","\r\n","    torch.save({\r\n","      'meta_controller': {\r\n","          'critic': model.meta_controller.critic.state_dict(),\r\n","          'actor': model.meta_controller.actor.state_dict(),\r\n","      },\r\n","      'controller': {\r\n","          'critic': model.controller.critic.state_dict(),\r\n","          'actor': model.controller.actor.state_dict(),\r\n","      }\r\n","    }, path)\r\n","\r\n","import copy\r\n","def load_model(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.meta_controller.critic.load_state_dict(checkpoint['meta_controller']['critic'])\r\n","    model.meta_controller.critic_target = copy.deepcopy(model.meta_controller.critic)\r\n","    model.meta_controller.actor.load_state_dict(checkpoint['meta_controller']['actor'])\r\n","    model.meta_controller.actor_target = copy.deepcopy(model.meta_controller.actor)\r\n","\r\n","    model.controller.critic.load_state_dict(checkpoint['controller']['critic'])\r\n","    model.controller.critic_target = copy.deepcopy(model.controller.critic)\r\n","    model.controller.actor.load_state_dict(checkpoint['controller']['actor'])\r\n","    model.controller.actor_target = copy.deepcopy(model.controller.actor)\r\n","\r\n","    # model.eval() for evaluation instead\r\n","    model.eval()\r\n","    model.meta_controller.eval()\r\n","    model.controller.eval()\r\n","\r\n","def load_model_sub(model, name):\r\n","    path = f\"/content/drive/My Drive/Dissertation/saved_models/{name}\" \r\n","    checkpoint = torch.load(path)\r\n","\r\n","    model.critic.load_state_dict(checkpoint['controller']['critic'])\r\n","    model.critic_target = copy.deepcopy(model.critic)\r\n","    model.actor.load_state_dict(checkpoint['controller']['actor'])\r\n","    model.actor_target = copy.deepcopy(model.actor)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJMjXntuErvs","executionInfo":{"status":"ok","timestamp":1609575495312,"user_tz":-60,"elapsed":5690,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["%matplotlib inline\n","\n","import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from IPython import display\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESCbXyTAQHNs","executionInfo":{"status":"ok","timestamp":1609575495320,"user_tz":-60,"elapsed":4575,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["class NormalizedEnv(gym.ActionWrapper):\n","    \"\"\" Wrap action \"\"\"\n","\n","    def action(self, action):\n","        act_k = (self.action_space.high - self.action_space.low)/ 2.\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k * action + act_b\n","\n","    def reverse_action(self, action):\n","        act_k_inv = 2./(self.action_space.high - self.action_space.low)\n","        act_b = (self.action_space.high + self.action_space.low)/ 2.\n","        return act_k_inv * (action - act_b)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRSC05Y-Erv0","executionInfo":{"status":"ok","timestamp":1609575495323,"user_tz":-60,"elapsed":4319,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["from continuous_arcobot import AcrobotEnv \r\n","env = NormalizedEnv(AcrobotEnv())"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiZFY63MErv3"},"source":["***"]},{"cell_type":"code","metadata":{"id":"DQtcj2j8Erv4","executionInfo":{"status":"ok","timestamp":1609575495326,"user_tz":-60,"elapsed":3546,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["loss_plot = []\n","loss_plot_meta = []\n","def plot_durations(episode_durations):\n","    global loss_plot\n","    fig, axs = plt.subplots(3, figsize=(10,15))\n","    \n","    durations_t, durations = list(map(list, zip(*episode_durations)))\n","    durations = torch.tensor(durations, dtype=torch.float)\n","    \n","    fig.suptitle('Training')\n","    axs[0].set_xlabel('Episode')\n","    axs[0].set_ylabel('Reward')\n","    axs[1].set_xlabel('Steps')\n","    axs[1].set_ylabel('Loss')\n","    axs[2].set_xlabel('Steps')\n","    axs[2].set_ylabel('Loss (meta)')\n","    \n","    axs[0].plot(durations_t, durations.numpy())\n","\n","    if len(loss_plot) > 0:\n","        durations_t, durations = list(map(list, zip(*loss_plot)))\n","        durations = torch.tensor(durations, dtype=torch.float)\n","\n","        axs[1].plot(durations_t, durations.numpy())\n","    if len(loss_plot_meta) > 0:\n","        durations_t, durations = list(map(list, zip(*loss_plot_meta)))\n","        durations = torch.tensor(durations, dtype=torch.float)\n","\n","        axs[2].plot(durations_t, durations.numpy())\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyQnUb6KErv6","executionInfo":{"status":"ok","timestamp":1609575495329,"user_tz":-60,"elapsed":2151,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n","\n","class RandomProcess(object):\n","    def reset_states(self):\n","        pass\n","\n","class AnnealedGaussianProcess(RandomProcess):\n","    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.n_steps = 0\n","\n","        if sigma_min is not None:\n","            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n","            self.c = sigma\n","            self.sigma_min = sigma_min\n","        else:\n","            self.m = 0.\n","            self.c = sigma\n","            self.sigma_min = sigma\n","\n","    @property\n","    def current_sigma(self):\n","        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n","        return sigma\n","\n","\n","# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n","class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n","    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n","        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n","        self.theta = theta\n","        self.mu = mu\n","        self.dt = dt\n","        self.x0 = x0\n","        self.size = size\n","        self.reset_states()\n","\n","    def sample(self):\n","        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n","        self.x_prev = x\n","        self.n_steps += 1\n","        return x\n","\n","    def reset_states(self):\n","        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWIkep5aErv9","executionInfo":{"status":"ok","timestamp":1609575495331,"user_tz":-60,"elapsed":965,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["def soft_update(target, source, tau):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","        target_param.data.copy_(\n","            target_param.data * (1.0 - tau) + param.data * tau\n","        )\n","\n","def hard_update(target, source):\n","    for target_param, param in zip(target.parameters(), source.parameters()):\n","            target_param.data.copy_(param.data)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtW05marErwA","executionInfo":{"status":"ok","timestamp":1609575498046,"user_tz":-60,"elapsed":2451,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["# (state, action) -> (next_state, reward, done)\n","transition = namedtuple('transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# replay memory D with capacity N\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    # implemented as a cyclical queue\n","    def store(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        \n","        self.memory[self.position] = transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrMrvwO1ErwC"},"source":["***"]},{"cell_type":"code","metadata":{"id":"0oyBjK1AErwD","executionInfo":{"status":"ok","timestamp":1609575498050,"user_tz":-60,"elapsed":1008,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["DEPTH = 128\n","class Actor(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(nb_states, DEPTH)\n","        self.fc2 = nn.Linear(DEPTH, DEPTH)\n","        self.head = nn.Linear(DEPTH, nb_actions)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return torch.tanh(self.head(x))\n","\n","class Critic(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(Critic, self).__init__()\n","\n","        # Q1 architecture\n","        self.l1 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l2 = nn.Linear(DEPTH, DEPTH)\n","        self.l3 = nn.Linear(DEPTH, 1)\n","\n","        # Q2 architecture\n","        self.l4 = nn.Linear(nb_states + nb_actions, DEPTH)\n","        self.l5 = nn.Linear(DEPTH, DEPTH)\n","        self.l6 = nn.Linear(DEPTH, 1)\n","    \n","    def forward(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","\n","        q2 = F.relu(self.l4(sa))\n","        q2 = F.relu(self.l5(q2))\n","        q2 = self.l6(q2)\n","        return q1, q2\n","\n","    def Q1(self, state, action):\n","        sa = torch.cat([state, action], 1).float()\n","\n","        q1 = F.relu(self.l1(sa))\n","        q1 = F.relu(self.l2(q1))\n","        q1 = self.l3(q1)\n","        return q1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-9mozrWErwG","executionInfo":{"status":"ok","timestamp":1609575499882,"user_tz":-60,"elapsed":1423,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","\n","# https://spinningup.openai.com/en/latest/algorithms/td3.html\n","class TD3(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(TD3, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        \n","        self.actor = Actor(self.nb_states, self.nb_actions)\n","        self.actor_target = Actor(self.nb_states, self.nb_actions)\n","        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=0.0001)\n","\n","        self.critic = Critic(self.nb_states, self.nb_actions)\n","        self.critic_target = Critic(self.nb_states, self.nb_actions)\n","        self.critic_optimizer  = optim.Adam(self.critic.parameters(), lr=0.0001)\n","\n","        hard_update(self.actor_target, self.actor)\n","        hard_update(self.critic_target, self.critic)\n","        \n","        #Create replay buffer\n","        self.memory = ReplayMemory(100000) # 50,000 for 4 frameskip\n","        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=0.15, mu=0.0, sigma=0.2)\n","\n","        # Hyper-parameters\n","        self.tau = 0.005\n","        self.depsilon = 1.0 / 20000\n","        self.policy_noise=0.2\n","        self.noise_clip=0.5\n","        self.policy_freq=2\n","        self.total_it = 0\n","\n","        # \n","        self.epsilon = 1.0\n","        self.is_training = True\n","\n","    def update_policy(self):\n","        if len(self.memory) < BATCH_SIZE:\n","            return\n","\n","        self.total_it += 1\n","        \n","        # in the form (state, action) -> (next_state, reward, done)\n","        transitions = self.memory.sample(BATCH_SIZE)\n","        batch = transition(*zip(*transitions))\n","        \n","        state_batch = torch.cat(batch.state)\n","        next_state_batch = torch.cat(batch.next_state)\n","        action_batch = torch.cat(batch.action)\n","        reward_batch = torch.cat(batch.reward)\n","        done_mask = np.array(batch.done)\n","        not_done_mask = torch.from_numpy(1 - done_mask).float().to(device)\n","\n","        # Target Policy Smoothing\n","        with torch.no_grad():\n","            # Select action according to policy and add clipped noise\n","            noise = (\n","                torch.randn_like(action_batch) * self.policy_noise\n","            ).clamp(-self.noise_clip, self.noise_clip).float()\n","            \n","            next_action = (\n","                self.actor_target(next_state_batch) + noise\n","            ).clamp(-1.0, 1.0).float()\n","\n","            # Compute the target Q value\n","            # Clipped Double-Q Learning\n","            target_Q1, target_Q2 = self.critic_target(next_state_batch, next_action)\n","            target_Q = torch.min(target_Q1, target_Q2).squeeze(1)\n","            target_Q = (reward_batch + GAMMA * not_done_mask  * target_Q).float()\n","        \n","        # Critic update\n","        current_Q1, current_Q2 = self.critic(state_batch, action_batch)\n","      \n","        critic_loss = F.mse_loss(current_Q1, target_Q.unsqueeze(1)) + F.mse_loss(current_Q2, target_Q.unsqueeze(1))\n","        loss_val_c = critic_loss.item()\n","\n","        # Optimize the critic\n","        self.critic_optimizer.zero_grad()\n","        critic_loss.backward()\n","        self.critic_optimizer.step()\n","\n","        # Delayed policy updates\n","        if self.total_it % self.policy_freq == 0:\n","            # Compute actor loss\n","            actor_loss = -self.critic.Q1(state_batch, self.actor(state_batch)).mean()\n","            loss_val = actor_loss.item()\n","\n","            # Optimize the actor \n","            self.actor_optimizer.zero_grad()\n","            actor_loss.backward()\n","            self.actor_optimizer.step()\n","\n","            # Target update\n","            soft_update(self.actor_target, self.actor, self.tau)\n","            soft_update(self.critic_target, self.critic, self.tau / 5)\n","\n","            return loss_val_c, loss_val\n","        return loss_val_c, None\n","\n","    def eval(self):\n","        self.actor.eval()\n","        self.actor_target.eval()\n","        self.critic.eval()\n","        self.critic_target.eval()\n","\n","    def observe(self, s_t, a_t, s_t1, r_t, done):\n","        self.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def random_action(self):\n","        #return torch.tensor([np.random.choice([-1, 0, 1],size=self.nb_actions)], device=device, dtype=torch.float)\n","        return torch.tensor([np.random.uniform(-1.,1.,self.nb_actions)], device=device, dtype=torch.float)\n","\n","    def select_action(self, s_t, warmup=True, decay_epsilon=True):\n","        if warmup:\n","            return self.random_action()\n","\n","        with torch.no_grad():\n","            action = self.actor(s_t).squeeze(0)\n","            #action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * self.random_process.sample()).to(device).float()\n","            action += torch.from_numpy(self.is_training * max(self.epsilon, 0) * np.random.uniform(-1.,1.,self.nb_actions)).to(device).float()\n","            action = torch.clamp(action, -1., 1.)\n","\n","            action = action.unsqueeze(0)\n","            \n","            if decay_epsilon:\n","                self.epsilon -= self.depsilon\n","            \n","            return action"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u23kJqHhvw8","executionInfo":{"status":"ok","timestamp":1609575500224,"user_tz":-60,"elapsed":460,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["class HIRO(nn.Module):\n","    def __init__(self, nb_states, nb_actions):\n","        super(HIRO, self).__init__()\n","        self.nb_states = nb_states\n","        self.nb_actions= nb_actions\n","        self.goal_dim = [0] * nb_actions\n","      \n","        self.meta_controller = TD3(nb_states, len(self.goal_dim)).to(device)\n","        self.max_goal_dist = torch.from_numpy(np.array([1.0] * nb_actions)).to(device)\n","\n","        self.controller = TD3(nb_states + len(self.goal_dim), nb_actions).to(device)\n","        self.controller.depsilon = 1.0 / 5000\n","        self.controller.memory = ReplayMemory(20000)\n","\n","    def teach_controller(self):\n","        self.controller.update_policy()\n","    def teach_meta_controller(self):\n","        return self.meta_controller.update_policy()\n","\n","    def h(self, state, goal, next_state):\n","        return goal\n","        #return state[:,self.goal_dim] + goal - next_state[:,self.goal_dim]\n","    def intrinsic_reward(self, action, goal):\n","        return torch.tensor(1.0 if self.goal_reached(action, goal) else 0.0, device=device) \n","    def goal_reached(self, action, goal, threshold = 0.1):\n","        return torch.abs(action - goal) <= threshold\n","    #def intrinsic_reward(self, state, goal, next_state):\n","    #    return torch.tensor(1.0 if self.goal_reached(state, goal, next_state) else 0.0, device=device)\n","    #    # just L2 norm\n","    #    #return -torch.pow(sum(torch.pow(state.squeeze(0)[self.goal_dim] + goal.squeeze(0) - next_state.squeeze(0)[self.goal_dim], 2)), 0.5)\n","    #def goal_reached(self, state, goal, next_state, threshold = 0.1):\n","    #    return torch.abs(next_state[:,self.goal_dim] - state[:,self.goal_dim] - goal) <= threshold\n","    #    #return torch.pow(sum(goal.squeeze(0), 2), 0.5) <= threshold\n","\n","    # correct goals to allow for use in experience replay\n","    def off_policy_correction(self, action_seq, state_seq, goal, next_state):\n","        return goal\n","        action_seq = torch.stack(action_seq).to(device)\n","        state_seq = torch.stack(state_seq).to(device)\n","\n","        mean = (next_state - state_seq[0])[:,self.goal_dim]\n","        std = 0.5 * (0.5 * self.max_goal_dist)\n","\n","        candidates = [\\\n","            torch.min(\\\n","                torch.max(torch.from_numpy(np.random.normal(loc=mean.cpu(), scale=std.cpu(), size=len(self.goal_dim)).astype(np.float32)).to(device).unsqueeze(0), -self.max_goal_dist),\\\n","                self.max_goal_dist) for _ in range(8)\\\n","            ]\n","        candidates.append(mean)\n","        candidates.append(goal)\n","        candidates = torch.stack(candidates).to(device)\n","\n","        surr_prob = [\\\n","              -F.mse_loss(action_seq, self.controller.actor_target(torch.cat([state_seq, state_seq[0][:,self.goal_dim] + candidates[0] - state_seq[:,:,self.goal_dim]], 2).float()))\\\n","              for candidate in candidates]\n","        index = int(np.argmax(surr_prob))\n","        goal_hat = candidates[index]\n","        return goal_hat\n","\n","    def observe_controller(self, s_t, a_t, s_t1, r_t, done):\n","        self.controller.memory.store(s_t, a_t, s_t1, r_t, done)\n","    def observe_meta_controller(self, s_t, a_t, s_t1, r_t, done):\n","        self.meta_controller.memory.store(s_t, a_t, s_t1, r_t, done)\n","\n","    def select_goal(self, s_t, warmup=True, decay_epsilon=True):\n","        return self.meta_controller.select_action(s_t, warmup, decay_epsilon) * self.max_goal_dist\n","    def select_action(self, s_t, g_t, warmup=True, decay_epsilon=True):\n","        sg_t = torch.cat([s_t, g_t], 1).float()\n","        return self.controller.select_action(sg_t, warmup, decay_epsilon)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7_KKbeSErwI","executionInfo":{"status":"ok","timestamp":1609575549407,"user_tz":-60,"elapsed":911,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}}},"source":["SAVE_OFFSET = 0\n","\n","def train_model():\n","    global SAVE_OFFSET\n","    n_observations = env.observation_space.shape[0]\n","    n_actions = env.action_space.shape[0]\n","    \n","    agent = HIRO(n_observations, n_actions).to(device)\n","\n","    #load_model_sub(agent.meta_controller, f\"td3_acrobot_{SAVE_OFFSET}\")\n","    #agent.meta_controller.is_training = False\n","    \n","    max_episode_length = 500\n","    \n","    episode_reward = 0.\n","    observation = None\n","    \n","    warmup = 100\n","    warmup_ctrl = 10\n","    num_episodes = 6000 # M\n","    episode_durations = []\n","    goal_durations = [(0,0)]\n","\n","    steps = 0\n","    c = 10\n","\n","    for i_episode in range(num_episodes):\n","        observation = env.reset()\n","        state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","        \n","        overall_reward = 0\n","        episode_steps = 0\n","        done = False\n","        goals_done = 0\n","\n","        while not done:\n","            goal = agent.select_goal(state, i_episode <= warmup)\n","            #loss_plot_meta.append((steps, goal[:,0]))\n","\n","            state_seq, action_seq = [], []\n","            first_goal = goal\n","            goal_done = False\n","            total_extrinsic = 0\n","            while not done and not goal_done:\n","                joint_goal_state = torch.cat([state, goal], axis=1).float()\n","\n","                # agent pick action ...\n","                action = agent.select_action(state, goal, i_episode <= warmup_ctrl)\n","                action_i = action.detach().cpu().squeeze(0).numpy()\n","                \n","                reward = 0\n","                for _ in range(4):\n","                    if done:\n","                        continue\n","                    # env response with next_observation, reward, terminate_info\n","                    observation, reward_i, done, info = env.step(action_i)\n","                    steps += 1\n","\n","                    reward += reward_i\n","                \n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1 \n","\n","                next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                next_goal = agent.h(state, goal, next_state)\n","                joint_next_state = torch.cat([next_state, next_goal], axis=1).float()\n","                \n","                extrinsic_reward = torch.tensor([reward], device=device)\n","                #intrinsic_reward = agent.intrinsic_reward(state, goal, next_state).unsqueeze(0)\n","                intrinsic_reward = agent.intrinsic_reward(action, goal).unsqueeze(0)\n","\n","                overall_reward += reward\n","                total_extrinsic += reward\n","\n","                #goal_done = agent.goal_reached(state, goal, next_state)\n","                goal_done = agent.goal_reached(action, goal)\n","                    \n","                # agent observe and update policy\n","                agent.observe_controller(joint_goal_state, action, joint_next_state, intrinsic_reward, done)\n","\n","                state_seq.append(state)\n","                action_seq.append(action)\n","\n","                if goal_done:\n","                    goals_done += 1\n","                \n","                if goal_done: #or (episode_steps % c) == 0:\n","                    # perform off-policy correction and store\n","                    goal_hat = agent.off_policy_correction(action_seq, state_seq, first_goal, next_state)\n","                    goal_done = True\n","                    \n","                    if i_episode > warmup:\n","                        agent.observe_meta_controller(state_seq[0], goal_hat, next_state,  torch.tensor([total_extrinsic], device=device), done)\n","                        losses = agent.teach_meta_controller()\n","\n","                        if losses is not None:\n","                            closs, loss = losses\n","                            if loss is not None:\n","                                loss_plot_meta.append((steps, loss))\n","                            if closs is not None:\n","                                loss_plot.append((steps, closs))\n","                        \n","\n","                state = next_state\n","                goal = next_goal\n","                \n","                if i_episode > warmup_ctrl:\n","                    loss = agent.teach_controller()\n","                    if loss is not None and i_episode % 50 == 0:\n","                        loss_plot.append((steps, loss))\n","\n","        #loss_plot.append((i_episode, goals_done / episode_steps))\n","        episode_durations.append((i_episode, overall_reward))\n","        #plot_durations(episode_durations)\n","\n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100 and len(loss_plot_meta) > 100 and len(loss_plot) > 100:\n","            _, actor_loss = list(map(list, zip(*loss_plot_meta)))\n","            _, critic_loss = list(map(list, zip(*loss_plot)))\n","            if i_episode % 50 == 0:\n","                print(f\"Episode {i_episode}: {np.mean(dur[-100:])}; critic loss: {np.mean(critic_loss[-100:])}; actor loss: {np.mean(actor_loss[-100:])}\")\n","          \n","        _, dur = list(map(list, zip(*episode_durations)))\n","        if len(dur) > 100:\n","            if i_episode % 100 == 0 and i_episode >= 1000 and np.mean(dur[-100:]) < -400.0:\n","                print(f\"Catastrophic forgetting after {i_episode} eps, terminating... Avg: {np.mean(dur[-100:])}\")\n","                return None # unlucky\n","            if np.mean(dur[-100:]) >= -90: #90 over 100\n","                print(f\"Solved after {i_episode} episodes!\")\n","                save_model(agent, f\"hiro_acrobot_{SAVE_OFFSET}\")\n","                SAVE_OFFSET += 1\n","                return agent\n","\n","    return None # did not train"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSrTqHQxtVOp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"67bdf215-769b-468d-9618-73c864c30b0b"},"source":["i = 0\r\n","while i < 3:\r\n","    loss_plot = []\r\n","    loss_plot_meta = []\r\n","    agent = train_model()\r\n","    if agent is not None:\r\n","        print(i)\r\n","        i +=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Episode 150: -496.67; critic loss: 0.9747425147145986; actor loss: 12.483453512191772\n","Episode 200: -500.0; critic loss: 5.61111303396523; actor loss: 23.075290546417236\n","Episode 250: -494.47; critic loss: 13.068780017495156; actor loss: 33.326710052490235\n","Episode 300: -481.97; critic loss: 22.673438042998313; actor loss: 42.71338726043701\n","Episode 350: -416.89; critic loss: 36.99726444482803; actor loss: 49.51512420654297\n","Episode 400: -390.37; critic loss: 52.588121331334115; actor loss: 57.37354610443115\n","Episode 450: -459.86; critic loss: 52.56239690065384; actor loss: 66.6411139678955\n","Episode 500: -495.44; critic loss: 80.70628161847591; actor loss: 75.03771293640136\n","Episode 550: -496.56; critic loss: 90.9306711679697; actor loss: 83.20940795898437\n","Episode 600: -500.0; critic loss: 121.28932268738747; actor loss: 90.26937614440918\n","Episode 650: -500.0; critic loss: 133.933124563694; actor loss: 97.5508080291748\n","Episode 700: -500.0; critic loss: 144.9656337082386; actor loss: 104.14008422851562\n","Episode 750: -493.12; critic loss: 147.10347415685655; actor loss: 110.2878204345703\n","Episode 800: -408.65; critic loss: 190.99460127592087; actor loss: 113.56430732727051\n","Episode 850: -296.94; critic loss: 234.07604754447937; actor loss: 114.61915237426757\n","Episode 900: -330.17; critic loss: 195.34893900752067; actor loss: 117.74808868408203\n","Episode 950: -364.01; critic loss: 228.3614881205559; actor loss: 120.4047695159912\n","Episode 1000: -332.52; critic loss: 221.21364724636078; actor loss: 122.73074905395508\n","Episode 1050: -291.68; critic loss: 249.6839912414551; actor loss: 125.20964172363281\n","Episode 1100: -270.46; critic loss: 218.71416408777236; actor loss: 127.93662384033203\n","Episode 1150: -358.69; critic loss: 269.36801513195036; actor loss: 132.50375701904298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7-GH33rpv6-Z"},"source":["Gstate_max = torch.from_numpy(env.observation_space.high).to(device)\r\n","state_min = torch.from_numpy(env.observation_space.low).to(device)\r\n","def fgsm_attack(data, eps, data_grad):\r\n","    sign_data_grad = data_grad.sign()\r\n","\r\n","    perturbed_data = data + eps * sign_data_grad * state_max\r\n","\r\n","    clipped_perturbed_data = torch.max(torch.min(perturbed_data, state_max), state_min)\r\n","\r\n","    return clipped_perturbed_data\r\n","\r\n","def fgsm_goal(g_state, agent, eps, target, targetted):\r\n","    #g_state = torch.tensor(g_state, requires_grad=True)\r\n","    g_state = g_state.clone().detach().requires_grad_(True)\r\n","\r\n","    # initial forward pass\r\n","    goal = agent.meta_controller.actor(g_state)\r\n","    goal = torch.clamp(goal, -1., 1.)\r\n","\r\n","    if not targetted:\r\n","        loss = F.mse_loss(goal, target)\r\n","    else:\r\n","         # if < 0 then -1 else 1\r\n","        loss = F.mse_loss(goal, target if goal > 0 else -target)\r\n","    agent.meta_controller.actor.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = g_state.grad.data\r\n","\r\n","    # perturb state\r\n","    g_state_p = fgsm_attack(g_state, eps, data_grad).float()\r\n","    return agent.select_goal(g_state_p, False)\r\n","\r\n","def fgsm_action(state, goal, agent, eps, target, targetted):\r\n","    #state = torch.tensor(state, requires_grad=True)\r\n","    state = state.clone().detach().requires_grad_(True)\r\n","\r\n","    sg_t = torch.cat([state, goal], 1).float()\r\n","    # initial forward pass\r\n","    action = agent.controller.actor(sg_t)\r\n","    action = torch.clamp(action, -1., 1.)\r\n","\r\n","    if not targetted:\r\n","        loss = F.mse_loss(action, target)\r\n","    else:\r\n","        loss = F.mse_loss(action, target if action > 0 else -target)\r\n","    agent.controller.actor.zero_grad()\r\n","\r\n","    # calc loss\r\n","    loss.backward()\r\n","    data_grad = state.grad.data\r\n","    # perturb state\r\n","    state_p = fgsm_attack(state, eps, data_grad).float()\r\n","    return agent.select_action(state_p, goal, False)\r\n","\r\n","def apply_fgsm(agent, episode_durations, goal_attack, action_attack, targetted):\r\n","    TARGET_GOAL = torch.tensor([[1.0]], device=device, dtype=torch.float)\r\n","    TARGET_ACTION = torch.tensor([[1.0]], device=device, dtype=torch.float)\r\n","\r\n","    agent.eval()\r\n","    agent.meta_controller.eval()\r\n","    agent.controller.eval()\r\n","\r\n","    max_episode_length = 200\r\n","    agent.meta_controller.is_training = False\r\n","    agent.controller.is_training = False\r\n","\r\n","    num_episodes = 100\r\n","\r\n","    for eps in np.arange(0.0, 0.31, 0.025):\r\n","\r\n","        overall_reward = 0\r\n","        for i_episode in range(num_episodes):\r\n","            observation = env.reset()\r\n","\r\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","            episode_steps = 0\r\n","            done = False\r\n","            while not done:\r\n","                if goal_attack:\r\n","                    goal = fgsm_goal(g_state, agent, eps, TARGET_GOAL, targetted)\r\n","                else:\r\n","                    goal = agent.select_goal(g_state, False)\r\n","\r\n","                goal_done = False\r\n","                while not done and not goal_done:\r\n","                    if action_attack:\r\n","                        action = fgsm_action(state, goal, agent, eps, TARGET_ACTION, targetted)\r\n","                    else:\r\n","                        action = agent.select_action(state, goal, False)\r\n","                    \r\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\r\n","\r\n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\r\n","\r\n","                    next_goal = agent.h(g_state, goal, g_next_state)\r\n","                                      \r\n","                    overall_reward += reward\r\n","\r\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\r\n","                        done = True\r\n","                    episode_steps += 1\r\n","\r\n","                    goal_done = agent.goal_reached(action, goal)\r\n","                    #goal_done = agent.goal_reached(g_state, goal, g_next_state)\r\n","\r\n","                    state = next_state\r\n","                    g_state = g_next_state\r\n","                    goal = next_goal\r\n","\r\n","        episode_durations[eps].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj1smUjnRiSJ"},"source":["def plot_fgsm(episode_durations):\r\n","    plt.figure(2, figsize=(10,10))\r\n","    \r\n","    for kk in ['both', 'goal_only', 'action_only']:\r\n","        x, ys = np.array(list(episode_durations[kk].keys())), np.array(list(episode_durations[kk].values()))\r\n","        #plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\r\n","        plt.xlabel('$\\epsilon$')\r\n","        plt.ylabel('Average Reward')\r\n","        \r\n","        mu = np.mean(ys, axis=1)\r\n","        plt.plot(x, mu, label=kk)\r\n","        stds = np.std(ys, axis = 1)\r\n","        plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\r\n","    \r\n","    plt.legend()\r\n","    plt.pause(0.001)  # pause a bit so that plots are updated\r\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5kgVRwJErwO"},"source":["#state_max = torch.from_numpy(np.array(env.observation_space.high)).to(device)\n","def eval_model(agent, episode_durations, goal_attack, action_attack, same_noise):\n","    agent.eval()\n","    agent.meta_controller.eval()\n","    agent.controller.eval()\n","\n","    max_episode_length = 200\n","    agent.meta_controller.is_training = False\n","    agent.controller.is_training = False\n","\n","    num_episodes = 100\n","\n","    for l2norm in np.arange(0,1.001,0.1):\n","\n","        overall_reward = 0\n","        for i_episode in range(num_episodes):\n","            observation = env.reset()\n","\n","            state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            g_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","            \n","            noise = torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","\n","            if goal_attack:\n","                g_state = state + state_max * noise\n","                g_state = g_state.float()\n","\n","            if action_attack:\n","                if same_noise:\n","                    state = state + state_max * noise\n","                else:\n","                    state = state + state_max * torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                state = state.float()\n","\n","            episode_steps = 0\n","            done = False\n","            while not done:\n","                # select a goal\n","                goal = agent.select_goal(g_state, False)\n","\n","                goal_done = False\n","                while not done and not goal_done:\n","                    action = agent.select_action(state, goal, False)\n","                    observation, reward, done, info = env.step(action.detach().cpu().squeeze(0).numpy())\n","\n","                    next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","                    g_next_state = torch.from_numpy(observation).float().unsqueeze(0).to(device)\n","\n","                    noise = torch.FloatTensor(state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                    if goal_attack:\n","                        g_next_state = next_state + state_max * noise\n","                        g_next_state = g_next_state.float()\n","                    if action_attack:\n","                        if same_noise:\n","                            next_state = next_state + state_max * noise\n","                        else:\n","                            next_state = next_state + state_max * torch.FloatTensor(next_state.shape).uniform_(-l2norm/2, l2norm/2).to(device)\n","                        next_state = next_state.float()\n","\n","                    next_goal = agent.h(g_state, goal, g_next_state)\n","                                      \n","                    overall_reward += reward\n","\n","                    if max_episode_length and episode_steps >= max_episode_length - 1:\n","                        done = True\n","                    episode_steps += 1\n","\n","                    goal_done = agent.goal_reached(action, goal)\n","                    #goal_done = agent.goal_reached(g_state, goal, g_next_state)\n","\n","                    state = next_state\n","                    g_state = g_next_state\n","                    goal = next_goal\n","\n","        episode_durations[l2norm].append(overall_reward / num_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2tHUSCPy6xf"},"source":["def plot_norms(episode_durations):\n","    plt.figure(2, figsize=(10,10))\n","    \n","    x, ys = np.array(list(episode_durations.keys())), np.array(list(episode_durations.values()))\n","    #plt.title('Action Prediction $\\mu$ and $\\pm \\sigma$ interval')\n","    plt.xlabel('L2 Norm')\n","    plt.ylabel('Average Reward')\n","    \n","    mu = np.mean(ys, axis=1)\n","    plt.plot(x, mu)\n","    stds = np.std(ys, axis = 1)\n","    plt.fill_between(x, mu + stds , mu - stds, alpha=0.2)\n","        \n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Od4IvIuPuNlc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608976167005,"user_tz":-60,"elapsed":8909692,"user":{"displayName":"David Khachaturov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv6TQULJqrRmGx4orsjnj2Qw8l6izQ6vq8Xhw1=s64","userId":"00615802394785083853"}},"outputId":"df155f85-7410-4496-cb04-b4f3f120ec06"},"source":["targeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\r\n","untargeted = {'both': {}, 'goal_only': {}, 'action_only': {}}\r\n","for eps in np.arange(0.0, 0.31, 0.025):\r\n","    for x in ['both', 'goal_only', 'action_only']:\r\n","        targeted[x][eps] = []\r\n","        untargeted[x][eps] = []\r\n","\r\n","n_observations = env.observation_space.shape[0]\r\n","n_actions = env.action_space.shape[0]\r\n","\r\n","i = 7\r\n","while i < 10:\r\n","    #agent = train_model()\r\n","    agent = HIRO(n_observations, n_actions).to(device)\r\n","    load_model(agent, f\"hiro_car_{i}\")\r\n","\r\n","    if agent is not None:\r\n","        apply_fgsm(agent, targeted['both'], True, True, True)\r\n","        apply_fgsm(agent, targeted['goal_only'], True, False, True)\r\n","        apply_fgsm(agent, targeted['action_only'], False, True, True)\r\n","        apply_fgsm(agent, untargeted['both'], True, True, False)\r\n","        apply_fgsm(agent, untargeted['goal_only'], True, False, False)\r\n","        apply_fgsm(agent, untargeted['action_only'], False, True, False)\r\n","\r\n","        print(i)\r\n","        print(f\"Targeted: {targeted}\")\r\n","        print(f\"Untargeted: {untargeted}\")\r\n","        #plot_fgsm(episode_durations)\r\n","        i += 1\r\n","\r\n","#plot_fgsm(episode_durations)\r\n","print(f\"Targeted: {targeted}\")\r\n","print(f\"Untargeted: {untargeted}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7\n","Targeted: {'both': {0.0: [94.6029850393237], 0.025: [94.30347758532805], 0.05: [94.42833085711162], 0.07500000000000001: [92.30526678581447], 0.1: [92.8487109726169], 0.125: [91.40526667138269], 0.15000000000000002: [90.39006756538494], 0.17500000000000002: [92.47912358361178], 0.2: [88.98261232518415], 0.225: [88.42945628528184], 0.25: [92.39025649669499], 0.275: [92.15853492567487], 0.30000000000000004: [91.9633837657054]}, 'goal_only': {0.0: [94.67913149747987], 0.025: [94.49112186273206], 0.05: [94.61011384850595], 0.07500000000000001: [93.6813187248154], 0.1: [91.88724316066555], 0.125: [91.15340016487633], 0.15000000000000002: [85.92583163314241], 0.17500000000000002: [90.21047444495377], 0.2: [87.88207568606018], 0.225: [86.02243511149106], 0.25: [92.26955655275455], 0.275: [91.96149897570415], 0.30000000000000004: [91.59828784142726]}, 'action_only': {0.0: [94.53450589059923], 0.025: [94.57214577273542], 0.05: [94.63344740961458], 0.07500000000000001: [94.54855888239146], 0.1: [94.64449268650424], 0.125: [94.38933894172467], 0.15000000000000002: [94.53201564742369], 0.17500000000000002: [94.65306152016369], 0.2: [94.73116586829907], 0.225: [94.57884494475867], 0.25: [94.50652073272884], 0.275: [94.510541298006], 0.30000000000000004: [94.45529479325575]}}\n","Untargeted: {'both': {0.0: [94.65581239573456], 0.025: [94.62823837986264], 0.05: [94.68437191896294], 0.07500000000000001: [94.5267458479354], 0.1: [94.23229243924594], 0.125: [93.8771682160986], 0.15000000000000002: [93.65306888549547], 0.17500000000000002: [93.18806652712509], 0.2: [93.1758649528023], 0.225: [92.6778994586106], 0.25: [92.28091107339243], 0.275: [92.13680546360224], 0.30000000000000004: [88.88953604688015]}, 'goal_only': {0.0: [94.66496683158131], 0.025: [94.63388995793433], 0.05: [94.49777597194367], 0.07500000000000001: [94.26435170285818], 0.1: [94.27916916494416], 0.125: [94.04924962658087], 0.15000000000000002: [93.70947021697769], 0.17500000000000002: [93.43021056655917], 0.2: [93.06388811112782], 0.225: [92.93691694777897], 0.25: [92.55307224472959], 0.275: [92.2056230618204], 0.30000000000000004: [91.23567962173819]}, 'action_only': {0.0: [94.45417464279332], 0.025: [94.57309196515227], 0.05: [94.64678434496336], 0.07500000000000001: [94.57969177812201], 0.1: [94.6223351031618], 0.125: [94.65996735891903], 0.15000000000000002: [94.63808356107651], 0.17500000000000002: [94.58667003140135], 0.2: [94.5269651007118], 0.225: [94.65965016048403], 0.25: [94.34936455380355], 0.275: [94.63280516822749], 0.30000000000000004: [94.64195680337836]}}\n","8\n","Targeted: {'both': {0.0: [94.6029850393237, 92.82027683604332], 0.025: [94.30347758532805, 92.99425286453908], 0.05: [94.42833085711162, 93.72417391525137], 0.07500000000000001: [92.30526678581447, 93.753774279929], 0.1: [92.8487109726169, 92.8523786868589], 0.125: [91.40526667138269, 92.48371054898602], 0.15000000000000002: [90.39006756538494, 92.02036397481508], 0.17500000000000002: [92.47912358361178, 78.59891837681683], 0.2: [88.98261232518415, 58.383242193046954], 0.225: [88.42945628528184, 68.91666699766999], 0.25: [92.39025649669499, 66.75265385313587], 0.275: [92.15853492567487, 43.86606961385846], 0.30000000000000004: [91.9633837657054, 45.92706812271864]}, 'goal_only': {0.0: [94.67913149747987, 92.2714055065423], 0.025: [94.49112186273206, 92.44394970092115], 0.05: [94.61011384850595, 93.36401923050879], 0.07500000000000001: [93.6813187248154, 93.51160209076964], 0.1: [91.88724316066555, 92.9242454373096], 0.125: [91.15340016487633, 92.47219127227093], 0.15000000000000002: [85.92583163314241, 91.99882820394946], 0.17500000000000002: [90.21047444495377, 85.26003683245038], 0.2: [87.88207568606018, 67.49114992926837], 0.225: [86.02243511149106, 60.649131415421095], 0.25: [92.26955655275455, 55.125145652700176], 0.275: [91.96149897570415, 60.752069035780266], 0.30000000000000004: [91.59828784142726, 58.19946179835648]}, 'action_only': {0.0: [94.53450589059923, 92.75817650456897], 0.025: [94.57214577273542, 92.23053211633096], 0.05: [94.63344740961458, 92.91553795116992], 0.07500000000000001: [94.54855888239146, 92.59735075654622], 0.1: [94.64449268650424, 92.5049997520555], 0.125: [94.38933894172467, 92.63286184833355], 0.15000000000000002: [94.53201564742369, 93.00186424617988], 0.17500000000000002: [94.65306152016369, 92.5490826593285], 0.2: [94.73116586829907, 91.85685848419409], 0.225: [94.57884494475867, 92.60774646721171], 0.25: [94.50652073272884, 92.79493109785466], 0.275: [94.510541298006, 92.80519377588766], 0.30000000000000004: [94.45529479325575, 91.79306960017976]}}\n","Untargeted: {'both': {0.0: [94.65581239573456, 92.66751295860162], 0.025: [94.62823837986264, 92.19800348037879], 0.05: [94.68437191896294, 91.59844014872206], 0.07500000000000001: [94.5267458479354, 91.22928898094948], 0.1: [94.23229243924594, 91.69083195541367], 0.125: [93.8771682160986, 91.04619001625866], 0.15000000000000002: [93.65306888549547, 91.0207930933348], 0.17500000000000002: [93.18806652712509, 90.24393572768659], 0.2: [93.1758649528023, 90.28213235114976], 0.225: [92.6778994586106, 86.28136008164589], 0.25: [92.28091107339243, 80.86364002838398], 0.275: [92.13680546360224, 71.54395190299579], 0.30000000000000004: [88.88953604688015, 56.49340783169192]}, 'goal_only': {0.0: [94.66496683158131, 92.7167902316335], 0.025: [94.63388995793433, 92.11713100313071], 0.05: [94.49777597194367, 91.72862132815693], 0.07500000000000001: [94.26435170285818, 91.09520456654693], 0.1: [94.27916916494416, 91.21495291560237], 0.125: [94.04924962658087, 90.97017957601784], 0.15000000000000002: [93.70947021697769, 90.55369649671924], 0.17500000000000002: [93.43021056655917, 90.47768604882005], 0.2: [93.06388811112782, 87.29151766097348], 0.225: [92.93691694777897, 86.05919770646868], 0.25: [92.55307224472959, 76.69927967152933], 0.275: [92.2056230618204, 65.27993592410779], 0.30000000000000004: [91.23567962173819, 59.90810346785916]}, 'action_only': {0.0: [94.45417464279332, 92.17920115569815], 0.025: [94.57309196515227, 92.21591354035573], 0.05: [94.64678434496336, 92.5627862591971], 0.07500000000000001: [94.57969177812201, 92.61028871885895], 0.1: [94.6223351031618, 92.41385684203847], 0.125: [94.65996735891903, 92.47317017082327], 0.15000000000000002: [94.63808356107651, 92.44749306492055], 0.17500000000000002: [94.58667003140135, 92.30472894056454], 0.2: [94.5269651007118, 92.23908565167898], 0.225: [94.65965016048403, 92.7756064309396], 0.25: [94.34936455380355, 92.80661530235864], 0.275: [94.63280516822749, 92.63740874297892], 0.30000000000000004: [94.64195680337836, 92.1948340611795]}}\n","9\n","Targeted: {'both': {0.0: [94.6029850393237, 92.82027683604332, 86.72002601866429], 0.025: [94.30347758532805, 92.99425286453908, 88.85925826377925], 0.05: [94.42833085711162, 93.72417391525137, 77.8428258846864], 0.07500000000000001: [92.30526678581447, 93.753774279929, 57.175301310089424], 0.1: [92.8487109726169, 92.8523786868589, 51.2796334127798], 0.125: [91.40526667138269, 92.48371054898602, 50.44526222734421], 0.15000000000000002: [90.39006756538494, 92.02036397481508, 45.83947299680884], 0.17500000000000002: [92.47912358361178, 78.59891837681683, 31.028390831574633], 0.2: [88.98261232518415, 58.383242193046954, 29.671804078368822], 0.225: [88.42945628528184, 68.91666699766999, 22.76073172465067], 0.25: [92.39025649669499, 66.75265385313587, 27.24709837790577], 0.275: [92.15853492567487, 43.86606961385846, 22.21431465057021], 0.30000000000000004: [91.9633837657054, 45.92706812271864, 11.546543336089096]}, 'goal_only': {0.0: [94.67913149747987, 92.2714055065423, 82.55326849469067], 0.025: [94.49112186273206, 92.44394970092115, 89.74223075842696], 0.05: [94.61011384850595, 93.36401923050879, 82.67771758289004], 0.07500000000000001: [93.6813187248154, 93.51160209076964, 54.95137988100266], 0.1: [91.88724316066555, 92.9242454373096, 41.910481771532666], 0.125: [91.15340016487633, 92.47219127227093, 46.70101237356585], 0.15000000000000002: [85.92583163314241, 91.99882820394946, 46.924266084024964], 0.17500000000000002: [90.21047444495377, 85.26003683245038, 31.683057252772645], 0.2: [87.88207568606018, 67.49114992926837, 40.65877913070196], 0.225: [86.02243511149106, 60.649131415421095, 14.432956634115683], 0.25: [92.26955655275455, 55.125145652700176, 23.666415209983448], 0.275: [91.96149897570415, 60.752069035780266, 16.690541688713495], 0.30000000000000004: [91.59828784142726, 58.19946179835648, 4.020155517779819]}, 'action_only': {0.0: [94.53450589059923, 92.75817650456897, 87.82624974594343], 0.025: [94.57214577273542, 92.23053211633096, 87.7628575669248], 0.05: [94.63344740961458, 92.91553795116992, 89.80586335375459], 0.07500000000000001: [94.54855888239146, 92.59735075654622, 87.88237137641491], 0.1: [94.64449268650424, 92.5049997520555, 87.75876138446607], 0.125: [94.38933894172467, 92.63286184833355, 86.82430751441215], 0.15000000000000002: [94.53201564742369, 93.00186424617988, 87.82210721788469], 0.17500000000000002: [94.65306152016369, 92.5490826593285, 85.87186207352757], 0.2: [94.73116586829907, 91.85685848419409, 89.94288902893648], 0.225: [94.57884494475867, 92.60774646721171, 85.97270025351605], 0.25: [94.50652073272884, 92.79493109785466, 87.7882382017691], 0.275: [94.510541298006, 92.80519377588766, 86.60844205749568], 0.30000000000000004: [94.45529479325575, 91.79306960017976, 88.92999123393749]}}\n","Untargeted: {'both': {0.0: [94.65581239573456, 92.66751295860162, 86.62242743271442], 0.025: [94.62823837986264, 92.19800348037879, 89.46198138438696], 0.05: [94.68437191896294, 91.59844014872206, 89.2322777128791], 0.07500000000000001: [94.5267458479354, 91.22928898094948, 89.43479372687081], 0.1: [94.23229243924594, 91.69083195541367, 89.01962934425872], 0.125: [93.8771682160986, 91.04619001625866, 88.81757861165994], 0.15000000000000002: [93.65306888549547, 91.0207930933348, 88.74376190816747], 0.17500000000000002: [93.18806652712509, 90.24393572768659, 88.72404389191149], 0.2: [93.1758649528023, 90.28213235114976, 88.74485048598874], 0.225: [92.6778994586106, 86.28136008164589, 88.7990495816969], 0.25: [92.28091107339243, 80.86364002838398, 88.87912624374654], 0.275: [92.13680546360224, 71.54395190299579, 88.81051879429383], 0.30000000000000004: [88.88953604688015, 56.49340783169192, -15.003525186455638]}, 'goal_only': {0.0: [94.66496683158131, 92.7167902316335, 87.62204297361313], 0.025: [94.63388995793433, 92.11713100313071, 89.35077184379263], 0.05: [94.49777597194367, 91.72862132815693, 88.71640093552273], 0.07500000000000001: [94.26435170285818, 91.09520456654693, 86.40854480272225], 0.1: [94.27916916494416, 91.21495291560237, 89.0609774890319], 0.125: [94.04924962658087, 90.97017957601784, 88.96973595792008], 0.15000000000000002: [93.70947021697769, 90.55369649671924, 88.74698389942272], 0.17500000000000002: [93.43021056655917, 90.47768604882005, 88.73432388054024], 0.2: [93.06388811112782, 87.29151766097348, 88.71945421322069], 0.225: [92.93691694777897, 86.05919770646868, 88.80936507736996], 0.25: [92.55307224472959, 76.69927967152933, 88.88920289504107], 0.275: [92.2056230618204, 65.27993592410779, 88.92128788789027], 0.30000000000000004: [91.23567962173819, 59.90810346785916, -15.061038384689844]}, 'action_only': {0.0: [94.45417464279332, 92.17920115569815, 88.85416414385594], 0.025: [94.57309196515227, 92.21591354035573, 84.61669222719864], 0.05: [94.64678434496336, 92.5627862591971, 85.54904339382469], 0.07500000000000001: [94.57969177812201, 92.61028871885895, 84.5644783487915], 0.1: [94.6223351031618, 92.41385684203847, 84.63204434460644], 0.125: [94.65996735891903, 92.47317017082327, 87.62619736015547], 0.15000000000000002: [94.63808356107651, 92.44749306492055, 88.75387634064069], 0.17500000000000002: [94.58667003140135, 92.30472894056454, 90.7241781768586], 0.2: [94.5269651007118, 92.23908565167898, 86.92506616351828], 0.225: [94.65965016048403, 92.7756064309396, 89.76020713771649], 0.25: [94.34936455380355, 92.80661530235864, 86.81803010691041], 0.275: [94.63280516822749, 92.63740874297892, 86.86167738104417], 0.30000000000000004: [94.64195680337836, 92.1948340611795, 89.60262617611345]}}\n","Targeted: {'both': {0.0: [94.6029850393237, 92.82027683604332, 86.72002601866429], 0.025: [94.30347758532805, 92.99425286453908, 88.85925826377925], 0.05: [94.42833085711162, 93.72417391525137, 77.8428258846864], 0.07500000000000001: [92.30526678581447, 93.753774279929, 57.175301310089424], 0.1: [92.8487109726169, 92.8523786868589, 51.2796334127798], 0.125: [91.40526667138269, 92.48371054898602, 50.44526222734421], 0.15000000000000002: [90.39006756538494, 92.02036397481508, 45.83947299680884], 0.17500000000000002: [92.47912358361178, 78.59891837681683, 31.028390831574633], 0.2: [88.98261232518415, 58.383242193046954, 29.671804078368822], 0.225: [88.42945628528184, 68.91666699766999, 22.76073172465067], 0.25: [92.39025649669499, 66.75265385313587, 27.24709837790577], 0.275: [92.15853492567487, 43.86606961385846, 22.21431465057021], 0.30000000000000004: [91.9633837657054, 45.92706812271864, 11.546543336089096]}, 'goal_only': {0.0: [94.67913149747987, 92.2714055065423, 82.55326849469067], 0.025: [94.49112186273206, 92.44394970092115, 89.74223075842696], 0.05: [94.61011384850595, 93.36401923050879, 82.67771758289004], 0.07500000000000001: [93.6813187248154, 93.51160209076964, 54.95137988100266], 0.1: [91.88724316066555, 92.9242454373096, 41.910481771532666], 0.125: [91.15340016487633, 92.47219127227093, 46.70101237356585], 0.15000000000000002: [85.92583163314241, 91.99882820394946, 46.924266084024964], 0.17500000000000002: [90.21047444495377, 85.26003683245038, 31.683057252772645], 0.2: [87.88207568606018, 67.49114992926837, 40.65877913070196], 0.225: [86.02243511149106, 60.649131415421095, 14.432956634115683], 0.25: [92.26955655275455, 55.125145652700176, 23.666415209983448], 0.275: [91.96149897570415, 60.752069035780266, 16.690541688713495], 0.30000000000000004: [91.59828784142726, 58.19946179835648, 4.020155517779819]}, 'action_only': {0.0: [94.53450589059923, 92.75817650456897, 87.82624974594343], 0.025: [94.57214577273542, 92.23053211633096, 87.7628575669248], 0.05: [94.63344740961458, 92.91553795116992, 89.80586335375459], 0.07500000000000001: [94.54855888239146, 92.59735075654622, 87.88237137641491], 0.1: [94.64449268650424, 92.5049997520555, 87.75876138446607], 0.125: [94.38933894172467, 92.63286184833355, 86.82430751441215], 0.15000000000000002: [94.53201564742369, 93.00186424617988, 87.82210721788469], 0.17500000000000002: [94.65306152016369, 92.5490826593285, 85.87186207352757], 0.2: [94.73116586829907, 91.85685848419409, 89.94288902893648], 0.225: [94.57884494475867, 92.60774646721171, 85.97270025351605], 0.25: [94.50652073272884, 92.79493109785466, 87.7882382017691], 0.275: [94.510541298006, 92.80519377588766, 86.60844205749568], 0.30000000000000004: [94.45529479325575, 91.79306960017976, 88.92999123393749]}}\n","Untargeted: {'both': {0.0: [94.65581239573456, 92.66751295860162, 86.62242743271442], 0.025: [94.62823837986264, 92.19800348037879, 89.46198138438696], 0.05: [94.68437191896294, 91.59844014872206, 89.2322777128791], 0.07500000000000001: [94.5267458479354, 91.22928898094948, 89.43479372687081], 0.1: [94.23229243924594, 91.69083195541367, 89.01962934425872], 0.125: [93.8771682160986, 91.04619001625866, 88.81757861165994], 0.15000000000000002: [93.65306888549547, 91.0207930933348, 88.74376190816747], 0.17500000000000002: [93.18806652712509, 90.24393572768659, 88.72404389191149], 0.2: [93.1758649528023, 90.28213235114976, 88.74485048598874], 0.225: [92.6778994586106, 86.28136008164589, 88.7990495816969], 0.25: [92.28091107339243, 80.86364002838398, 88.87912624374654], 0.275: [92.13680546360224, 71.54395190299579, 88.81051879429383], 0.30000000000000004: [88.88953604688015, 56.49340783169192, -15.003525186455638]}, 'goal_only': {0.0: [94.66496683158131, 92.7167902316335, 87.62204297361313], 0.025: [94.63388995793433, 92.11713100313071, 89.35077184379263], 0.05: [94.49777597194367, 91.72862132815693, 88.71640093552273], 0.07500000000000001: [94.26435170285818, 91.09520456654693, 86.40854480272225], 0.1: [94.27916916494416, 91.21495291560237, 89.0609774890319], 0.125: [94.04924962658087, 90.97017957601784, 88.96973595792008], 0.15000000000000002: [93.70947021697769, 90.55369649671924, 88.74698389942272], 0.17500000000000002: [93.43021056655917, 90.47768604882005, 88.73432388054024], 0.2: [93.06388811112782, 87.29151766097348, 88.71945421322069], 0.225: [92.93691694777897, 86.05919770646868, 88.80936507736996], 0.25: [92.55307224472959, 76.69927967152933, 88.88920289504107], 0.275: [92.2056230618204, 65.27993592410779, 88.92128788789027], 0.30000000000000004: [91.23567962173819, 59.90810346785916, -15.061038384689844]}, 'action_only': {0.0: [94.45417464279332, 92.17920115569815, 88.85416414385594], 0.025: [94.57309196515227, 92.21591354035573, 84.61669222719864], 0.05: [94.64678434496336, 92.5627862591971, 85.54904339382469], 0.07500000000000001: [94.57969177812201, 92.61028871885895, 84.5644783487915], 0.1: [94.6223351031618, 92.41385684203847, 84.63204434460644], 0.125: [94.65996735891903, 92.47317017082327, 87.62619736015547], 0.15000000000000002: [94.63808356107651, 92.44749306492055, 88.75387634064069], 0.17500000000000002: [94.58667003140135, 92.30472894056454, 90.7241781768586], 0.2: [94.5269651007118, 92.23908565167898, 86.92506616351828], 0.225: [94.65965016048403, 92.7756064309396, 89.76020713771649], 0.25: [94.34936455380355, 92.80661530235864, 86.81803010691041], 0.275: [94.63280516822749, 92.63740874297892, 86.86167738104417], 0.30000000000000004: [94.64195680337836, 92.1948340611795, 89.60262617611345]}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YIxghhHpy8hO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608905647864,"user_tz":-60,"elapsed":3798401,"user":{"displayName":"David Khachaturov","photoUrl":"","userId":"00449378819393486934"}},"outputId":"ad30ed34-63ad-41df-9c57-de7b62f08ce9"},"source":["same_noise = {}\n","diff_noise = {}\n","goal_only = {}\n","action_only = {}\n","for l2norm in np.arange(0,1.001,0.1):\n","    for i in [same_noise, diff_noise, goal_only, action_only]:\n","        i[l2norm] = []\n","\n","n_observations = env.observation_space.shape[0]\n","n_actions = env.action_space.shape[0]\n","\n","i = 0\n","while i < 10:\n","    #agent = train_model()\n","    agent = HIRO(n_observations, n_actions).to(device)\n","    load_model(agent, f\"hiro_car_{i}\")\n","\n","    if agent is not None:\n","        # goal_attack, action_attack, same_noise\n","        eval_model(agent, same_noise, True, True, True)\n","        eval_model(agent, diff_noise, True, True, False)\n","        eval_model(agent, goal_only, True, False, False)\n","        eval_model(agent, action_only, False, True, False)\n","        print(i)\n","        print(f\"same noise: {same_noise}\")\n","        print(f\"diff noise: {diff_noise}\")\n","        print(f\"goal only: {goal_only}\")\n","        print(f\"action only: {action_only}\")\n","        i += 1\n","\n","print(f\"same noise: {same_noise}\")\n","print(f\"diff noise: {diff_noise}\")\n","print(f\"goal only: {goal_only}\")\n","print(f\"action only: {action_only}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","same noise: {0.0: [94.02214846112338], 0.1: [92.91088280148409], 0.2: [88.73957680964396], 0.30000000000000004: [80.45426127347909], 0.4: [88.48766995509122], 0.5: [84.24853736617013], 0.6000000000000001: [79.05334451963672], 0.7000000000000001: [72.85193338894335], 0.8: [74.69679308765011], 0.9: [56.211924336018576], 1.0: [59.01015903604335]}\n","diff noise: {0.0: [93.71854677796182], 0.1: [94.1561725378607], 0.2: [90.79897596794927], 0.30000000000000004: [84.3688637035313], 0.4: [84.45073110011441], 0.5: [88.38314904062052], 0.6000000000000001: [78.04229531815609], 0.7000000000000001: [71.67194475009654], 0.8: [69.3790644730948], 0.9: [53.03670017795054], 1.0: [46.7059416631126]}\n","goal only: {0.0: [93.84735112165377], 0.1: [91.96161437943367], 0.2: [87.6470437385984], 0.30000000000000004: [87.64604546978117], 0.4: [82.28885099771983], 0.5: [84.24833004123533], 0.6000000000000001: [79.98867379601444], 0.7000000000000001: [73.82575091751588], 0.8: [64.56126897762347], 0.9: [46.0148448055563], 1.0: [37.78962043663363]}\n","action only: {0.0: [92.84385725861983], 0.1: [92.81737694140213], 0.2: [93.86329958986066], 0.30000000000000004: [94.00209450946478], 0.4: [93.90816574586349], 0.5: [93.81550420688966], 0.6000000000000001: [93.91374736001225], 0.7000000000000001: [92.77606967914164], 0.8: [92.96501752136868], 0.9: [93.96625057252558], 1.0: [93.78522813567665]}\n","1\n","same noise: {0.0: [94.02214846112338, 92.46604482439199], 0.1: [92.91088280148409, 93.68347903397819], 0.2: [88.73957680964396, 93.81050924564418], 0.30000000000000004: [80.45426127347909, 93.38912613646136], 0.4: [88.48766995509122, 93.04580007729498], 0.5: [84.24853736617013, 86.48651477691469], 0.6000000000000001: [79.05334451963672, 91.08012965855447], 0.7000000000000001: [72.85193338894335, 85.68801342770628], 0.8: [74.69679308765011, 73.33480060972536], 0.9: [56.211924336018576, 75.91297982551082], 1.0: [59.01015903604335, 69.78585499021216]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213], 0.1: [94.1561725378607, 93.84342062352366], 0.2: [90.79897596794927, 93.56180478985999], 0.30000000000000004: [84.3688637035313, 93.47456422515916], 0.4: [84.45073110011441, 93.4361085973489], 0.5: [88.38314904062052, 92.52640561227223], 0.6000000000000001: [78.04229531815609, 91.20291012579966], 0.7000000000000001: [71.67194475009654, 85.9377952797025], 0.8: [69.3790644730948, 78.31535901452867], 0.9: [53.03670017795054, 69.97698462867156], 1.0: [46.7059416631126, 64.42667179918533]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104], 0.1: [91.96161437943367, 93.85400499304062], 0.2: [87.6470437385984, 93.73440099914068], 0.30000000000000004: [87.64604546978117, 93.46331922851236], 0.4: [82.28885099771983, 93.13336922185073], 0.5: [84.24833004123533, 91.55076447641024], 0.6000000000000001: [79.98867379601444, 90.14294473331046], 0.7000000000000001: [73.82575091751588, 86.73935797316517], 0.8: [64.56126897762347, 82.54754208099402], 0.9: [46.0148448055563, 75.32347593020958], 1.0: [37.78962043663363, 66.45719498882666]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515], 0.1: [92.81737694140213, 93.4801967380133], 0.2: [93.86329958986066, 93.83864999895691], 0.30000000000000004: [94.00209450946478, 94.01588910837714], 0.4: [93.90816574586349, 93.89998325778666], 0.5: [93.81550420688966, 93.74386884724696], 0.6000000000000001: [93.91374736001225, 93.77002160599852], 0.7000000000000001: [92.77606967914164, 94.0524815606488], 0.8: [92.96501752136868, 93.91074465866332], 0.9: [93.96625057252558, 93.81475343602828], 1.0: [93.78522813567665, 94.27955916045175]}\n","2\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656]}\n","3\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501]}\n","4\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771]}\n","5\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047]}\n","6\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284, 93.79741066379066], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975, 94.1663301430064], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853, 94.28409525632301], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093, 93.34036408923366], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306, 90.75530544308802], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872, 92.21782375862544], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442, 88.18627125413494], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183, 84.76094640096385], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839, 81.54680433694085], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726, 74.12776568523137], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079, 64.86982633884782]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598, 94.08568890115133], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125, 94.00756383516533], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462, 93.41164063592169], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911, 93.62839514225999], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172, 92.78217139541287], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944, 92.0893047242276], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834, 87.58393411487309], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205, 87.87172835554719], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501, 81.43097163061053], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772, 75.9605298823621], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564, 66.85438452572745]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859, 94.19367012838119], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733, 94.14870610831919], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123, 93.73875547634107], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479, 93.56810446766426], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521, 93.05842466701846], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262, 92.25750765492546], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405, 89.35564649042395], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533, 81.74076644274129], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248, 86.65957979829037], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897, 75.05719551385151], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176, 70.92686691887276]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578, 93.87025529051338], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479, 93.67806316884285], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051, 94.24870083338703], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575, 94.23287610270877], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107, 93.86695078837874], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048, 94.32101588773206], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983, 94.45555255926662], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577, 94.10397014995138], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673, 93.85493046982936], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511, 94.07958835836193], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047, 94.10839101835188]}\n","7\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284, 93.79741066379066, 94.62343849865329], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975, 94.1663301430064, 94.60826004173154], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853, 94.28409525632301, 94.2520755005166], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093, 93.34036408923366, 94.02631587584222], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306, 90.75530544308802, 91.97837388510492], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872, 92.21782375862544, 91.99241161183922], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442, 88.18627125413494, 91.08119818654235], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183, 84.76094640096385, 84.47797202965195], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839, 81.54680433694085, 82.00333287789798], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726, 74.12776568523137, 68.63150499434045], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079, 64.86982633884782, 64.32627278087584]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598, 94.08568890115133, 94.71121751356462], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125, 94.00756383516533, 94.61731756908566], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462, 93.41164063592169, 94.39664540146632], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911, 93.62839514225999, 93.96589484185468], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172, 92.78217139541287, 93.76453728201666], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944, 92.0893047242276, 91.98747649441435], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834, 87.58393411487309, 89.07899274864486], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205, 87.87172835554719, 84.4768108895242], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501, 81.43097163061053, 78.728203690688], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772, 75.9605298823621, 69.6224140897447], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564, 66.85438452572745, 66.40621008559958]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859, 94.19367012838119, 94.62007536572783], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733, 94.14870610831919, 94.67284703504389], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123, 93.73875547634107, 94.34239178956742], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479, 93.56810446766426, 94.12803898188739], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521, 93.05842466701846, 93.45471977319126], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262, 92.25750765492546, 92.70217809797732], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405, 89.35564649042395, 88.14633587212495], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533, 81.74076644274129, 87.4206544566479], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248, 86.65957979829037, 83.03955299951096], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897, 75.05719551385151, 70.33795670545908], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176, 70.92686691887276, 69.21003785981513]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578, 93.87025529051338, 94.49778407006889], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479, 93.67806316884285, 94.65993089582565], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051, 94.24870083338703, 94.59085998887954], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575, 94.23287610270877, 94.60311777555088], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107, 93.86695078837874, 94.6384050082636], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048, 94.32101588773206, 94.48769584406176], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983, 94.45555255926662, 94.3369439600516], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577, 94.10397014995138, 94.52432796948811], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673, 93.85493046982936, 94.50104714021208], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511, 94.07958835836193, 94.58335068761497], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047, 94.10839101835188, 94.68298585254234]}\n","8\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284, 93.79741066379066, 94.62343849865329, 92.76678048062745], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975, 94.1663301430064, 94.60826004173154, 92.42530538745716], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853, 94.28409525632301, 94.2520755005166, 92.78049834214704], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093, 93.34036408923366, 94.02631587584222, 92.09780125084853], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306, 90.75530544308802, 91.97837388510492, 91.76023136935567], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872, 92.21782375862544, 91.99241161183922, 88.90055789228727], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442, 88.18627125413494, 91.08119818654235, 87.88031043128166], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183, 84.76094640096385, 84.47797202965195, 87.07525430153964], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839, 81.54680433694085, 82.00333287789798, 84.50665166209423], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726, 74.12776568523137, 68.63150499434045, 78.96917852273104], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079, 64.86982633884782, 64.32627278087584, 72.5000315836005]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598, 94.08568890115133, 94.71121751356462, 92.73065536779328], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125, 94.00756383516533, 94.61731756908566, 92.36779862920355], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462, 93.41164063592169, 94.39664540146632, 92.45000302431737], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911, 93.62839514225999, 93.96589484185468, 92.10687150905137], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172, 92.78217139541287, 93.76453728201666, 90.49435305266734], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944, 92.0893047242276, 91.98747649441435, 87.72326432915386], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834, 87.58393411487309, 89.07899274864486, 90.01944746858439], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205, 87.87172835554719, 84.4768108895242, 82.47964117223648], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501, 81.43097163061053, 78.728203690688, 83.609419971774], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772, 75.9605298823621, 69.6224140897447, 78.70605633444417], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564, 66.85438452572745, 66.40621008559958, 62.315835948369774]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859, 94.19367012838119, 94.62007536572783, 92.55441647769295], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733, 94.14870610831919, 94.67284703504389, 92.64111397579451], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123, 93.73875547634107, 94.34239178956742, 92.40782911752859], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479, 93.56810446766426, 94.12803898188739, 92.02680469572215], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521, 93.05842466701846, 93.45471977319126, 90.58727987622251], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262, 92.25750765492546, 92.70217809797732, 89.9371863366119], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405, 89.35564649042395, 88.14633587212495, 85.92378128098362], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533, 81.74076644274129, 87.4206544566479, 85.57242953316825], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248, 86.65957979829037, 83.03955299951096, 82.20385001072069], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897, 75.05719551385151, 70.33795670545908, 73.43231930000894], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176, 70.92686691887276, 69.21003785981513, 73.72586163872964]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578, 93.87025529051338, 94.49778407006889, 92.7510731404678], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479, 93.67806316884285, 94.65993089582565, 92.66772239049696], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051, 94.24870083338703, 94.59085998887954, 92.40129681845123], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575, 94.23287610270877, 94.60311777555088, 92.55850715241642], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107, 93.86695078837874, 94.6384050082636, 92.73282413253446], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048, 94.32101588773206, 94.48769584406176, 92.53080162546108], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983, 94.45555255926662, 94.3369439600516, 92.8614012543832], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577, 94.10397014995138, 94.52432796948811, 92.50779845936782], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673, 93.85493046982936, 94.50104714021208, 92.74985903802202], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511, 94.07958835836193, 94.58335068761497, 92.84567714303648], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047, 94.10839101835188, 94.68298585254234, 92.71693619593464]}\n","9\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284, 93.79741066379066, 94.62343849865329, 92.76678048062745, 86.7583094058671], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975, 94.1663301430064, 94.60826004173154, 92.42530538745716, 84.43882899515947], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853, 94.28409525632301, 94.2520755005166, 92.78049834214704, 87.62139792585401], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093, 93.34036408923366, 94.02631587584222, 92.09780125084853, 83.35997645017231], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306, 90.75530544308802, 91.97837388510492, 91.76023136935567, 83.99324559158613], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872, 92.21782375862544, 91.99241161183922, 88.90055789228727, 80.89366879082317], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442, 88.18627125413494, 91.08119818654235, 87.88031043128166, 75.95015373937156], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183, 84.76094640096385, 84.47797202965195, 87.07525430153964, 82.6538855502491], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839, 81.54680433694085, 82.00333287789798, 84.50665166209423, 60.86937811959101], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726, 74.12776568523137, 68.63150499434045, 78.96917852273104, 56.64649639626633], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079, 64.86982633884782, 64.32627278087584, 72.5000315836005, 56.06392144870873]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598, 94.08568890115133, 94.71121751356462, 92.73065536779328, 84.62770986525229], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125, 94.00756383516533, 94.61731756908566, 92.36779862920355, 86.58509302451702], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462, 93.41164063592169, 94.39664540146632, 92.45000302431737, 89.748083524907], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911, 93.62839514225999, 93.96589484185468, 92.10687150905137, 83.47071164788069], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172, 92.78217139541287, 93.76453728201666, 90.49435305266734, 82.92456877033105], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944, 92.0893047242276, 91.98747649441435, 87.72326432915386, 78.55124390061833], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834, 87.58393411487309, 89.07899274864486, 90.01944746858439, 77.06708446249912], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205, 87.87172835554719, 84.4768108895242, 82.47964117223648, 77.67729014747755], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501, 81.43097163061053, 78.728203690688, 83.609419971774, 71.0251950160587], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772, 75.9605298823621, 69.6224140897447, 78.70605633444417, 64.65609019528002], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564, 66.85438452572745, 66.40621008559958, 62.315835948369774, 51.98490642716622]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859, 94.19367012838119, 94.62007536572783, 92.55441647769295, 83.44231377032438], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733, 94.14870610831919, 94.67284703504389, 92.64111397579451, 89.85531811482801], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123, 93.73875547634107, 94.34239178956742, 92.40782911752859, 86.57327235408162], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479, 93.56810446766426, 94.12803898188739, 92.02680469572215, 85.04645975228914], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521, 93.05842466701846, 93.45471977319126, 90.58727987622251, 79.89938292119258], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262, 92.25750765492546, 92.70217809797732, 89.9371863366119, 77.38665350846925], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405, 89.35564649042395, 88.14633587212495, 85.92378128098362, 73.67673199203483], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533, 81.74076644274129, 87.4206544566479, 85.57242953316825, 70.79368872367753], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248, 86.65957979829037, 83.03955299951096, 82.20385001072069, 66.01414136888617], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897, 75.05719551385151, 70.33795670545908, 73.43231930000894, 66.64626496390245], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176, 70.92686691887276, 69.21003785981513, 73.72586163872964, 58.262871780997614]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578, 93.87025529051338, 94.49778407006889, 92.7510731404678, 88.83969327521207], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479, 93.67806316884285, 94.65993089582565, 92.66772239049696, 82.51830053452969], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051, 94.24870083338703, 94.59085998887954, 92.40129681845123, 86.81853067450737], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575, 94.23287610270877, 94.60311777555088, 92.55850715241642, 85.64716957951383], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107, 93.86695078837874, 94.6384050082636, 92.73282413253446, 85.76913027803468], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048, 94.32101588773206, 94.48769584406176, 92.53080162546108, 83.62802797278988], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983, 94.45555255926662, 94.3369439600516, 92.8614012543832, 86.78649792669258], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577, 94.10397014995138, 94.52432796948811, 92.50779845936782, 88.67091612333189], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673, 93.85493046982936, 94.50104714021208, 92.74985903802202, 86.57612376978854], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511, 94.07958835836193, 94.58335068761497, 92.84567714303648, 88.60387990297251], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047, 94.10839101835188, 94.68298585254234, 92.71693619593464, 87.46541517866407]}\n","same noise: {0.0: [94.02214846112338, 92.46604482439199, 94.6267986075503, 93.7934701673048, 93.93178666611402, 93.86893321164284, 93.79741066379066, 94.62343849865329, 92.76678048062745, 86.7583094058671], 0.1: [92.91088280148409, 93.68347903397819, 94.49249989545106, 94.2155443141096, 93.6696586314285, 93.4861958953975, 94.1663301430064, 94.60826004173154, 92.42530538745716, 84.43882899515947], 0.2: [88.73957680964396, 93.81050924564418, 94.04547692415295, 93.67467012104251, 93.67737534492566, 93.79105459966853, 94.28409525632301, 94.2520755005166, 92.78049834214704, 87.62139792585401], 0.30000000000000004: [80.45426127347909, 93.38912613646136, 93.7332797927102, 93.33203009462463, 93.46655614604009, 92.55065630130093, 93.34036408923366, 94.02631587584222, 92.09780125084853, 83.35997645017231], 0.4: [88.48766995509122, 93.04580007729498, 93.18029098180074, 91.87627389290154, 93.13296346352895, 92.32439408611306, 90.75530544308802, 91.97837388510492, 91.76023136935567, 83.99324559158613], 0.5: [84.24853736617013, 86.48651477691469, 91.38706386382927, 90.8980118895532, 89.66755739704604, 91.45148504420872, 92.21782375862544, 91.99241161183922, 88.90055789228727, 80.89366879082317], 0.6000000000000001: [79.05334451963672, 91.08012965855447, 91.26632336151899, 85.45706036858147, 89.14477716489785, 85.78518138078442, 88.18627125413494, 91.08119818654235, 87.88031043128166, 75.95015373937156], 0.7000000000000001: [72.85193338894335, 85.68801342770628, 86.72114165357952, 87.21206206047007, 87.51584332313536, 84.30173794685183, 84.76094640096385, 84.47797202965195, 87.07525430153964, 82.6538855502491], 0.8: [74.69679308765011, 73.33480060972536, 82.99654073723643, 79.6677018418459, 90.16974458953422, 76.96498834016839, 81.54680433694085, 82.00333287789798, 84.50665166209423, 60.86937811959101], 0.9: [56.211924336018576, 75.91297982551082, 81.28526851250881, 80.49840036459963, 63.44069216871539, 72.82106007357726, 74.12776568523137, 68.63150499434045, 78.96917852273104, 56.64649639626633], 1.0: [59.01015903604335, 69.78585499021216, 81.19744106451509, 64.94798885182618, 66.08804419415326, 66.4714337672079, 64.86982633884782, 64.32627278087584, 72.5000315836005, 56.06392144870873]}\n","diff noise: {0.0: [93.71854677796182, 93.733955016213, 94.53222754596733, 94.2928513109786, 93.48236569117334, 93.91256570044598, 94.08568890115133, 94.71121751356462, 92.73065536779328, 84.62770986525229], 0.1: [94.1561725378607, 93.84342062352366, 94.35400615216945, 93.96426944803385, 92.74454467426456, 93.74776676844125, 94.00756383516533, 94.61731756908566, 92.36779862920355, 86.58509302451702], 0.2: [90.79897596794927, 93.56180478985999, 93.6225371771608, 93.80426698199045, 93.56955913037052, 92.55100821014462, 93.41164063592169, 94.39664540146632, 92.45000302431737, 89.748083524907], 0.30000000000000004: [84.3688637035313, 93.47456422515916, 93.80339079964865, 93.34630076372703, 92.47680467012403, 93.54236362946911, 93.62839514225999, 93.96589484185468, 92.10687150905137, 83.47071164788069], 0.4: [84.45073110011441, 93.4361085973489, 93.0384489639039, 93.0633545909846, 93.0402603273106, 91.21948941632172, 92.78217139541287, 93.76453728201666, 90.49435305266734, 82.92456877033105], 0.5: [88.38314904062052, 92.52640561227223, 92.68493026312821, 91.92534523928585, 88.34027011051698, 90.29492623925944, 92.0893047242276, 91.98747649441435, 87.72326432915386, 78.55124390061833], 0.6000000000000001: [78.04229531815609, 91.20291012579966, 91.47692697515544, 87.41848871224128, 85.66149602621952, 83.37244691474834, 87.58393411487309, 89.07899274864486, 90.01944746858439, 77.06708446249912], 0.7000000000000001: [71.67194475009654, 85.9377952797025, 88.9839219704068, 81.80632522900991, 82.4391870256026, 77.30678692283205, 87.87172835554719, 84.4768108895242, 82.47964117223648, 77.67729014747755], 0.8: [69.3790644730948, 78.31535901452867, 88.18454474210739, 80.49068174032976, 78.96501277294271, 67.94884331988501, 81.43097163061053, 78.728203690688, 83.609419971774, 71.0251950160587], 0.9: [53.03670017795054, 69.97698462867156, 81.3511620483026, 71.99758215471445, 71.32572249578313, 81.05091387790772, 75.9605298823621, 69.6224140897447, 78.70605633444417, 64.65609019528002], 1.0: [46.7059416631126, 64.42667179918533, 76.87535836910202, 63.70224871495952, 64.07969268162056, 59.43529383643564, 66.85438452572745, 66.40621008559958, 62.315835948369774, 51.98490642716622]}\n","goal only: {0.0: [93.84735112165377, 94.01368878041104, 94.59882218528121, 94.32547125348006, 93.77220437901678, 93.98654305624859, 94.19367012838119, 94.62007536572783, 92.55441647769295, 83.44231377032438], 0.1: [91.96161437943367, 93.85400499304062, 94.3080542778834, 93.5621228460896, 93.90578112508092, 93.87949122466733, 94.14870610831919, 94.67284703504389, 92.64111397579451, 89.85531811482801], 0.2: [87.6470437385984, 93.73440099914068, 94.2197004346482, 94.02705602123629, 92.78621881208123, 93.86846072805123, 93.73875547634107, 94.34239178956742, 92.40782911752859, 86.57327235408162], 0.30000000000000004: [87.64604546978117, 93.46331922851236, 93.55264928784307, 93.33491955069708, 93.39530235026066, 92.56357533565479, 93.56810446766426, 94.12803898188739, 92.02680469572215, 85.04645975228914], 0.4: [82.28885099771983, 93.13336922185073, 92.74699557203155, 92.65536269510987, 93.08811299095323, 88.79298359010521, 93.05842466701846, 93.45471977319126, 90.58727987622251, 79.89938292119258], 0.5: [84.24833004123533, 91.55076447641024, 92.68823698638009, 88.9654840767474, 89.23851054159962, 89.29174860551262, 92.25750765492546, 92.70217809797732, 89.9371863366119, 77.38665350846925], 0.6000000000000001: [79.98867379601444, 90.14294473331046, 88.52953570121275, 86.35368120752368, 84.7113705020232, 85.92072096714405, 89.35564649042395, 88.14633587212495, 85.92378128098362, 73.67673199203483], 0.7000000000000001: [73.82575091751588, 86.73935797316517, 87.96708064898499, 84.6819331098375, 86.57619139242068, 83.21751093634533, 81.74076644274129, 87.4206544566479, 85.57242953316825, 70.79368872367753], 0.8: [64.56126897762347, 82.54754208099402, 88.40403553348953, 78.87342695370282, 74.67952709489299, 73.8579889005248, 86.65957979829037, 83.03955299951096, 82.20385001072069, 66.01414136888617], 0.9: [46.0148448055563, 75.32347593020958, 82.41616359582065, 81.50579642051923, 64.14009128869708, 63.50132850272897, 75.05719551385151, 70.33795670545908, 73.43231930000894, 66.64626496390245], 1.0: [37.78962043663363, 66.45719498882666, 76.661222807842, 59.84041315301121, 64.80464488941064, 62.4830149642176, 70.92686691887276, 69.21003785981513, 73.72586163872964, 58.262871780997614]}\n","action only: {0.0: [92.84385725861983, 94.01850260126515, 94.57610118787348, 94.06747640446123, 93.79549406328957, 94.08147622371578, 93.87025529051338, 94.49778407006889, 92.7510731404678, 88.83969327521207], 0.1: [92.81737694140213, 93.4801967380133, 94.58862958725474, 94.03698755218574, 93.72566203945051, 93.8409144262479, 93.67806316884285, 94.65993089582565, 92.66772239049696, 82.51830053452969], 0.2: [93.86329958986066, 93.83864999895691, 94.63176353153801, 93.94626612178563, 93.8600671355677, 93.91813177908051, 94.24870083338703, 94.59085998887954, 92.40129681845123, 86.81853067450737], 0.30000000000000004: [94.00209450946478, 94.01588910837714, 94.62125943188748, 93.81662519517484, 93.6213578902633, 93.9875762106575, 94.23287610270877, 94.60311777555088, 92.55850715241642, 85.64716957951383], 0.4: [93.90816574586349, 93.89998325778666, 94.60767767883986, 94.26698859998363, 93.66115354557373, 93.92689857192107, 93.86695078837874, 94.6384050082636, 92.73282413253446, 85.76913027803468], 0.5: [93.81550420688966, 93.74386884724696, 94.61036607890526, 94.08791411361607, 93.7689180636279, 94.02724293360048, 94.32101588773206, 94.48769584406176, 92.53080162546108, 83.62802797278988], 0.6000000000000001: [93.91374736001225, 93.77002160599852, 94.63208493717019, 94.30489569185018, 93.58409838059065, 94.01515673636983, 94.45555255926662, 94.3369439600516, 92.8614012543832, 86.78649792669258], 0.7000000000000001: [92.77606967914164, 94.0524815606488, 94.59051251096865, 94.03093226389943, 93.79620606666498, 93.87895953117577, 94.10397014995138, 94.52432796948811, 92.50779845936782, 88.67091612333189], 0.8: [92.96501752136868, 93.91074465866332, 94.60122687195843, 94.01853203076026, 93.45840078292044, 93.89454807665673, 93.85493046982936, 94.50104714021208, 92.74985903802202, 86.57612376978854], 0.9: [93.96625057252558, 93.81475343602828, 94.58513661181904, 94.22961656093015, 93.62553166371475, 93.94181766540511, 94.07958835836193, 94.58335068761497, 92.84567714303648, 88.60387990297251], 1.0: [93.78522813567665, 94.27955916045175, 94.59430336741656, 94.2248371281501, 93.85462799504771, 94.06483399314047, 94.10839101835188, 94.68298585254234, 92.71693619593464, 87.46541517866407]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4R3KE1BJuCRj"},"source":[""],"execution_count":null,"outputs":[]}]}